{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS114_lab01_BCT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1EznLNCy7yyZ",
        "HvLZmQ-g8v2S",
        "NDFQic-s-HIF",
        "o5dDekaEG3fN",
        "-VZeZjmqAHhU",
        "vzSH4daO89Nu",
        "fo4af48wEXC5"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1A4HIcS0eJn"
      },
      "source": [
        "# __LAB 1: LINEAR REGRESSION__\n",
        "***\n",
        "Members:\n",
        "\n",
        "*   19522195 - Dương Đình Thắng\n",
        "*   19522179 - Trịnh Nhật Tân\n",
        "*   19522395 - Trương Đình Đức Trí\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EznLNCy7yyZ"
      },
      "source": [
        "# __Import các thư viện cần thiết__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZX83aJayF2Z"
      },
      "source": [
        "import requests\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import log_loss, mean_squared_error, r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvLZmQ-g8v2S"
      },
      "source": [
        "# __Data__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpD-7-LnakRx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1-MgqAC9BSv"
      },
      "source": [
        "## __Load data__\n",
        "***\n",
        "`url_train` = \"https://cs.uit.edu.vn/data2.txt\"\n",
        "\n",
        "`url_test_1` = \"https://cs.uit.edu.vn/data3.txt\"\n",
        "\n",
        "`url_test_2` = \"https://cs.uit.edu.vn/data4.txt\"\n",
        "\n",
        "Dùng `requests.get(url).text` để lấy nội dung của url và viết vào file `.csv`.\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmDyR-bSyVkQ"
      },
      "source": [
        "url_train = \"https://cs.uit.edu.vn/data2.txt\"\n",
        "s = requests.get(url_train).text\n",
        "\n",
        "with open(\"./train.csv\", \"w\") as f:\n",
        "    f.write(\"size,time\\n\")\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgRT038X0IbS"
      },
      "source": [
        "url_test_1 = \"https://cs.uit.edu.vn/data3.txt\"\n",
        "s = requests.get(url_test_1).text\n",
        "\n",
        "with open(\"./test_1.csv\", \"w\") as f:\n",
        "    f.write(\"size,time\\n\")\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwcdxYIhDSc5"
      },
      "source": [
        "url_test_2 = \"https://cs.uit.edu.vn/data4.txt\"\n",
        "s = requests.get(url_test_2).text\n",
        "\n",
        "with open(\"./test_2.csv\", \"w\") as f:\n",
        "    f.write(\"size,time\\n\")\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDFQic-s-HIF"
      },
      "source": [
        "## __Visualize Data__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd9m1e6gFW3P"
      },
      "source": [
        "### Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbolXNBoynNf",
        "outputId": "74fd0e7d-80fb-46d6-90a3-0c85a05f9aae"
      },
      "source": [
        "df_train = pd.read_csv(\"./train.csv\")\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>size</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6083695</td>\n",
              "      <td>0.521842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1954367</td>\n",
              "      <td>0.152648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3734185</td>\n",
              "      <td>0.298548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5839301</td>\n",
              "      <td>0.460480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6343427</td>\n",
              "      <td>0.527977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      size      time\n",
              "0  6083695  0.521842\n",
              "1  1954367  0.152648\n",
              "2  3734185  0.298548\n",
              "3  5839301  0.460480\n",
              "4  6343427  0.527977"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BciONBzM_TFX",
        "outputId": "824e4eb8-956c-4c49-d096-c85d46033709"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>size</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7.111500e+04</td>\n",
              "      <td>71115.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.998766e+06</td>\n",
              "      <td>0.406785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.882618e+06</td>\n",
              "      <td>0.244039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.550000e+02</td>\n",
              "      <td>0.000009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.496521e+06</td>\n",
              "      <td>0.192746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.010144e+06</td>\n",
              "      <td>0.403410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.481742e+06</td>\n",
              "      <td>0.616155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.999882e+06</td>\n",
              "      <td>0.983776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               size          time\n",
              "count  7.111500e+04  71115.000000\n",
              "mean   4.998766e+06      0.406785\n",
              "std    2.882618e+06      0.244039\n",
              "min    2.550000e+02      0.000009\n",
              "25%    2.496521e+06      0.192746\n",
              "50%    5.010144e+06      0.403410\n",
              "75%    7.481742e+06      0.616155\n",
              "max    9.999882e+06      0.983776"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoOXRJxUFoqv",
        "outputId": "72121b98-da94-46df-c967-100852d2aa4d"
      },
      "source": [
        "sns.scatterplot(x='size', y='time', data=df_train, color='crimson')\n",
        "\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "\n",
        "plt.legend([\"Training samples\"])\n",
        "plt.title(\"Training set Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb20CpezFlF8"
      },
      "source": [
        "### Test set 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6BGh0vs-S5U",
        "outputId": "fe8d8891-457a-4c62-b357-f6411d59949f"
      },
      "source": [
        "df_test_1 = pd.read_csv('./test_1.csv')\n",
        "df_test_1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>size</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37837612</td>\n",
              "      <td>4.12166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37395246</td>\n",
              "      <td>3.92089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36610827</td>\n",
              "      <td>3.21540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>29555651</td>\n",
              "      <td>2.54506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25928216</td>\n",
              "      <td>2.21831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       size     time\n",
              "0  37837612  4.12166\n",
              "1  37395246  3.92089\n",
              "2  36610827  3.21540\n",
              "3  29555651  2.54506\n",
              "4  25928216  2.21831"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCMsNd20_YCY",
        "outputId": "1ddc9179-e2ba-45b8-8b2a-299cd2213a35"
      },
      "source": [
        "df_test_1.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>size</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.059000e+04</td>\n",
              "      <td>10590.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.999277e+07</td>\n",
              "      <td>2.642812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.759381e+06</td>\n",
              "      <td>0.537305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000026e+07</td>\n",
              "      <td>1.669640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.503806e+07</td>\n",
              "      <td>2.180550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.994436e+07</td>\n",
              "      <td>2.639820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.500845e+07</td>\n",
              "      <td>3.100155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.999734e+07</td>\n",
              "      <td>4.287660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               size          time\n",
              "count  1.059000e+04  10590.000000\n",
              "mean   2.999277e+07      2.642812\n",
              "std    5.759381e+06      0.537305\n",
              "min    2.000026e+07      1.669640\n",
              "25%    2.503806e+07      2.180550\n",
              "50%    2.994436e+07      2.639820\n",
              "75%    3.500845e+07      3.100155\n",
              "max    3.999734e+07      4.287660"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ke6WCoH4GQWH",
        "outputId": "5e2ad1bc-cd1a-4860-f43c-e338420d5bf9"
      },
      "source": [
        "sns.scatterplot(x='size', y='time', data=df_test_1, color=\"blue\")\n",
        "\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "\n",
        "plt.legend([\"Test samples\"])\n",
        "plt.title(\"Test set 1 Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYLFjEU0813N"
      },
      "source": [
        "### Test set 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dIs2tEL9TDz",
        "outputId": "fc7864c2-5ce8-4e6c-e06c-7528d55c6fa6"
      },
      "source": [
        "df_test_2 = pd.read_csv('./test_2.csv')\n",
        "df_test_2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>size</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50142057</td>\n",
              "      <td>5.51836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>65232531</td>\n",
              "      <td>7.18304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67683741</td>\n",
              "      <td>6.94395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59798449</td>\n",
              "      <td>5.48383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62297119</td>\n",
              "      <td>5.65503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       size     time\n",
              "0  50142057  5.51836\n",
              "1  65232531  7.18304\n",
              "2  67683741  6.94395\n",
              "3  59798449  5.48383\n",
              "4  62297119  5.65503"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2QuLJlL9WiI",
        "outputId": "9db60a1f-b828-4a2e-8578-d956e913988b"
      },
      "source": [
        "df_test_2.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>size</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.023000e+03</td>\n",
              "      <td>6023.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.001134e+07</td>\n",
              "      <td>5.510494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.788140e+06</td>\n",
              "      <td>0.571520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.000951e+07</td>\n",
              "      <td>4.395220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.501938e+07</td>\n",
              "      <td>5.019585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.992788e+07</td>\n",
              "      <td>5.495210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.506852e+07</td>\n",
              "      <td>6.002910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6.999990e+07</td>\n",
              "      <td>7.615200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               size         time\n",
              "count  6.023000e+03  6023.000000\n",
              "mean   6.001134e+07     5.510494\n",
              "std    5.788140e+06     0.571520\n",
              "min    5.000951e+07     4.395220\n",
              "25%    5.501938e+07     5.019585\n",
              "50%    5.992788e+07     5.495210\n",
              "75%    6.506852e+07     6.002910\n",
              "max    6.999990e+07     7.615200"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMXj7N2g9Yp3",
        "outputId": "7d495e00-fc3d-4ef6-e238-c7c036d0b128"
      },
      "source": [
        "sns.scatterplot(x='size', y='time', data=df_test_2, color=\"green\")\n",
        "\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "\n",
        "plt.legend([\"Test samples\"])\n",
        "plt.title(\"Test set 2 Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHCnTDgQ0sCf",
        "outputId": "d4462fee-1f32-44f8-8140-88a1469c7bac"
      },
      "source": [
        "sns.scatterplot(x='size', y='time', data=df_train, color='crimson')\n",
        "sns.scatterplot(x='size', y='time', data=df_test_1, color=\"blue\")\n",
        "sns.scatterplot(x='size', y='time', data=df_test_2, color=\"green\")\n",
        "\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "\n",
        "plt.legend((\"Training samples\", \"Test set 1 samples\", \"Test set 2 samples\"))\n",
        "plt.title(\"Dataset Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5dDekaEG3fN"
      },
      "source": [
        "# __Tiền xử lý dữ liệu__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYYpDxxqHaPv"
      },
      "source": [
        "## Chuyển các dataframe về dạng np.darray"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "torTgBcdHfv4"
      },
      "source": [
        "# Training set\n",
        "X_train, y_train = df_train.to_numpy(dtype=np.float32)[:, :-1], df_train.to_numpy(dtype=np.float32)[:, -1].reshape(-1, 1)\n",
        "\n",
        "# Test set 1\n",
        "X_test_1, y_test_1 = df_test_1.to_numpy(dtype=np.float32)[:, :-1], df_test_1.to_numpy(dtype=np.float32)[:, -1].reshape(-1, 1)\n",
        "\n",
        "# Test set 2\n",
        "X_test_2, y_test_2 = df_test_2.to_numpy(dtype=np.float32)[:, :-1], df_test_2.to_numpy(dtype=np.float32)[:, -1].reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD1VmdC1Ibns"
      },
      "source": [
        "## Feature Scaling sử dụng Standard Scaler\n",
        "\n",
        "Công thức: $z=\\frac{x - μ}{σ}$\n",
        "\n",
        "\n",
        "với $\\mu = \\frac{1}{N}𝚺^{N}_{i=1}x_i$\n",
        "\n",
        "$σ = \\sqrt(\\frac{1}{N}𝚺_{i=1}^{N}(x_i - \\mu)^2)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMbxWCYHIg9J",
        "outputId": "2b7e9e0b-f3c2-4ac0-f07b-4726c7e870d5"
      },
      "source": [
        "X_scaler = StandardScaler()\n",
        "X_scaler.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj84GPdsIjEV"
      },
      "source": [
        "X_train_scale = X_scaler.transform(X_train)\n",
        "X_test_1_scale = X_scaler.transform(X_test_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DdfGTmgL5E0",
        "outputId": "8bc87d37-79cc-4851-9779-d5f324b697cc"
      },
      "source": [
        "y_scaler = StandardScaler()\n",
        "y_scaler.fit(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ly_tegNL9nX"
      },
      "source": [
        "y_train_scale = y_scaler.transform(y_train)\n",
        "y_test_1_scale = y_scaler.transform(y_test_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VZeZjmqAHhU"
      },
      "source": [
        "# __Huấn luyện mô hình Linear Regression__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQKsL0E2s6KD"
      },
      "source": [
        "## Sử dụng class LinearRegression() trong thư viện sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlNpKAVd03ft"
      },
      "source": [
        "lin_reg = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJoIWm2CIyfv",
        "outputId": "28ce3e52-88fb-4e27-86d2-d3ded9b28cd7"
      },
      "source": [
        "lin_reg.fit(X_train_scale, y_train_scale)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX0ws0aR5y3i",
        "outputId": "99a19592-e0e7-44c1-e25f-c2746f4068f4"
      },
      "source": [
        "lin_reg.coef_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9987955]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP-J1ukT52g-",
        "outputId": "a1e4d5e8-a66c-43c0-bbc2-3ebb4bd58bec"
      },
      "source": [
        "lin_reg.intercept_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.3831042e-08], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By8usjP6wRjF"
      },
      "source": [
        "## Đánh giá mô hình Linear Regression bằng độ đo R2 Score\n",
        "Công thức $R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} = 1 - \\frac{Σ_{i=1}^{N}(y_i-ŷ_i)}{Σ_{i=1}^{N}(y_i-y̅)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSHofm5LAw7R"
      },
      "source": [
        "y_pred = lin_reg.predict(X_test_1_scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVR8pRAsJRDP",
        "outputId": "e08c120d-0059-40e5-d1df-d068c8a95eb5"
      },
      "source": [
        "print(\"R2 Score: \", lin_reg.score(y_pred, y_test_1_scale))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Score:  0.9260356074251243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "spdfFuaa6EH0",
        "outputId": "4cb76089-ea82-4d5d-bbbe-85eaa6d9af1e"
      },
      "source": [
        "y_pred = lin_reg.predict(X_train_scale)\n",
        "plt.scatter(X_train_scale, y_train_scale, c=\"crimson\")\n",
        "plt.scatter(X_train_scale, y_pred, c=\"yellow\")\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "plt.legend((\"True label\", \"Pred label\"))\n",
        "plt.title(\"Regression result on Training\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sjuyYOFEJYT5",
        "outputId": "8fda8dbf-acf9-4162-e65b-84513853aa99"
      },
      "source": [
        "y_pred = lin_reg.predict(X_test_1_scale)\n",
        "plt.scatter(X_test_1_scale, y_test_1_scale, c=\"crimson\")\n",
        "plt.scatter(X_test_1_scale, y_pred, c=\"yellow\")\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "plt.legend((\"True label\", \"Pred label\"))\n",
        "plt.title(\"Regression result on Test set 1\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8ild406twe8"
      },
      "source": [
        "## Sử dụng SGDRegressor() trong thư viện sklearn kết hợp với thuật toán GridSearch để tìm bộ tham số tối ưu cho SGDRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg3HOonemyXu"
      },
      "source": [
        "tuned_parameters = {\n",
        "    'alpha': 10.0 ** -np.arange(1, 7),\n",
        "    'loss': ['squared_loss', 'huber', 'epsilon_insensitive'],\n",
        "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
        "    'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
        "}\n",
        "\n",
        "score = 'r2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grspIPN_nvq2"
      },
      "source": [
        "sgd_reg_gird = SGDRegressor(verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hapxpLRn4Si"
      },
      "source": [
        "reg = GridSearchCV(sgd_reg_gird, tuned_parameters, scoring=score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQKKVXizoYz4",
        "outputId": "1001ab8d-1630-4462-8679-52ce7e5eb155"
      },
      "source": [
        "reg = reg.fit(X_train_scale, y_train_scale)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.90, NNZs: 1, Bias: 0.000042, T: 56892, Avg. loss: 0.005851\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.90, NNZs: 1, Bias: -0.007565, T: 113784, Avg. loss: 0.005386\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.90, NNZs: 1, Bias: -0.011859, T: 170676, Avg. loss: 0.005388\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.008874, T: 227568, Avg. loss: 0.005388\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.90, NNZs: 1, Bias: -0.000070, T: 284460, Avg. loss: 0.005385\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.90, NNZs: 1, Bias: -0.004478, T: 341352, Avg. loss: 0.005387\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.001921, T: 56892, Avg. loss: 0.005886\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.90, NNZs: 1, Bias: -0.009242, T: 113784, Avg. loss: 0.005425\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.006124, T: 170676, Avg. loss: 0.005424\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.92, NNZs: 1, Bias: 0.004100, T: 227568, Avg. loss: 0.005426\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.003787, T: 284460, Avg. loss: 0.005419\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.005820, T: 341352, Avg. loss: 0.005426\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.005032, T: 56892, Avg. loss: 0.005887\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.009597, T: 113784, Avg. loss: 0.005419\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.008780, T: 170676, Avg. loss: 0.005420\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.002754, T: 227568, Avg. loss: 0.005421\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.90, NNZs: 1, Bias: -0.005447, T: 284460, Avg. loss: 0.005419\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.001519, T: 341352, Avg. loss: 0.005420\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.92, NNZs: 1, Bias: 0.013924, T: 56892, Avg. loss: 0.005889\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.002911, T: 113784, Avg. loss: 0.005421\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.92, NNZs: 1, Bias: 0.001449, T: 170676, Avg. loss: 0.005425\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.90, NNZs: 1, Bias: -0.001935, T: 227568, Avg. loss: 0.005420\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.90, NNZs: 1, Bias: -0.018687, T: 284460, Avg. loss: 0.005423\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.90, NNZs: 1, Bias: 0.000383, T: 341352, Avg. loss: 0.005424\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.007210, T: 56892, Avg. loss: 0.005680\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.92, NNZs: 1, Bias: 0.008276, T: 113784, Avg. loss: 0.005217\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.008147, T: 170676, Avg. loss: 0.005214\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.92, NNZs: 1, Bias: 0.006003, T: 227568, Avg. loss: 0.005217\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.005649, T: 284460, Avg. loss: 0.005216\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.014447, T: 341352, Avg. loss: 0.005216\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 10.15, NNZs: 1, Bias: -0.001962, T: 56892, Avg. loss: 0.006788\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 14.33, NNZs: 1, Bias: -0.000987, T: 113784, Avg. loss: 0.006273\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 17.54, NNZs: 1, Bias: -0.007436, T: 170676, Avg. loss: 0.006274\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 20.25, NNZs: 1, Bias: 0.011824, T: 227568, Avg. loss: 0.006278\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 22.63, NNZs: 1, Bias: 0.000707, T: 284460, Avg. loss: 0.006268\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 24.79, NNZs: 1, Bias: -0.000595, T: 341352, Avg. loss: 0.006274\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 10.14, NNZs: 1, Bias: 0.001851, T: 56892, Avg. loss: 0.006848\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 14.32, NNZs: 1, Bias: 0.004195, T: 113784, Avg. loss: 0.006315\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 17.53, NNZs: 1, Bias: -0.016319, T: 170676, Avg. loss: 0.006313\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 20.24, NNZs: 1, Bias: 0.004961, T: 227568, Avg. loss: 0.006317\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 22.63, NNZs: 1, Bias: 0.005602, T: 284460, Avg. loss: 0.006316\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 24.79, NNZs: 1, Bias: -0.004882, T: 341352, Avg. loss: 0.006311\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 10.15, NNZs: 1, Bias: 0.004978, T: 56892, Avg. loss: 0.006826\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 14.33, NNZs: 1, Bias: -0.001910, T: 113784, Avg. loss: 0.006298\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 17.54, NNZs: 1, Bias: -0.003884, T: 170676, Avg. loss: 0.006306\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 20.25, NNZs: 1, Bias: 0.010252, T: 227568, Avg. loss: 0.006301\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 22.64, NNZs: 1, Bias: -0.006781, T: 284460, Avg. loss: 0.006301\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 24.80, NNZs: 1, Bias: 0.002068, T: 341352, Avg. loss: 0.006308\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 10.15, NNZs: 1, Bias: -0.013368, T: 56892, Avg. loss: 0.006819\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 14.33, NNZs: 1, Bias: 0.002709, T: 113784, Avg. loss: 0.006315\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 17.54, NNZs: 1, Bias: 0.000786, T: 170676, Avg. loss: 0.006316\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 20.25, NNZs: 1, Bias: -0.006215, T: 227568, Avg. loss: 0.006316\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 22.63, NNZs: 1, Bias: -0.009053, T: 284460, Avg. loss: 0.006312\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 24.79, NNZs: 1, Bias: -0.009995, T: 341352, Avg. loss: 0.006317\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 10.15, NNZs: 1, Bias: 0.003196, T: 56892, Avg. loss: 0.006623\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 14.33, NNZs: 1, Bias: -0.002603, T: 113784, Avg. loss: 0.006100\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 17.54, NNZs: 1, Bias: -0.005269, T: 170676, Avg. loss: 0.006105\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 20.25, NNZs: 1, Bias: 0.000025, T: 227568, Avg. loss: 0.006106\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 22.63, NNZs: 1, Bias: 0.004165, T: 284460, Avg. loss: 0.006104\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 24.79, NNZs: 1, Bias: -0.004803, T: 341352, Avg. loss: 0.006101\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.006716, T: 56892, Avg. loss: 0.005978\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001468, T: 113784, Avg. loss: 0.005509\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.014120, T: 170676, Avg. loss: 0.005504\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.006696, T: 227568, Avg. loss: 0.005504\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003095, T: 284460, Avg. loss: 0.005505\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001150, T: 341352, Avg. loss: 0.005502\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008882, T: 56892, Avg. loss: 0.006014\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004840, T: 113784, Avg. loss: 0.005540\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.003610, T: 170676, Avg. loss: 0.005538\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001952, T: 227568, Avg. loss: 0.005543\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.016237, T: 284460, Avg. loss: 0.005542\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.006191, T: 341352, Avg. loss: 0.005540\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000431, T: 56892, Avg. loss: 0.006001\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003573, T: 113784, Avg. loss: 0.005540\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003011, T: 170676, Avg. loss: 0.005532\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.006720, T: 227568, Avg. loss: 0.005534\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.99, NNZs: 1, Bias: -0.016468, T: 284460, Avg. loss: 0.005535\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.012079, T: 341352, Avg. loss: 0.005533\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.007409, T: 56892, Avg. loss: 0.006015\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001423, T: 113784, Avg. loss: 0.005547\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003220, T: 170676, Avg. loss: 0.005542\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.014075, T: 227568, Avg. loss: 0.005540\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.002796, T: 284460, Avg. loss: 0.005540\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000852, T: 341352, Avg. loss: 0.005538\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.002006, T: 56892, Avg. loss: 0.005807\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.006714, T: 113784, Avg. loss: 0.005335\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003293, T: 170676, Avg. loss: 0.005332\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.005960, T: 227568, Avg. loss: 0.005332\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008561, T: 284460, Avg. loss: 0.005335\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.012094, T: 341352, Avg. loss: 0.005330\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.021865, T: 56892, Avg. loss: 0.012079\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.84, NNZs: 1, Bias: 0.010587, T: 113784, Avg. loss: 0.011007\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.009804, T: 170676, Avg. loss: 0.010992\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.012513, T: 227568, Avg. loss: 0.011002\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.031667, T: 284460, Avg. loss: 0.011007\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.81, NNZs: 1, Bias: -0.033777, T: 341352, Avg. loss: 0.010998\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020703, T: 398244, Avg. loss: 0.010991\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.004855, T: 56892, Avg. loss: 0.012213\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.84, NNZs: 1, Bias: -0.030191, T: 113784, Avg. loss: 0.011099\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.008965, T: 170676, Avg. loss: 0.011074\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.035729, T: 227568, Avg. loss: 0.011081\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.005577, T: 284460, Avg. loss: 0.011102\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.013967, T: 341352, Avg. loss: 0.011086\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.025788, T: 398244, Avg. loss: 0.011099\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.81, NNZs: 1, Bias: -0.023292, T: 56892, Avg. loss: 0.012132\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.81, NNZs: 1, Bias: -0.010401, T: 113784, Avg. loss: 0.011042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.018098, T: 170676, Avg. loss: 0.011070\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.023582, T: 227568, Avg. loss: 0.011047\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.81, NNZs: 1, Bias: -0.016033, T: 284460, Avg. loss: 0.011008\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.82, NNZs: 1, Bias: 0.004284, T: 341352, Avg. loss: 0.011043\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.031481, T: 398244, Avg. loss: 0.011043\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.020583, T: 56892, Avg. loss: 0.012171\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.84, NNZs: 1, Bias: -0.025468, T: 113784, Avg. loss: 0.011086\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.84, NNZs: 1, Bias: -0.015337, T: 170676, Avg. loss: 0.011057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.017001, T: 227568, Avg. loss: 0.011052\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.025437, T: 284460, Avg. loss: 0.011066\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.81, NNZs: 1, Bias: -0.028523, T: 341352, Avg. loss: 0.011034\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.012739, T: 398244, Avg. loss: 0.011074\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.029941, T: 56892, Avg. loss: 0.012077\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.018226, T: 113784, Avg. loss: 0.010999\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.029962, T: 170676, Avg. loss: 0.010966\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.027403, T: 227568, Avg. loss: 0.010987\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.025818, T: 284460, Avg. loss: 0.010997\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.81, NNZs: 1, Bias: -0.007174, T: 341352, Avg. loss: 0.010960\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.81, NNZs: 1, Bias: -0.047060, T: 398244, Avg. loss: 0.010990\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.24, NNZs: 0, Bias: -0.045784, T: 56892, Avg. loss: 0.081850\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.34, NNZs: 0, Bias: -0.019181, T: 113784, Avg. loss: 0.081848\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.41, NNZs: 0, Bias: -0.019256, T: 170676, Avg. loss: 0.081854\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.48, NNZs: 0, Bias: 0.049736, T: 227568, Avg. loss: 0.081850\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.53, NNZs: 0, Bias: -0.052891, T: 284460, Avg. loss: 0.081845\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.58, NNZs: 0, Bias: -0.002104, T: 341352, Avg. loss: 0.081851\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.24, NNZs: 0, Bias: -0.047644, T: 56892, Avg. loss: 0.081680\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.34, NNZs: 0, Bias: -0.002108, T: 113784, Avg. loss: 0.081686\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.41, NNZs: 0, Bias: -0.028833, T: 170676, Avg. loss: 0.081686\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.48, NNZs: 0, Bias: -0.000889, T: 227568, Avg. loss: 0.081689\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.53, NNZs: 0, Bias: -0.006021, T: 284460, Avg. loss: 0.081689\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.58, NNZs: 0, Bias: -0.059963, T: 341352, Avg. loss: 0.081683\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.24, NNZs: 0, Bias: -0.011147, T: 56892, Avg. loss: 0.081846\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.34, NNZs: 0, Bias: -0.002868, T: 113784, Avg. loss: 0.081846\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.41, NNZs: 0, Bias: 0.018202, T: 170676, Avg. loss: 0.081837\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.48, NNZs: 0, Bias: -0.019196, T: 227568, Avg. loss: 0.081841\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.53, NNZs: 0, Bias: 0.060612, T: 284460, Avg. loss: 0.081824\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.58, NNZs: 0, Bias: -0.004931, T: 341352, Avg. loss: 0.081844\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.24, NNZs: 0, Bias: -0.005221, T: 56892, Avg. loss: 0.081761\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.34, NNZs: 0, Bias: -0.010071, T: 113784, Avg. loss: 0.081753\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.41, NNZs: 0, Bias: -0.011302, T: 170676, Avg. loss: 0.081762\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.48, NNZs: 0, Bias: -0.014659, T: 227568, Avg. loss: 0.081753\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.53, NNZs: 0, Bias: -0.016088, T: 284460, Avg. loss: 0.081764\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.58, NNZs: 0, Bias: -0.025544, T: 341352, Avg. loss: 0.081755\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.24, NNZs: 0, Bias: -0.008316, T: 56892, Avg. loss: 0.081713\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.34, NNZs: 0, Bias: -0.013354, T: 113784, Avg. loss: 0.081717\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.41, NNZs: 0, Bias: -0.070239, T: 170676, Avg. loss: 0.081706\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.48, NNZs: 0, Bias: -0.023585, T: 227568, Avg. loss: 0.081718\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.53, NNZs: 0, Bias: -0.036385, T: 284460, Avg. loss: 0.081715\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.58, NNZs: 0, Bias: -0.032053, T: 341352, Avg. loss: 0.081710\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.007743, T: 56892, Avg. loss: 0.013990\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.90, NNZs: 1, Bias: -0.000915, T: 113784, Avg. loss: 0.012788\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.87, NNZs: 1, Bias: -0.039975, T: 170676, Avg. loss: 0.012726\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.032041, T: 227568, Avg. loss: 0.012793\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.029612, T: 284460, Avg. loss: 0.012744\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.87, NNZs: 1, Bias: -0.046118, T: 341352, Avg. loss: 0.012741\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.87, NNZs: 1, Bias: -0.000457, T: 398244, Avg. loss: 0.012735\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.036465, T: 56892, Avg. loss: 0.014151\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.89, NNZs: 1, Bias: 0.006694, T: 113784, Avg. loss: 0.012863\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.87, NNZs: 1, Bias: -0.013573, T: 170676, Avg. loss: 0.012854\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.037778, T: 227568, Avg. loss: 0.012893\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.024377, T: 284460, Avg. loss: 0.012846\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.012882, T: 341352, Avg. loss: 0.012891\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.016384, T: 398244, Avg. loss: 0.012848\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.87, NNZs: 1, Bias: -0.016298, T: 56892, Avg. loss: 0.014078\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.90, NNZs: 1, Bias: -0.043127, T: 113784, Avg. loss: 0.012834\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.86, NNZs: 1, Bias: -0.021433, T: 170676, Avg. loss: 0.012764\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.016521, T: 227568, Avg. loss: 0.012850\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.010191, T: 284460, Avg. loss: 0.012796\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.016808, T: 341352, Avg. loss: 0.012828\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.87, NNZs: 1, Bias: -0.013392, T: 398244, Avg. loss: 0.012742\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.020879, T: 56892, Avg. loss: 0.014075\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.90, NNZs: 1, Bias: 0.003369, T: 113784, Avg. loss: 0.012867\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.019240, T: 170676, Avg. loss: 0.012825\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.90, NNZs: 1, Bias: -0.022384, T: 227568, Avg. loss: 0.012863\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.045071, T: 284460, Avg. loss: 0.012812\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.015869, T: 341352, Avg. loss: 0.012840\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.008221, T: 398244, Avg. loss: 0.012841\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.023334, T: 56892, Avg. loss: 0.014011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.023118, T: 113784, Avg. loss: 0.012768\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.027109, T: 170676, Avg. loss: 0.012757\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.024735, T: 227568, Avg. loss: 0.012770\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.009190, T: 284460, Avg. loss: 0.012768\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.87, NNZs: 1, Bias: -0.005602, T: 341352, Avg. loss: 0.012746\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.018885, T: 398244, Avg. loss: 0.012793\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.004309\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.050000, T: 113784, Avg. loss: 0.003577\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.003567\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.93, NNZs: 1, Bias: -0.000000, T: 227568, Avg. loss: 0.003606\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.030000, T: 284460, Avg. loss: 0.003541\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030000, T: 341352, Avg. loss: 0.003579\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.004490\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.030000, T: 113784, Avg. loss: 0.003722\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030000, T: 170676, Avg. loss: 0.003716\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.003726\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.003736\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.003717\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.004406\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.030000, T: 113784, Avg. loss: 0.003621\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.003618\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.003614\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.030000, T: 284460, Avg. loss: 0.003674\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.003629\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.004475\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.92, NNZs: 1, Bias: -0.000000, T: 113784, Avg. loss: 0.003733\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.040000, T: 170676, Avg. loss: 0.003715\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.003715\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.040000, T: 284460, Avg. loss: 0.003694\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.93, NNZs: 1, Bias: 0.030000, T: 341352, Avg. loss: 0.003710\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.96, NNZs: 1, Bias: 0.040000, T: 56892, Avg. loss: 0.003840\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.040000, T: 113784, Avg. loss: 0.003098\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.003105\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.003120\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030000, T: 284460, Avg. loss: 0.003084\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.003094\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 10.45, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.004503\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 14.76, NNZs: 1, Bias: 0.040000, T: 113784, Avg. loss: 0.003690\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 18.06, NNZs: 1, Bias: 0.030000, T: 170676, Avg. loss: 0.003698\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 20.85, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.003692\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 23.31, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.003716\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 25.53, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.003665\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 10.45, NNZs: 1, Bias: 0.040000, T: 56892, Avg. loss: 0.004683\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 14.76, NNZs: 1, Bias: 0.030000, T: 113784, Avg. loss: 0.003879\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 18.06, NNZs: 1, Bias: 0.030000, T: 170676, Avg. loss: 0.003876\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 20.85, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.003827\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 23.31, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.003866\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 25.53, NNZs: 1, Bias: 0.030000, T: 341352, Avg. loss: 0.003845\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 10.46, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.004530\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 14.76, NNZs: 1, Bias: 0.050000, T: 113784, Avg. loss: 0.003747\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 18.07, NNZs: 1, Bias: 0.030000, T: 170676, Avg. loss: 0.003761\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 20.86, NNZs: 1, Bias: 0.040000, T: 227568, Avg. loss: 0.003749\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 23.31, NNZs: 1, Bias: 0.040000, T: 284460, Avg. loss: 0.003767\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 25.54, NNZs: 1, Bias: 0.050000, T: 341352, Avg. loss: 0.003740\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 10.45, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.004646\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 14.76, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.003864\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 18.06, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.003844\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 20.85, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.003848\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 23.31, NNZs: 1, Bias: 0.030000, T: 284460, Avg. loss: 0.003827\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 25.53, NNZs: 1, Bias: 0.040000, T: 341352, Avg. loss: 0.003811\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 10.45, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.004057\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 14.76, NNZs: 1, Bias: 0.030000, T: 113784, Avg. loss: 0.003227\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 18.06, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.003222\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 20.85, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.003187\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 23.31, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.003217\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 25.53, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.003197\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.004371\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030000, T: 113784, Avg. loss: 0.003600\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030000, T: 170676, Avg. loss: 0.003605\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.040000, T: 227568, Avg. loss: 0.003567\n",
            "Total training time: 0.01 seconds."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.003604\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.040000, T: 341352, Avg. loss: 0.003583\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.004480\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.003711\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.030000, T: 170676, Avg. loss: 0.003720\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.003746\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030000, T: 284460, Avg. loss: 0.003747\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.003733\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.004441\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.003664\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.003649\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.050000, T: 227568, Avg. loss: 0.003660\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.003665\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030000, T: 341352, Avg. loss: 0.003669\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.004512\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.003720\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.003733\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.003750\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.030000, T: 284460, Avg. loss: 0.003731\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030000, T: 341352, Avg. loss: 0.003755\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.003935\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.030000, T: 113784, Avg. loss: 0.003098\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030000, T: 170676, Avg. loss: 0.003145\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.040000, T: 227568, Avg. loss: 0.003111\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.030000, T: 284460, Avg. loss: 0.003143\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.003138\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.001112, T: 56892, Avg. loss: 0.005374\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000616, T: 113784, Avg. loss: 0.005337\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000034, T: 170676, Avg. loss: 0.005339\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000295, T: 227568, Avg. loss: 0.005361\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000143, T: 284460, Avg. loss: 0.005332\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000246, T: 341352, Avg. loss: 0.005323\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.001220, T: 56892, Avg. loss: 0.006012\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000249, T: 113784, Avg. loss: 0.005365\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000046, T: 170676, Avg. loss: 0.005357\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000379, T: 227568, Avg. loss: 0.005400\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000411, T: 284460, Avg. loss: 0.005369\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000429, T: 341352, Avg. loss: 0.005367\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.002336, T: 56892, Avg. loss: 0.005580\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000868, T: 113784, Avg. loss: 0.005372\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.001234, T: 170676, Avg. loss: 0.005375\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.001087, T: 227568, Avg. loss: 0.005374\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000698, T: 284460, Avg. loss: 0.005357\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000820, T: 341352, Avg. loss: 0.005383\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000640, T: 56892, Avg. loss: 0.005447\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000055, T: 113784, Avg. loss: 0.005377\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000033, T: 170676, Avg. loss: 0.005361\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000694, T: 227568, Avg. loss: 0.005370\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000303, T: 284460, Avg. loss: 0.005395\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000106, T: 341352, Avg. loss: 0.005379\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000823, T: 56892, Avg. loss: 0.013598\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000553, T: 113784, Avg. loss: 0.005154\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000200, T: 170676, Avg. loss: 0.005176\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000188, T: 227568, Avg. loss: 0.005184\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000127, T: 284460, Avg. loss: 0.005160\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000173, T: 341352, Avg. loss: 0.005176\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000081, T: 398244, Avg. loss: 0.005153\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7.82, NNZs: 1, Bias: -0.000128, T: 56892, Avg. loss: 0.009829\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 7.90, NNZs: 1, Bias: -0.000488, T: 113784, Avg. loss: 0.006195\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 7.95, NNZs: 1, Bias: 0.000310, T: 170676, Avg. loss: 0.006241\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 7.98, NNZs: 1, Bias: 0.000304, T: 227568, Avg. loss: 0.006204\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 8.00, NNZs: 1, Bias: 0.000235, T: 284460, Avg. loss: 0.006217\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.03, NNZs: 1, Bias: 0.000113, T: 341352, Avg. loss: 0.006217\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 8.04, NNZs: 1, Bias: 0.000082, T: 398244, Avg. loss: 0.006227\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 5.36, NNZs: 1, Bias: 0.000373, T: 56892, Avg. loss: 0.006581\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 5.48, NNZs: 1, Bias: 0.000232, T: 113784, Avg. loss: 0.006237\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.55, NNZs: 1, Bias: -0.000235, T: 170676, Avg. loss: 0.006270\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.59, NNZs: 1, Bias: -0.000311, T: 227568, Avg. loss: 0.006249\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.63, NNZs: 1, Bias: -0.000457, T: 284460, Avg. loss: 0.006242\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5.66, NNZs: 1, Bias: -0.000243, T: 341352, Avg. loss: 0.006280\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7.58, NNZs: 1, Bias: -0.002422, T: 56892, Avg. loss: 0.007105\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 7.66, NNZs: 1, Bias: 0.000872, T: 113784, Avg. loss: 0.006261\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 7.71, NNZs: 1, Bias: 0.000909, T: 170676, Avg. loss: 0.006244\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 7.75, NNZs: 1, Bias: 0.000990, T: 227568, Avg. loss: 0.006255\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.77, NNZs: 1, Bias: 0.001062, T: 284460, Avg. loss: 0.006257\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 7.79, NNZs: 1, Bias: 0.000714, T: 341352, Avg. loss: 0.006228\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 13.06, NNZs: 1, Bias: -0.001183, T: 56892, Avg. loss: 0.026712\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 13.10, NNZs: 1, Bias: -0.000734, T: 113784, Avg. loss: 0.006257\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 13.13, NNZs: 1, Bias: -0.001083, T: 170676, Avg. loss: 0.006257\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 13.15, NNZs: 1, Bias: -0.000802, T: 227568, Avg. loss: 0.006250\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 13.17, NNZs: 1, Bias: -0.000349, T: 284460, Avg. loss: 0.006265\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 13.18, NNZs: 1, Bias: -0.000199, T: 341352, Avg. loss: 0.006256\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 13.19, NNZs: 1, Bias: -0.000097, T: 398244, Avg. loss: 0.006257\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4.39, NNZs: 1, Bias: -0.000331, T: 56892, Avg. loss: 0.006247\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.53, NNZs: 1, Bias: 0.000581, T: 113784, Avg. loss: 0.006062\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.61, NNZs: 1, Bias: 0.000001, T: 170676, Avg. loss: 0.006027\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.66, NNZs: 1, Bias: -0.000309, T: 227568, Avg. loss: 0.006063\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4.70, NNZs: 1, Bias: -0.000151, T: 284460, Avg. loss: 0.006048\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.74, NNZs: 1, Bias: -0.000128, T: 341352, Avg. loss: 0.006032\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001534, T: 56892, Avg. loss: 0.005616\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000229, T: 113784, Avg. loss: 0.005447\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000368, T: 170676, Avg. loss: 0.005464\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000663, T: 227568, Avg. loss: 0.005430\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000211, T: 284460, Avg. loss: 0.005494\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000066, T: 341352, Avg. loss: 0.005448\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001443, T: 56892, Avg. loss: 0.009064\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000689, T: 113784, Avg. loss: 0.005512\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000355, T: 170676, Avg. loss: 0.005484\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000577, T: 227568, Avg. loss: 0.005487\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000023, T: 284460, Avg. loss: 0.005498\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000221, T: 341352, Avg. loss: 0.005493\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000368, T: 398244, Avg. loss: 0.005489\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001995, T: 56892, Avg. loss: 0.005583\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000832, T: 113784, Avg. loss: 0.005490\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000838, T: 170676, Avg. loss: 0.005484\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001223, T: 227568, Avg. loss: 0.005475\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000658, T: 284460, Avg. loss: 0.005498\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000808, T: 341352, Avg. loss: 0.005491\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000125, T: 56892, Avg. loss: 0.042152\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001027, T: 113784, Avg. loss: 0.005470\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000112, T: 170676, Avg. loss: 0.005502\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000122, T: 227568, Avg. loss: 0.005485\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000125, T: 284460, Avg. loss: 0.005514\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000133, T: 341352, Avg. loss: 0.005509\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000147, T: 398244, Avg. loss: 0.005478\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000671, T: 56892, Avg. loss: 0.005421\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001410, T: 113784, Avg. loss: 0.005292\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000427, T: 170676, Avg. loss: 0.005283\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000500, T: 227568, Avg. loss: 0.005290\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000050, T: 284460, Avg. loss: 0.005278\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000034, T: 341352, Avg. loss: 0.005288\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.018962, T: 56892, Avg. loss: 0.011047\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.020634, T: 113784, Avg. loss: 0.010851\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.020093, T: 170676, Avg. loss: 0.010869\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.020159, T: 227568, Avg. loss: 0.010873\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.020204, T: 284460, Avg. loss: 0.010886\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.020211, T: 341352, Avg. loss: 0.010875\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.018987, T: 56892, Avg. loss: 0.011225\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020241, T: 113784, Avg. loss: 0.010946\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020761, T: 170676, Avg. loss: 0.010996\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020926, T: 227568, Avg. loss: 0.010968\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020638, T: 284460, Avg. loss: 0.010963\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020667, T: 341352, Avg. loss: 0.010987\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.019587, T: 56892, Avg. loss: 0.011061\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.018720, T: 113784, Avg. loss: 0.010929\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.019005, T: 170676, Avg. loss: 0.010918\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.019158, T: 227568, Avg. loss: 0.010927\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.019121, T: 284460, Avg. loss: 0.010931\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.019062, T: 341352, Avg. loss: 0.010945\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.021550, T: 56892, Avg. loss: 0.011010\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.021214, T: 113784, Avg. loss: 0.010958\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020688, T: 170676, Avg. loss: 0.010975\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020764, T: 227568, Avg. loss: 0.010987\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020806, T: 284460, Avg. loss: 0.010945\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020748, T: 341352, Avg. loss: 0.010961\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.017165, T: 56892, Avg. loss: 0.010952\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.020179, T: 113784, Avg. loss: 0.010858\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.020380, T: 170676, Avg. loss: 0.010878\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.020346, T: 227568, Avg. loss: 0.010881\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.020292, T: 284460, Avg. loss: 0.010867\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.020297, T: 341352, Avg. loss: 0.010886\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.38, NNZs: 0, Bias: -0.007229, T: 56892, Avg. loss: 0.081832\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.38, NNZs: 0, Bias: -0.009064, T: 113784, Avg. loss: 0.081823\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.38, NNZs: 0, Bias: -0.009878, T: 170676, Avg. loss: 0.081823\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.38, NNZs: 0, Bias: -0.010273, T: 227568, Avg. loss: 0.081823\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.38, NNZs: 0, Bias: -0.010570, T: 284460, Avg. loss: 0.081823\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.38, NNZs: 0, Bias: -0.010782, T: 341352, Avg. loss: 0.081822\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 6 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.46, NNZs: 0, Bias: -0.004795, T: 56892, Avg. loss: 0.081681\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.46, NNZs: 0, Bias: -0.007887, T: 113784, Avg. loss: 0.081658\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.46, NNZs: 0, Bias: -0.009223, T: 170676, Avg. loss: 0.081657\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.46, NNZs: 0, Bias: -0.009929, T: 227568, Avg. loss: 0.081657\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.46, NNZs: 0, Bias: -0.010306, T: 284460, Avg. loss: 0.081657\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.46, NNZs: 0, Bias: -0.010615, T: 341352, Avg. loss: 0.081657\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.38, NNZs: 0, Bias: -0.010136, T: 56892, Avg. loss: 0.081824\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.38, NNZs: 0, Bias: -0.010746, T: 113784, Avg. loss: 0.081816\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.38, NNZs: 0, Bias: -0.010819, T: 170676, Avg. loss: 0.081815\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.38, NNZs: 0, Bias: -0.010862, T: 227568, Avg. loss: 0.081815\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.38, NNZs: 0, Bias: -0.010949, T: 284460, Avg. loss: 0.081815\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.38, NNZs: 0, Bias: -0.010989, T: 341352, Avg. loss: 0.081815\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.40, NNZs: 0, Bias: -0.008309, T: 56892, Avg. loss: 0.081753\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.40, NNZs: 0, Bias: -0.010854, T: 113784, Avg. loss: 0.081731\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.40, NNZs: 0, Bias: -0.011877, T: 170676, Avg. loss: 0.081730\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.40, NNZs: 0, Bias: -0.012500, T: 227568, Avg. loss: 0.081730\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.40, NNZs: 0, Bias: -0.012935, T: 284460, Avg. loss: 0.081729\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.40, NNZs: 0, Bias: -0.013254, T: 341352, Avg. loss: 0.081729\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.61, NNZs: 0, Bias: -0.014690, T: 56892, Avg. loss: 0.081697\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.61, NNZs: 0, Bias: -0.015720, T: 113784, Avg. loss: 0.081686\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.61, NNZs: 0, Bias: -0.016003, T: 170676, Avg. loss: 0.081685\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.61, NNZs: 0, Bias: -0.016144, T: 227568, Avg. loss: 0.081685\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.61, NNZs: 0, Bias: -0.016235, T: 284460, Avg. loss: 0.081685\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.61, NNZs: 0, Bias: -0.016279, T: 341352, Avg. loss: 0.081685\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.021612, T: 56892, Avg. loss: 0.012681\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020348, T: 113784, Avg. loss: 0.012658\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020357, T: 170676, Avg. loss: 0.012651\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020248, T: 227568, Avg. loss: 0.012668\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020164, T: 284460, Avg. loss: 0.012618\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020228, T: 341352, Avg. loss: 0.012631\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.89, NNZs: 1, Bias: -0.021156, T: 56892, Avg. loss: 0.012827\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.021191, T: 113784, Avg. loss: 0.012757\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020764, T: 170676, Avg. loss: 0.012771\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020591, T: 227568, Avg. loss: 0.012745\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020634, T: 284460, Avg. loss: 0.012763\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020522, T: 341352, Avg. loss: 0.012748\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.019735, T: 56892, Avg. loss: 0.012917\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.019037, T: 113784, Avg. loss: 0.012659\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.018866, T: 170676, Avg. loss: 0.012717\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.018905, T: 227568, Avg. loss: 0.012703\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.018874, T: 284460, Avg. loss: 0.012713\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.018884, T: 341352, Avg. loss: 0.012698\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.021662, T: 56892, Avg. loss: 0.012725\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020427, T: 113784, Avg. loss: 0.012769\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020889, T: 170676, Avg. loss: 0.012721\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.021051, T: 227568, Avg. loss: 0.012713\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020876, T: 284460, Avg. loss: 0.012723\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020866, T: 341352, Avg. loss: 0.012726\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.019775, T: 56892, Avg. loss: 0.012791\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020591, T: 113784, Avg. loss: 0.012635\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020239, T: 170676, Avg. loss: 0.012616\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020233, T: 227568, Avg. loss: 0.012639\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020145, T: 284460, Avg. loss: 0.012666\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020187, T: 341352, Avg. loss: 0.012638\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028504, T: 56892, Avg. loss: 0.003735\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028683, T: 113784, Avg. loss: 0.003357\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028860, T: 170676, Avg. loss: 0.003355\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029216, T: 227568, Avg. loss: 0.003382\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029279, T: 284460, Avg. loss: 0.003361\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028825, T: 341352, Avg. loss: 0.003363\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.027770, T: 56892, Avg. loss: 0.003828\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029204, T: 113784, Avg. loss: 0.003509\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028051, T: 170676, Avg. loss: 0.003494\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.027577, T: 227568, Avg. loss: 0.003486\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028330, T: 284460, Avg. loss: 0.003495\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028162, T: 341352, Avg. loss: 0.003494\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029782, T: 56892, Avg. loss: 0.003806\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029503, T: 113784, Avg. loss: 0.003403\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029164, T: 170676, Avg. loss: 0.003391\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029938, T: 227568, Avg. loss: 0.003412\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030874, T: 284460, Avg. loss: 0.003396\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.031006, T: 341352, Avg. loss: 0.003409\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.026186, T: 56892, Avg. loss: 0.003845\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.025335, T: 113784, Avg. loss: 0.003465\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030153, T: 170676, Avg. loss: 0.003522\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.027471, T: 227568, Avg. loss: 0.003470\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.027857, T: 284460, Avg. loss: 0.003473\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028115, T: 341352, Avg. loss: 0.003488\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028977, T: 56892, Avg. loss: 0.003156\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.031150, T: 113784, Avg. loss: 0.002909\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.032109, T: 170676, Avg. loss: 0.002905\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030769, T: 227568, Avg. loss: 0.002890\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030397, T: 284460, Avg. loss: 0.002896\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030765, T: 341352, Avg. loss: 0.002922\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4.48, NNZs: 1, Bias: 0.029232, T: 56892, Avg. loss: 0.003844\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.63, NNZs: 1, Bias: 0.029763, T: 113784, Avg. loss: 0.003498\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.71, NNZs: 1, Bias: 0.029388, T: 170676, Avg. loss: 0.003487\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.77, NNZs: 1, Bias: 0.027198, T: 227568, Avg. loss: 0.003455\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4.81, NNZs: 1, Bias: 0.027835, T: 284460, Avg. loss: 0.003474\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.85, NNZs: 1, Bias: 0.029643, T: 341352, Avg. loss: 0.003509\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4.71, NNZs: 1, Bias: 0.026262, T: 56892, Avg. loss: 0.004005\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.85, NNZs: 1, Bias: 0.027489, T: 113784, Avg. loss: 0.003619\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.93, NNZs: 1, Bias: 0.026233, T: 170676, Avg. loss: 0.003614\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.98, NNZs: 1, Bias: 0.027889, T: 227568, Avg. loss: 0.003636\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.03, NNZs: 1, Bias: 0.027223, T: 284460, Avg. loss: 0.003600\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5.06, NNZs: 1, Bias: 0.027204, T: 341352, Avg. loss: 0.003605\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4.51, NNZs: 1, Bias: 0.031818, T: 56892, Avg. loss: 0.003946\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.65, NNZs: 1, Bias: 0.030240, T: 113784, Avg. loss: 0.003508\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.73, NNZs: 1, Bias: 0.030394, T: 170676, Avg. loss: 0.003497\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.79, NNZs: 1, Bias: 0.030172, T: 227568, Avg. loss: 0.003518\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4.83, NNZs: 1, Bias: 0.029922, T: 284460, Avg. loss: 0.003524\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.87, NNZs: 1, Bias: 0.028924, T: 341352, Avg. loss: 0.003475\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4.50, NNZs: 1, Bias: 0.027823, T: 56892, Avg. loss: 0.003983\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.64, NNZs: 1, Bias: 0.027703, T: 113784, Avg. loss: 0.003599\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.73, NNZs: 1, Bias: 0.028691, T: 170676, Avg. loss: 0.003611\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 4.78, NNZs: 1, Bias: 0.028336, T: 227568, Avg. loss: 0.003587\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4.83, NNZs: 1, Bias: 0.027972, T: 284460, Avg. loss: 0.003599\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.86, NNZs: 1, Bias: 0.028313, T: 341352, Avg. loss: 0.003589\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4.58, NNZs: 1, Bias: 0.030360, T: 56892, Avg. loss: 0.003311\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.73, NNZs: 1, Bias: 0.029981, T: 113784, Avg. loss: 0.003018\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.81, NNZs: 1, Bias: 0.028631, T: 170676, Avg. loss: 0.003020\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.86, NNZs: 1, Bias: 0.029671, T: 227568, Avg. loss: 0.003027\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4.91, NNZs: 1, Bias: 0.029517, T: 284460, Avg. loss: 0.003013\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.94, NNZs: 1, Bias: 0.028830, T: 341352, Avg. loss: 0.003023\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.031252, T: 56892, Avg. loss: 0.003708\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.028459, T: 113784, Avg. loss: 0.003379\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.029871, T: 170676, Avg. loss: 0.003401\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.029987, T: 227568, Avg. loss: 0.003376\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.029565, T: 284460, Avg. loss: 0.003384\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.029410, T: 341352, Avg. loss: 0.003375\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.029843, T: 56892, Avg. loss: 0.003914\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030426, T: 113784, Avg. loss: 0.003532\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.027672, T: 170676, Avg. loss: 0.003497\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.028332, T: 227568, Avg. loss: 0.003501\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.027982, T: 284460, Avg. loss: 0.003518\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.027770, T: 341352, Avg. loss: 0.003503\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.029172, T: 56892, Avg. loss: 0.003711\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.029600, T: 113784, Avg. loss: 0.003425\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030641, T: 170676, Avg. loss: 0.003413\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030109, T: 227568, Avg. loss: 0.003425\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.032147, T: 284460, Avg. loss: 0.003426\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030294, T: 341352, Avg. loss: 0.003394\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.031040, T: 56892, Avg. loss: 0.003800\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.027230, T: 113784, Avg. loss: 0.003498\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.028251, T: 170676, Avg. loss: 0.003509\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.028517, T: 227568, Avg. loss: 0.003502\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.028778, T: 284460, Avg. loss: 0.003502\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.029280, T: 341352, Avg. loss: 0.003491\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.031950, T: 56892, Avg. loss: 0.003277\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.028849, T: 113784, Avg. loss: 0.002902\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.028723, T: 170676, Avg. loss: 0.002909\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030632, T: 227568, Avg. loss: 0.002932\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030207, T: 284460, Avg. loss: 0.002931\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.029878, T: 341352, Avg. loss: 0.002900\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.91, NNZs: 1, Bias: -0.001632, T: 56892, Avg. loss: 0.006826\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000448, T: 113784, Avg. loss: 0.005345\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.001425, T: 170676, Avg. loss: 0.005336\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000266, T: 227568, Avg. loss: 0.005345\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.003162, T: 284460, Avg. loss: 0.005336\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.003692, T: 341352, Avg. loss: 0.005350\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000046, T: 398244, Avg. loss: 0.005330\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000125, T: 56892, Avg. loss: 0.006856\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000454, T: 113784, Avg. loss: 0.005379\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000091, T: 170676, Avg. loss: 0.005379\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000649, T: 227568, Avg. loss: 0.005374\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000093, T: 284460, Avg. loss: 0.005378\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000103, T: 341352, Avg. loss: 0.005376\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.002033, T: 398244, Avg. loss: 0.005377\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.002857, T: 56892, Avg. loss: 0.006821\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.001469, T: 113784, Avg. loss: 0.005364\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.001593, T: 170676, Avg. loss: 0.005377\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.001478, T: 227568, Avg. loss: 0.005373\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.001040, T: 284460, Avg. loss: 0.005374\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.001208, T: 341352, Avg. loss: 0.005381\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000128, T: 398244, Avg. loss: 0.005367\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000783, T: 56892, Avg. loss: 0.006865\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.91, NNZs: 1, Bias: 0.000944, T: 113784, Avg. loss: 0.005375\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.002058, T: 170676, Avg. loss: 0.005372\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.001953, T: 227568, Avg. loss: 0.005383\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000784, T: 284460, Avg. loss: 0.005378\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000060, T: 341352, Avg. loss: 0.005379\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000905, T: 398244, Avg. loss: 0.005380\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.000834, T: 56892, Avg. loss: 0.006584\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.001178, T: 113784, Avg. loss: 0.005169\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.000238, T: 170676, Avg. loss: 0.005169\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.001272, T: 227568, Avg. loss: 0.005175\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.003043, T: 284460, Avg. loss: 0.005174\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.003132, T: 341352, Avg. loss: 0.005157\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.001085, T: 398244, Avg. loss: 0.005173\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.07, NNZs: 1, Bias: -0.000687, T: 56892, Avg. loss: 0.007907\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.93, NNZs: 1, Bias: -0.001211, T: 113784, Avg. loss: 0.006223\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.56, NNZs: 1, Bias: 0.000788, T: 170676, Avg. loss: 0.006213\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.06, NNZs: 1, Bias: 0.003787, T: 227568, Avg. loss: 0.006223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.49, NNZs: 1, Bias: -0.000228, T: 284460, Avg. loss: 0.006213\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5.87, NNZs: 1, Bias: -0.000622, T: 341352, Avg. loss: 0.006222\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 6.21, NNZs: 1, Bias: -0.003478, T: 398244, Avg. loss: 0.006213\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.08, NNZs: 1, Bias: -0.000799, T: 56892, Avg. loss: 0.007907\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.93, NNZs: 1, Bias: 0.003486, T: 113784, Avg. loss: 0.006257\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.56, NNZs: 1, Bias: -0.000149, T: 170676, Avg. loss: 0.006261\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.06, NNZs: 1, Bias: 0.002609, T: 227568, Avg. loss: 0.006267\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.49, NNZs: 1, Bias: -0.002133, T: 284460, Avg. loss: 0.006248\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5.87, NNZs: 1, Bias: -0.001264, T: 341352, Avg. loss: 0.006263\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 6.21, NNZs: 1, Bias: -0.000793, T: 398244, Avg. loss: 0.006248\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.07, NNZs: 1, Bias: 0.000104, T: 56892, Avg. loss: 0.008064\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.93, NNZs: 1, Bias: -0.000321, T: 113784, Avg. loss: 0.006236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.55, NNZs: 1, Bias: -0.000809, T: 170676, Avg. loss: 0.006253\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.06, NNZs: 1, Bias: 0.001765, T: 227568, Avg. loss: 0.006248\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.49, NNZs: 1, Bias: -0.001503, T: 284460, Avg. loss: 0.006239\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5.87, NNZs: 1, Bias: 0.000516, T: 341352, Avg. loss: 0.006249\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 6.21, NNZs: 1, Bias: 0.000031, T: 398244, Avg. loss: 0.006249\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.07, NNZs: 1, Bias: -0.003538, T: 56892, Avg. loss: 0.007967\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.93, NNZs: 1, Bias: -0.001486, T: 113784, Avg. loss: 0.006267\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.56, NNZs: 1, Bias: -0.001495, T: 170676, Avg. loss: 0.006259\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.06, NNZs: 1, Bias: 0.001933, T: 227568, Avg. loss: 0.006260\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.49, NNZs: 1, Bias: -0.001630, T: 284460, Avg. loss: 0.006246\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5.87, NNZs: 1, Bias: -0.000305, T: 341352, Avg. loss: 0.006259\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 6.21, NNZs: 1, Bias: 0.001498, T: 398244, Avg. loss: 0.006263\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.07, NNZs: 1, Bias: 0.000539, T: 56892, Avg. loss: 0.007759\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.93, NNZs: 1, Bias: 0.000820, T: 113784, Avg. loss: 0.006046\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.56, NNZs: 1, Bias: -0.000586, T: 170676, Avg. loss: 0.006049\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.06, NNZs: 1, Bias: -0.001418, T: 227568, Avg. loss: 0.006050\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.49, NNZs: 1, Bias: 0.000893, T: 284460, Avg. loss: 0.006053\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5.87, NNZs: 1, Bias: -0.001439, T: 341352, Avg. loss: 0.006044\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 6.21, NNZs: 1, Bias: -0.001903, T: 398244, Avg. loss: 0.006047\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002612, T: 56892, Avg. loss: 0.006991\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001895, T: 113784, Avg. loss: 0.005459\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000085, T: 170676, Avg. loss: 0.005462\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000104, T: 227568, Avg. loss: 0.005455\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001482, T: 284460, Avg. loss: 0.005458\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000999, T: 341352, Avg. loss: 0.005453\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000466, T: 398244, Avg. loss: 0.005462\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003595, T: 56892, Avg. loss: 0.007023\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000343, T: 113784, Avg. loss: 0.005499\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000406, T: 170676, Avg. loss: 0.005490\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000909, T: 227568, Avg. loss: 0.005490\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001632, T: 284460, Avg. loss: 0.005503\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000353, T: 341352, Avg. loss: 0.005482\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000582, T: 398244, Avg. loss: 0.005497\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000966, T: 56892, Avg. loss: 0.006966\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.003797, T: 113784, Avg. loss: 0.005487\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000448, T: 170676, Avg. loss: 0.005484\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000583, T: 227568, Avg. loss: 0.005492\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000076, T: 284460, Avg. loss: 0.005491\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.99, NNZs: 1, Bias: -0.000838, T: 341352, Avg. loss: 0.005478\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000190, T: 398244, Avg. loss: 0.005501\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.002374, T: 56892, Avg. loss: 0.007031\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000864, T: 113784, Avg. loss: 0.005492\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000044, T: 170676, Avg. loss: 0.005497\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000565, T: 227568, Avg. loss: 0.005489\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000990, T: 284460, Avg. loss: 0.005491\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000254, T: 341352, Avg. loss: 0.005505\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001300, T: 398244, Avg. loss: 0.005492\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000600, T: 56892, Avg. loss: 0.006814\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002131, T: 113784, Avg. loss: 0.005291\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001483, T: 170676, Avg. loss: 0.005289\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000858, T: 227568, Avg. loss: 0.005276\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000335, T: 284460, Avg. loss: 0.005291\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000444, T: 341352, Avg. loss: 0.005292\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000979, T: 398244, Avg. loss: 0.005288\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.017737, T: 56892, Avg. loss: 0.019363\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.020713, T: 113784, Avg. loss: 0.010928\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.022620, T: 170676, Avg. loss: 0.010842\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.015826, T: 227568, Avg. loss: 0.010848\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.021820, T: 284460, Avg. loss: 0.010920\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.018858, T: 341352, Avg. loss: 0.010913\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.83, NNZs: 1, Bias: -0.022588, T: 398244, Avg. loss: 0.010902\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.018730, T: 56892, Avg. loss: 0.019484\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.017559, T: 113784, Avg. loss: 0.010941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.021616, T: 170676, Avg. loss: 0.011029\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.022029, T: 227568, Avg. loss: 0.011002\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.018191, T: 284460, Avg. loss: 0.011002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.017417, T: 341352, Avg. loss: 0.010945\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.021977, T: 398244, Avg. loss: 0.011046\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.017984, T: 56892, Avg. loss: 0.019471\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.017579, T: 113784, Avg. loss: 0.010892\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020083, T: 170676, Avg. loss: 0.010885\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.021993, T: 227568, Avg. loss: 0.011053\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.019637, T: 284460, Avg. loss: 0.010902\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020264, T: 341352, Avg. loss: 0.010897\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.021445, T: 398244, Avg. loss: 0.011002\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.019247, T: 56892, Avg. loss: 0.019384\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.021085, T: 113784, Avg. loss: 0.011011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.021265, T: 170676, Avg. loss: 0.010972\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.021226, T: 227568, Avg. loss: 0.010913\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.019547, T: 284460, Avg. loss: 0.010989\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020630, T: 341352, Avg. loss: 0.010987\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.021265, T: 398244, Avg. loss: 0.010965\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.82, NNZs: 1, Bias: -0.018704, T: 56892, Avg. loss: 0.019303\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.018065, T: 113784, Avg. loss: 0.010914\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.019349, T: 170676, Avg. loss: 0.010845\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.021840, T: 227568, Avg. loss: 0.010844\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.021070, T: 284460, Avg. loss: 0.010922\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.83, NNZs: 1, Bias: -0.022507, T: 341352, Avg. loss: 0.010931\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.020253, T: 398244, Avg. loss: 0.010794\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.02, NNZs: 0, Bias: -0.018276, T: 56892, Avg. loss: 0.081824\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.007386, T: 113784, Avg. loss: 0.081823\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.015274, T: 170676, Avg. loss: 0.081824\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.014899, T: 227568, Avg. loss: 0.081824\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.006672, T: 284460, Avg. loss: 0.081822\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.011574, T: 341352, Avg. loss: 0.081824\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 6 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.02, NNZs: 0, Bias: -0.018718, T: 56892, Avg. loss: 0.081661\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.008278, T: 113784, Avg. loss: 0.081658\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.013711, T: 170676, Avg. loss: 0.081659\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.007082, T: 227568, Avg. loss: 0.081657\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.011778, T: 284460, Avg. loss: 0.081659\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.006479, T: 341352, Avg. loss: 0.081656\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 6 epochs took 0.07 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.02, NNZs: 0, Bias: -0.004384, T: 56892, Avg. loss: 0.081818\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.008654, T: 113784, Avg. loss: 0.081818\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.011740, T: 170676, Avg. loss: 0.081817\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.012064, T: 227568, Avg. loss: 0.081817\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.013628, T: 284460, Avg. loss: 0.081817\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.011562, T: 341352, Avg. loss: 0.081817\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 6 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.02, NNZs: 0, Bias: -0.017553, T: 56892, Avg. loss: 0.081734\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.015226, T: 113784, Avg. loss: 0.081732\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.017424, T: 170676, Avg. loss: 0.081731\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.017103, T: 227568, Avg. loss: 0.081731\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.013264, T: 284460, Avg. loss: 0.081731\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.013412, T: 341352, Avg. loss: 0.081731\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 6 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.02, NNZs: 0, Bias: -0.012463, T: 56892, Avg. loss: 0.081690\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.019827, T: 113784, Avg. loss: 0.081687\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.019540, T: 170676, Avg. loss: 0.081687\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.019343, T: 227568, Avg. loss: 0.081687\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.018560, T: 284460, Avg. loss: 0.081687\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.03, NNZs: 0, Bias: -0.013859, T: 341352, Avg. loss: 0.081686\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 6 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.021909, T: 56892, Avg. loss: 0.022997\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.016339, T: 113784, Avg. loss: 0.012715\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.021822, T: 170676, Avg. loss: 0.012639\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.022043, T: 227568, Avg. loss: 0.012635\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.024277, T: 284460, Avg. loss: 0.012661\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.022592, T: 341352, Avg. loss: 0.012630\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.023199, T: 398244, Avg. loss: 0.012603\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.017812, T: 56892, Avg. loss: 0.023085\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.015370, T: 113784, Avg. loss: 0.012795\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.017114, T: 170676, Avg. loss: 0.012750\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.026440, T: 227568, Avg. loss: 0.012771\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.018644, T: 284460, Avg. loss: 0.012799\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.018415, T: 341352, Avg. loss: 0.012665\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.019866, T: 398244, Avg. loss: 0.012796\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.023896, T: 56892, Avg. loss: 0.023023\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.014197, T: 113784, Avg. loss: 0.012836\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.018774, T: 170676, Avg. loss: 0.012750\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.016739, T: 227568, Avg. loss: 0.012682\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.022411, T: 284460, Avg. loss: 0.012666\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.017931, T: 341352, Avg. loss: 0.012650\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020251, T: 398244, Avg. loss: 0.012725\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.025464, T: 56892, Avg. loss: 0.023071\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020803, T: 113784, Avg. loss: 0.012786\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.022138, T: 170676, Avg. loss: 0.012772\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.020630, T: 227568, Avg. loss: 0.012658\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.021869, T: 284460, Avg. loss: 0.012840\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.021009, T: 341352, Avg. loss: 0.012732\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.019469, T: 398244, Avg. loss: 0.012684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.023871, T: 56892, Avg. loss: 0.022926\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.018710, T: 113784, Avg. loss: 0.012801\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.019259, T: 170676, Avg. loss: 0.012690\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.015700, T: 227568, Avg. loss: 0.012616\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.024619, T: 284460, Avg. loss: 0.012646\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.022038, T: 341352, Avg. loss: 0.012685\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.019479, T: 398244, Avg. loss: 0.012599\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.027584, T: 56892, Avg. loss: 0.005443\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030027, T: 113784, Avg. loss: 0.003394\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.026038, T: 170676, Avg. loss: 0.003355\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030855, T: 227568, Avg. loss: 0.003371\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.027316, T: 284460, Avg. loss: 0.003372\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029477, T: 341352, Avg. loss: 0.003379\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.031861, T: 398244, Avg. loss: 0.003375\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029459, T: 56892, Avg. loss: 0.005622\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.027677, T: 113784, Avg. loss: 0.003502\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.026277, T: 170676, Avg. loss: 0.003517\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.025976, T: 227568, Avg. loss: 0.003498\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028274, T: 284460, Avg. loss: 0.003500\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.026629, T: 341352, Avg. loss: 0.003494\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028692, T: 398244, Avg. loss: 0.003499\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.94, NNZs: 1, Bias: 0.027024, T: 56892, Avg. loss: 0.005564\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.031328, T: 113784, Avg. loss: 0.003432\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030235, T: 170676, Avg. loss: 0.003418\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.033438, T: 227568, Avg. loss: 0.003410\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.031101, T: 284460, Avg. loss: 0.003418\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.033130, T: 341352, Avg. loss: 0.003419\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030238, T: 398244, Avg. loss: 0.003408\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030686, T: 56892, Avg. loss: 0.005594\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029271, T: 113784, Avg. loss: 0.003497\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030704, T: 170676, Avg. loss: 0.003481\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.027358, T: 227568, Avg. loss: 0.003497\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029162, T: 284460, Avg. loss: 0.003504\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029559, T: 341352, Avg. loss: 0.003488\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.029125, T: 398244, Avg. loss: 0.003497\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.024560, T: 56892, Avg. loss: 0.005090\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028639, T: 113784, Avg. loss: 0.002931\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.027782, T: 170676, Avg. loss: 0.002883\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030652, T: 227568, Avg. loss: 0.002931\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.028019, T: 284460, Avg. loss: 0.002876\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.030581, T: 341352, Avg. loss: 0.002907\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.030559, T: 398244, Avg. loss: 0.002891\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.18, NNZs: 1, Bias: 0.031430, T: 56892, Avg. loss: 0.005817\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 4.06, NNZs: 1, Bias: 0.031031, T: 113784, Avg. loss: 0.003495\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.70, NNZs: 1, Bias: 0.030828, T: 170676, Avg. loss: 0.003492\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.21, NNZs: 1, Bias: 0.027504, T: 227568, Avg. loss: 0.003464\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.65, NNZs: 1, Bias: 0.028026, T: 284460, Avg. loss: 0.003466\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 6.04, NNZs: 1, Bias: 0.027249, T: 341352, Avg. loss: 0.003464\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 6.40, NNZs: 1, Bias: 0.031690, T: 398244, Avg. loss: 0.003490\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.18, NNZs: 1, Bias: 0.032277, T: 56892, Avg. loss: 0.005975\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.06, NNZs: 1, Bias: 0.027257, T: 113784, Avg. loss: 0.003609\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.69, NNZs: 1, Bias: 0.022905, T: 170676, Avg. loss: 0.003604\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.21, NNZs: 1, Bias: 0.029684, T: 227568, Avg. loss: 0.003607\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.65, NNZs: 1, Bias: 0.024840, T: 284460, Avg. loss: 0.003609\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 6.05, NNZs: 1, Bias: 0.030358, T: 341352, Avg. loss: 0.003606\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 6.40, NNZs: 1, Bias: 0.029480, T: 398244, Avg. loss: 0.003612\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.18, NNZs: 1, Bias: 0.031120, T: 56892, Avg. loss: 0.005853\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.06, NNZs: 1, Bias: 0.027648, T: 113784, Avg. loss: 0.003526\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.70, NNZs: 1, Bias: 0.030318, T: 170676, Avg. loss: 0.003525\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.21, NNZs: 1, Bias: 0.027536, T: 227568, Avg. loss: 0.003513\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.66, NNZs: 1, Bias: 0.032414, T: 284460, Avg. loss: 0.003532\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 6.05, NNZs: 1, Bias: 0.028993, T: 341352, Avg. loss: 0.003519\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 6.40, NNZs: 1, Bias: 0.036980, T: 398244, Avg. loss: 0.003529\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.18, NNZs: 1, Bias: 0.026064, T: 56892, Avg. loss: 0.005970\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.06, NNZs: 1, Bias: 0.029157, T: 113784, Avg. loss: 0.003593\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.70, NNZs: 1, Bias: 0.030561, T: 170676, Avg. loss: 0.003591\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 5.21, NNZs: 1, Bias: 0.027652, T: 227568, Avg. loss: 0.003626\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.65, NNZs: 1, Bias: 0.025522, T: 284460, Avg. loss: 0.003606\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 6.05, NNZs: 1, Bias: 0.028953, T: 341352, Avg. loss: 0.003609\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 6.40, NNZs: 1, Bias: 0.027333, T: 398244, Avg. loss: 0.003594\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.18, NNZs: 1, Bias: 0.024172, T: 56892, Avg. loss: 0.005219\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.06, NNZs: 1, Bias: 0.025551, T: 113784, Avg. loss: 0.003019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.70, NNZs: 1, Bias: 0.026412, T: 170676, Avg. loss: 0.003014\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.21, NNZs: 1, Bias: 0.029358, T: 227568, Avg. loss: 0.003043\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.66, NNZs: 1, Bias: 0.030660, T: 284460, Avg. loss: 0.003026\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 6.05, NNZs: 1, Bias: 0.027706, T: 341352, Avg. loss: 0.003012\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 6.40, NNZs: 1, Bias: 0.025782, T: 398244, Avg. loss: 0.003019\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.027964, T: 56892, Avg. loss: 0.005493\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030350, T: 113784, Avg. loss: 0.003388\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.027788, T: 170676, Avg. loss: 0.003389\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.029267, T: 227568, Avg. loss: 0.003388\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030577, T: 284460, Avg. loss: 0.003366\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030106, T: 341352, Avg. loss: 0.003409\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.027690, T: 398244, Avg. loss: 0.003385\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.029967, T: 56892, Avg. loss: 0.005677\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.028650, T: 113784, Avg. loss: 0.003518\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030105, T: 170676, Avg. loss: 0.003515\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.023587, T: 227568, Avg. loss: 0.003504\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.029905, T: 284460, Avg. loss: 0.003535\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.029008, T: 341352, Avg. loss: 0.003522\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.04, NNZs: 1, Bias: 0.031375, T: 398244, Avg. loss: 0.003521\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030340, T: 56892, Avg. loss: 0.005576\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.033037, T: 113784, Avg. loss: 0.003431\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.029794, T: 170676, Avg. loss: 0.003436\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.028449, T: 227568, Avg. loss: 0.003429\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.032437, T: 284460, Avg. loss: 0.003430\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.026547, T: 341352, Avg. loss: 0.003441\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.031058, T: 398244, Avg. loss: 0.003432\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.025177, T: 56892, Avg. loss: 0.005730\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.026818, T: 113784, Avg. loss: 0.003510\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.027503, T: 170676, Avg. loss: 0.003493\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.027115, T: 227568, Avg. loss: 0.003526\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.025454, T: 284460, Avg. loss: 0.003522\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.026830, T: 341352, Avg. loss: 0.003514\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.031673, T: 398244, Avg. loss: 0.003504\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.024533, T: 56892, Avg. loss: 0.005125\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.025925, T: 113784, Avg. loss: 0.002932\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.029240, T: 170676, Avg. loss: 0.002936\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.032932, T: 227568, Avg. loss: 0.002933\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.027566, T: 284460, Avg. loss: 0.002933\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.03, NNZs: 1, Bias: 0.027663, T: 341352, Avg. loss: 0.002927\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030528, T: 398244, Avg. loss: 0.002934\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001462, T: 56892, Avg. loss: 0.001740\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.002046, T: 113784, Avg. loss: 0.001285\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001711, T: 170676, Avg. loss: 0.001285\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.002045, T: 227568, Avg. loss: 0.001286\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000924, T: 284460, Avg. loss: 0.001286\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001982, T: 341352, Avg. loss: 0.001285\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.003351, T: 56892, Avg. loss: 0.001766\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003448, T: 113784, Avg. loss: 0.001315\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001641, T: 170676, Avg. loss: 0.001315\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003512, T: 227568, Avg. loss: 0.001315\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.003999, T: 284460, Avg. loss: 0.001314\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004532, T: 341352, Avg. loss: 0.001315\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.004510, T: 56892, Avg. loss: 0.001761\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000333, T: 113784, Avg. loss: 0.001310\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.005183, T: 170676, Avg. loss: 0.001309\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.007669, T: 227568, Avg. loss: 0.001308\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.000227, T: 284460, Avg. loss: 0.001309\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001562, T: 341352, Avg. loss: 0.001310\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001559, T: 56892, Avg. loss: 0.001769\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.004395, T: 113784, Avg. loss: 0.001317\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.003282, T: 170676, Avg. loss: 0.001318\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001288, T: 227568, Avg. loss: 0.001318\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.000488, T: 284460, Avg. loss: 0.001317\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.004231, T: 341352, Avg. loss: 0.001317\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002328, T: 56892, Avg. loss: 0.001556\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.002760, T: 113784, Avg. loss: 0.001106\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.005873, T: 170676, Avg. loss: 0.001105\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.002169, T: 227568, Avg. loss: 0.001106\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000078, T: 284460, Avg. loss: 0.001105\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003339, T: 341352, Avg. loss: 0.001106\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.49, NNZs: 1, Bias: 0.001129, T: 56892, Avg. loss: 0.001740\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.84, NNZs: 1, Bias: -0.003149, T: 113784, Avg. loss: 0.001286\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.89, NNZs: 1, Bias: -0.003916, T: 170676, Avg. loss: 0.001286\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.78, NNZs: 1, Bias: -0.000903, T: 227568, Avg. loss: 0.001286\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.56, NNZs: 1, Bias: -0.004331, T: 284460, Avg. loss: 0.001286\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.27, NNZs: 1, Bias: 0.001082, T: 341352, Avg. loss: 0.001285\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.49, NNZs: 1, Bias: -0.000533, T: 56892, Avg. loss: 0.001776\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 4.84, NNZs: 1, Bias: 0.002073, T: 113784, Avg. loss: 0.001315\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.89, NNZs: 1, Bias: 0.004308, T: 170676, Avg. loss: 0.001316\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.78, NNZs: 1, Bias: -0.005425, T: 227568, Avg. loss: 0.001315\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.56, NNZs: 1, Bias: 0.003236, T: 284460, Avg. loss: 0.001315\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.27, NNZs: 1, Bias: 0.003605, T: 341352, Avg. loss: 0.001316\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.49, NNZs: 1, Bias: 0.000266, T: 56892, Avg. loss: 0.001769\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.84, NNZs: 1, Bias: -0.005016, T: 113784, Avg. loss: 0.001310\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.89, NNZs: 1, Bias: -0.003719, T: 170676, Avg. loss: 0.001311\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.78, NNZs: 1, Bias: -0.001895, T: 227568, Avg. loss: 0.001311\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.57, NNZs: 1, Bias: -0.006171, T: 284460, Avg. loss: 0.001311\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.28, NNZs: 1, Bias: 0.001658, T: 341352, Avg. loss: 0.001312\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.50, NNZs: 1, Bias: 0.000053, T: 56892, Avg. loss: 0.001777\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.84, NNZs: 1, Bias: -0.001485, T: 113784, Avg. loss: 0.001319\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.89, NNZs: 1, Bias: -0.000622, T: 170676, Avg. loss: 0.001319\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.78, NNZs: 1, Bias: 0.002766, T: 227568, Avg. loss: 0.001319\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.56, NNZs: 1, Bias: -0.001262, T: 284460, Avg. loss: 0.001319\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.27, NNZs: 1, Bias: -0.002817, T: 341352, Avg. loss: 0.001319\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.50, NNZs: 1, Bias: 0.001102, T: 56892, Avg. loss: 0.001563\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.84, NNZs: 1, Bias: -0.004137, T: 113784, Avg. loss: 0.001107\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.89, NNZs: 1, Bias: -0.000644, T: 170676, Avg. loss: 0.001106\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.78, NNZs: 1, Bias: 0.000705, T: 227568, Avg. loss: 0.001107\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.56, NNZs: 1, Bias: -0.002562, T: 284460, Avg. loss: 0.001106\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.28, NNZs: 1, Bias: 0.002018, T: 341352, Avg. loss: 0.001107\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.003741, T: 56892, Avg. loss: 0.001732\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.002017, T: 113784, Avg. loss: 0.001286\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000711, T: 170676, Avg. loss: 0.001285\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.005566, T: 227568, Avg. loss: 0.001284\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.000925, T: 284460, Avg. loss: 0.001287\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.006205, T: 341352, Avg. loss: 0.001285\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.009381, T: 56892, Avg. loss: 0.001759\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.003456, T: 113784, Avg. loss: 0.001315\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000107, T: 170676, Avg. loss: 0.001315\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.003153, T: 227568, Avg. loss: 0.001314\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.003612, T: 284460, Avg. loss: 0.001317\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.003068, T: 341352, Avg. loss: 0.001315\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002335, T: 56892, Avg. loss: 0.001758\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.000260, T: 113784, Avg. loss: 0.001310\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000923, T: 170676, Avg. loss: 0.001310\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.005218, T: 227568, Avg. loss: 0.001310\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.007294, T: 284460, Avg. loss: 0.001309\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.001044, T: 341352, Avg. loss: 0.001310\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.004937, T: 56892, Avg. loss: 0.001766\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.001224, T: 113784, Avg. loss: 0.001318\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.003772, T: 170676, Avg. loss: 0.001319\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.004036, T: 227568, Avg. loss: 0.001318\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.003858, T: 284460, Avg. loss: 0.001319\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.005453, T: 341352, Avg. loss: 0.001317\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.005898, T: 56892, Avg. loss: 0.001556\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000167, T: 113784, Avg. loss: 0.001107\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.002723, T: 170676, Avg. loss: 0.001105\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.004318, T: 227568, Avg. loss: 0.001106\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.001824, T: 284460, Avg. loss: 0.001106\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.003448, T: 341352, Avg. loss: 0.001105\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.005276, T: 56892, Avg. loss: 0.001865\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001514, T: 113784, Avg. loss: 0.001062\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.001109, T: 170676, Avg. loss: 0.001061\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.006511, T: 227568, Avg. loss: 0.001063\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.004618, T: 284460, Avg. loss: 0.001062\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.002462, T: 341352, Avg. loss: 0.001062\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.006670, T: 56892, Avg. loss: 0.001903\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.003331, T: 113784, Avg. loss: 0.001094\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.005941, T: 170676, Avg. loss: 0.001095\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.006338, T: 227568, Avg. loss: 0.001095\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.005196, T: 284460, Avg. loss: 0.001094\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.004553, T: 341352, Avg. loss: 0.001094\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002532, T: 56892, Avg. loss: 0.001883\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001225, T: 113784, Avg. loss: 0.001070\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.005545, T: 170676, Avg. loss: 0.001071\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004685, T: 227568, Avg. loss: 0.001071\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.003206, T: 284460, Avg. loss: 0.001071\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.001209, T: 341352, Avg. loss: 0.001070\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.005188, T: 56892, Avg. loss: 0.001900\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.007302, T: 113784, Avg. loss: 0.001091\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.004252, T: 170676, Avg. loss: 0.001092\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002767, T: 227568, Avg. loss: 0.001091\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000030, T: 284460, Avg. loss: 0.001091\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.004491, T: 341352, Avg. loss: 0.001091\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000120, T: 56892, Avg. loss: 0.001804\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000820, T: 113784, Avg. loss: 0.000993\n",
            "Total training time: 0.01 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001250, T: 170676, Avg. loss: 0.000992\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003937, T: 227568, Avg. loss: 0.000993\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004441, T: 284460, Avg. loss: 0.000993\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004172, T: 341352, Avg. loss: 0.000993\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.48, NNZs: 1, Bias: 0.001153, T: 56892, Avg. loss: 0.001947\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.83, NNZs: 1, Bias: -0.000024, T: 113784, Avg. loss: 0.001063\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.87, NNZs: 1, Bias: -0.000268, T: 170676, Avg. loss: 0.001063\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.76, NNZs: 1, Bias: -0.005719, T: 227568, Avg. loss: 0.001064\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.55, NNZs: 1, Bias: 0.002192, T: 284460, Avg. loss: 0.001064\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.26, NNZs: 1, Bias: 0.000238, T: 341352, Avg. loss: 0.001063\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.47, NNZs: 1, Bias: -0.011913, T: 56892, Avg. loss: 0.001974\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.83, NNZs: 1, Bias: -0.005738, T: 113784, Avg. loss: 0.001096\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.87, NNZs: 1, Bias: -0.006153, T: 170676, Avg. loss: 0.001096\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.76, NNZs: 1, Bias: -0.005442, T: 227568, Avg. loss: 0.001096\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.55, NNZs: 1, Bias: -0.003322, T: 284460, Avg. loss: 0.001096\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.26, NNZs: 1, Bias: -0.003346, T: 341352, Avg. loss: 0.001095\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.47, NNZs: 1, Bias: -0.003588, T: 56892, Avg. loss: 0.001945\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.83, NNZs: 1, Bias: -0.002582, T: 113784, Avg. loss: 0.001072\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.87, NNZs: 1, Bias: -0.007609, T: 170676, Avg. loss: 0.001073\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.76, NNZs: 1, Bias: -0.003630, T: 227568, Avg. loss: 0.001072\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.55, NNZs: 1, Bias: -0.003596, T: 284460, Avg. loss: 0.001072\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.26, NNZs: 1, Bias: -0.002003, T: 341352, Avg. loss: 0.001073\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.47, NNZs: 1, Bias: -0.005763, T: 56892, Avg. loss: 0.001971\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.83, NNZs: 1, Bias: -0.000823, T: 113784, Avg. loss: 0.001093\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.87, NNZs: 1, Bias: -0.004400, T: 170676, Avg. loss: 0.001093\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.76, NNZs: 1, Bias: -0.002252, T: 227568, Avg. loss: 0.001092\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.55, NNZs: 1, Bias: -0.005611, T: 284460, Avg. loss: 0.001094\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.26, NNZs: 1, Bias: 0.004210, T: 341352, Avg. loss: 0.001093\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.47, NNZs: 1, Bias: 0.000057, T: 56892, Avg. loss: 0.001874\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.83, NNZs: 1, Bias: -0.001527, T: 113784, Avg. loss: 0.000995\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.88, NNZs: 1, Bias: -0.004823, T: 170676, Avg. loss: 0.000995\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.76, NNZs: 1, Bias: -0.003138, T: 227568, Avg. loss: 0.000995\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.55, NNZs: 1, Bias: -0.003119, T: 284460, Avg. loss: 0.000994\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.26, NNZs: 1, Bias: -0.006691, T: 341352, Avg. loss: 0.000994\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.006451, T: 56892, Avg. loss: 0.001882\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.003160, T: 113784, Avg. loss: 0.001063\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.005198, T: 170676, Avg. loss: 0.001062\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002140, T: 227568, Avg. loss: 0.001062\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.004424, T: 284460, Avg. loss: 0.001063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002783, T: 341352, Avg. loss: 0.001063\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.003497, T: 56892, Avg. loss: 0.001912\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000590, T: 113784, Avg. loss: 0.001094\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.002993, T: 170676, Avg. loss: 0.001095\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.004167, T: 227568, Avg. loss: 0.001095\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.006959, T: 284460, Avg. loss: 0.001094\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.005380, T: 341352, Avg. loss: 0.001095\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.007611, T: 56892, Avg. loss: 0.001893\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000802, T: 113784, Avg. loss: 0.001071\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001073, T: 170676, Avg. loss: 0.001071\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.000674, T: 227568, Avg. loss: 0.001072\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.004475, T: 284460, Avg. loss: 0.001071\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.001512, T: 341352, Avg. loss: 0.001071\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.005250, T: 56892, Avg. loss: 0.001907\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000628, T: 113784, Avg. loss: 0.001092\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.007736, T: 170676, Avg. loss: 0.001092\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001534, T: 227568, Avg. loss: 0.001092\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.001770, T: 284460, Avg. loss: 0.001092\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.006387, T: 341352, Avg. loss: 0.001092\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000362, T: 56892, Avg. loss: 0.001809\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000081, T: 113784, Avg. loss: 0.000993\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.001573, T: 170676, Avg. loss: 0.000994\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002852, T: 227568, Avg. loss: 0.000993\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.006427, T: 284460, Avg. loss: 0.000993\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002404, T: 341352, Avg. loss: 0.000994\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.002661\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.001900\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.030000, T: 170676, Avg. loss: 0.001908\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.001927\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.010000, T: 284460, Avg. loss: 0.001889\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.001924\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002735\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.040000, T: 113784, Avg. loss: 0.002014\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.002037\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000000, T: 227568, Avg. loss: 0.002013\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000000, T: 284460, Avg. loss: 0.002029\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010000, T: 341352, Avg. loss: 0.002032\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.002681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.001969\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.030000, T: 170676, Avg. loss: 0.001969\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001971\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.030000, T: 284460, Avg. loss: 0.001977\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.001980\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.002773\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.002016\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.002024\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.002027\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.002014\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.002033\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000000, T: 56892, Avg. loss: 0.002124\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.001371\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.001371\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.001373\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.001362\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.001353\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.50, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.002657\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.85, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.001920\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.90, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.001923\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.80, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001901\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.58, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.001903\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.29, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001899\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.50, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.002776\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.86, NNZs: 1, Bias: 0.040000, T: 113784, Avg. loss: 0.002023\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.91, NNZs: 1, Bias: -0.000000, T: 170676, Avg. loss: 0.002029\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.80, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.002035\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.59, NNZs: 1, Bias: -0.010000, T: 284460, Avg. loss: 0.002023\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.30, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.002028\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.51, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002714\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.86, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.001969\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.91, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001970\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.80, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.001979\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.58, NNZs: 1, Bias: 0.040000, T: 284460, Avg. loss: 0.001980\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.30, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001970\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 3.50, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.002759\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.86, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.002017\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.91, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.002024\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.80, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.002028\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.59, NNZs: 1, Bias: -0.000000, T: 284460, Avg. loss: 0.002010\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.30, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.002022\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.50, NNZs: 1, Bias: -0.010000, T: 56892, Avg. loss: 0.002091\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.86, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001354\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.91, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001369\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.81, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.001369\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.59, NNZs: 1, Bias: 0.030000, T: 284460, Avg. loss: 0.001357\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 8.31, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001353\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.002636\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001900\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.001910\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.001909\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.000000, T: 284460, Avg. loss: 0.001921\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.001918\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.002759\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.002031\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.002045\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.002041\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.002016\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.002012\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002702\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001980\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.030000, T: 170676, Avg. loss: 0.001960\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.001970\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.040000, T: 284460, Avg. loss: 0.001970\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001963\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002756\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.11, NNZs: 1, Bias: 0.030000, T: 113784, Avg. loss: 0.002010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.002031\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.002031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.002038\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.002035\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002115\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001365\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.001361\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.001378\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001381\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.001362\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: nan, NNZs: 1, Bias: 0.002339, T: 56892, Avg. loss: 520574221536258880.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: nan, NNZs: 1, Bias: 0.000710, T: 113784, Avg. loss: 0.001272\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: nan, NNZs: 1, Bias: 0.000217, T: 170676, Avg. loss: 0.001271\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.60, NNZs: 1, Bias: -0.000389, T: 227568, Avg. loss: 0.001271\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.77, NNZs: 1, Bias: 0.000208, T: 284460, Avg. loss: 0.001272\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.84, NNZs: 1, Bias: 0.000998, T: 341352, Avg. loss: 0.001271\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.88, NNZs: 1, Bias: 0.000482, T: 398244, Avg. loss: 0.001271\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.85, NNZs: 1, Bias: -0.002610, T: 56892, Avg. loss: 551256998246728576.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: -0.000693, T: 113784, Avg. loss: 0.001302\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.97, NNZs: 1, Bias: -0.000376, T: 170676, Avg. loss: 0.001302\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.000624, T: 227568, Avg. loss: 0.001302\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.000172, T: 284460, Avg. loss: 0.001300\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.000687, T: 341352, Avg. loss: 0.001300\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000789, T: 398244, Avg. loss: 0.001301\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: nan, NNZs: 1, Bias: -0.000670, T: 56892, Avg. loss: 409723747415777673216.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: nan, NNZs: 1, Bias: 0.000107, T: 113784, Avg. loss: 0.001297\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: nan, NNZs: 1, Bias: 0.001466, T: 170676, Avg. loss: 0.001296\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: nan, NNZs: 1, Bias: 0.000086, T: 227568, Avg. loss: 0.001296\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: nan, NNZs: 1, Bias: 0.001522, T: 284460, Avg. loss: 0.001296\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: nan, NNZs: 1, Bias: 0.001842, T: 341352, Avg. loss: 0.001296\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: nan, NNZs: 1, Bias: 0.000256, T: 398244, Avg. loss: 0.001295\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 2.25, NNZs: 1, Bias: -0.001215, T: 56892, Avg. loss: 773892412615463296.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.42, NNZs: 1, Bias: 0.000584, T: 113784, Avg. loss: 0.001305\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.20, NNZs: 1, Bias: 0.000232, T: 170676, Avg. loss: 0.001304\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.11, NNZs: 1, Bias: 0.000577, T: 227568, Avg. loss: 0.001304\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000381, T: 284460, Avg. loss: 0.001304\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.000232, T: 341352, Avg. loss: 0.001304\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.000729, T: 398244, Avg. loss: 0.001304\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4.95, NNZs: 1, Bias: 0.001829, T: 56892, Avg. loss: 1234274539211254272.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 2.62, NNZs: 1, Bias: 0.000240, T: 113784, Avg. loss: 0.001095\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.90, NNZs: 1, Bias: -0.000204, T: 170676, Avg. loss: 0.001094\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.57, NNZs: 1, Bias: 0.000894, T: 227568, Avg. loss: 0.001094\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.39, NNZs: 1, Bias: 0.000862, T: 284460, Avg. loss: 0.001094\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.28, NNZs: 1, Bias: -0.000171, T: 341352, Avg. loss: 0.001094\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.21, NNZs: 1, Bias: 0.000479, T: 398244, Avg. loss: 0.001095\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1486081.03, NNZs: 1, Bias: 0.000468, T: 56892, Avg. loss: 639627214427368704.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1486081.03, NNZs: 1, Bias: -0.000463, T: 113784, Avg. loss: 0.001274\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1486081.03, NNZs: 1, Bias: 0.000967, T: 170676, Avg. loss: 0.001273\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1486081.03, NNZs: 1, Bias: -0.000470, T: 227568, Avg. loss: 0.001272\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1486081.03, NNZs: 1, Bias: 0.000025, T: 284460, Avg. loss: 0.001273\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1486081.03, NNZs: 1, Bias: -0.000875, T: 341352, Avg. loss: 0.001272\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1486081.03, NNZs: 1, Bias: 0.000376, T: 398244, Avg. loss: 0.001273\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 809454.43, NNZs: 1, Bias: 0.002886, T: 56892, Avg. loss: 193701056927061216.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 809454.43, NNZs: 1, Bias: -0.001407, T: 113784, Avg. loss: 0.001303\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 809454.43, NNZs: 1, Bias: 0.001268, T: 170676, Avg. loss: 0.001303\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 809454.43, NNZs: 1, Bias: -0.000125, T: 227568, Avg. loss: 0.001302\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 809454.43, NNZs: 1, Bias: -0.001031, T: 284460, Avg. loss: 0.001302\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 809454.43, NNZs: 1, Bias: -0.001318, T: 341352, Avg. loss: 0.001302\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 809454.43, NNZs: 1, Bias: -0.000486, T: 398244, Avg. loss: 0.001302\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4707470.08, NNZs: 1, Bias: 0.000235, T: 56892, Avg. loss: 74252865236972748800.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4707470.08, NNZs: 1, Bias: 0.001096, T: 113784, Avg. loss: 0.001298\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4707470.08, NNZs: 1, Bias: 0.000430, T: 170676, Avg. loss: 0.001297\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4707470.08, NNZs: 1, Bias: 0.000891, T: 227568, Avg. loss: 0.001297\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4707470.08, NNZs: 1, Bias: 0.000214, T: 284460, Avg. loss: 0.001296\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4707470.08, NNZs: 1, Bias: 0.000300, T: 341352, Avg. loss: 0.001297\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 4707470.08, NNZs: 1, Bias: 0.001124, T: 398244, Avg. loss: 0.001297\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 5287045.56, NNZs: 1, Bias: -0.001554, T: 56892, Avg. loss: 163975966304731791360.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 5287045.56, NNZs: 1, Bias: 0.001422, T: 113784, Avg. loss: 0.001306\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5287045.56, NNZs: 1, Bias: 0.000735, T: 170676, Avg. loss: 0.001305\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5287045.56, NNZs: 1, Bias: -0.000471, T: 227568, Avg. loss: 0.001305\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5287045.56, NNZs: 1, Bias: -0.000567, T: 284460, Avg. loss: 0.001305\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5287045.56, NNZs: 1, Bias: -0.000998, T: 341352, Avg. loss: 0.001305\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 5287045.56, NNZs: 1, Bias: -0.000488, T: 398244, Avg. loss: 0.001305\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4536154.94, NNZs: 1, Bias: -0.001674, T: 56892, Avg. loss: 146950678670176452608.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4536154.94, NNZs: 1, Bias: 0.001130, T: 113784, Avg. loss: 0.001097\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4536154.94, NNZs: 1, Bias: 0.000528, T: 170676, Avg. loss: 0.001095\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4536154.94, NNZs: 1, Bias: -0.000621, T: 227568, Avg. loss: 0.001095\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4536154.94, NNZs: 1, Bias: 0.000516, T: 284460, Avg. loss: 0.001096\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4536154.94, NNZs: 1, Bias: -0.000116, T: 341352, Avg. loss: 0.001094\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 4536154.94, NNZs: 1, Bias: -0.000593, T: 398244, Avg. loss: 0.001095\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 6590.14, NNZs: 1, Bias: 0.000417, T: 56892, Avg. loss: 20523529693213462528.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3656.95, NNZs: 1, Bias: -0.000125, T: 113784, Avg. loss: 0.001273\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2591.04, NNZs: 1, Bias: -0.000325, T: 170676, Avg. loss: 0.001272\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2029.05, NNZs: 1, Bias: 0.000599, T: 227568, Avg. loss: 0.001272\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1678.53, NNZs: 1, Bias: 0.000168, T: 284460, Avg. loss: 0.001271\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1437.58, NNZs: 1, Bias: 0.001178, T: 341352, Avg. loss: 0.001273\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1261.05, NNZs: 1, Bias: 0.000457, T: 398244, Avg. loss: 0.001271\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 873.24, NNZs: 1, Bias: 0.000757, T: 56892, Avg. loss: 53546409500304728.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 484.57, NNZs: 1, Bias: 0.000800, T: 113784, Avg. loss: 0.001302\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 343.33, NNZs: 1, Bias: -0.000772, T: 170676, Avg. loss: 0.001301\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 268.86, NNZs: 1, Bias: -0.000623, T: 227568, Avg. loss: 0.001301\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 222.42, NNZs: 1, Bias: -0.000616, T: 284460, Avg. loss: 0.001301\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 190.49, NNZs: 1, Bias: 0.000218, T: 341352, Avg. loss: 0.001302\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 167.10, NNZs: 1, Bias: -0.000300, T: 398244, Avg. loss: 0.001301\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 9096.82, NNZs: 1, Bias: -0.001176, T: 56892, Avg. loss: 101906674110735319040.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 5047.93, NNZs: 1, Bias: 0.000825, T: 113784, Avg. loss: 0.001297\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 3576.59, NNZs: 1, Bias: 0.000289, T: 170676, Avg. loss: 0.001297\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2800.84, NNZs: 1, Bias: 0.000615, T: 227568, Avg. loss: 0.001295\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2316.99, NNZs: 1, Bias: 0.000970, T: 284460, Avg. loss: 0.001296\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1984.39, NNZs: 1, Bias: 0.000301, T: 341352, Avg. loss: 0.001296\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1740.71, NNZs: 1, Bias: 0.000350, T: 398244, Avg. loss: 0.001295\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 169.42, NNZs: 1, Bias: -0.001806, T: 56892, Avg. loss: 35588569572722.101562\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 94.02, NNZs: 1, Bias: -0.000395, T: 113784, Avg. loss: 0.001305\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 66.62, NNZs: 1, Bias: 0.000415, T: 170676, Avg. loss: 0.001304\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 52.17, NNZs: 1, Bias: -0.000496, T: 227568, Avg. loss: 0.001304\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 43.16, NNZs: 1, Bias: -0.000988, T: 284460, Avg. loss: 0.001304\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 36.97, NNZs: 1, Bias: -0.000010, T: 341352, Avg. loss: 0.001305\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 32.44, NNZs: 1, Bias: -0.000123, T: 398244, Avg. loss: 0.001303\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 392.11, NNZs: 1, Bias: 0.000537, T: 56892, Avg. loss: 1286401651128250.500000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 217.59, NNZs: 1, Bias: -0.000534, T: 113784, Avg. loss: 0.001095\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 154.17, NNZs: 1, Bias: -0.001057, T: 170676, Avg. loss: 0.001095\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 120.73, NNZs: 1, Bias: 0.000121, T: 227568, Avg. loss: 0.001094\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 99.88, NNZs: 1, Bias: -0.000448, T: 284460, Avg. loss: 0.001094\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 85.54, NNZs: 1, Bias: 0.000510, T: 341352, Avg. loss: 0.001094\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 75.04, NNZs: 1, Bias: 0.000551, T: 398244, Avg. loss: 0.001094\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.001879, T: 56892, Avg. loss: 0.001080\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003359, T: 113784, Avg. loss: 0.001055\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002260, T: 170676, Avg. loss: 0.001054\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002822, T: 227568, Avg. loss: 0.001054\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002283, T: 284460, Avg. loss: 0.001054\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002020, T: 341352, Avg. loss: 0.001054\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001156, T: 56892, Avg. loss: 0.001114\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002351, T: 113784, Avg. loss: 0.001086\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001990, T: 170676, Avg. loss: 0.001085\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002816, T: 227568, Avg. loss: 0.001086\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002846, T: 284460, Avg. loss: 0.001086\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003202, T: 341352, Avg. loss: 0.001085\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000158, T: 56892, Avg. loss: 0.001087\n",
            "Total training time: 0.00 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003956, T: 113784, Avg. loss: 0.001062\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001392, T: 170676, Avg. loss: 0.001063\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002181, T: 227568, Avg. loss: 0.001062\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000478, T: 284460, Avg. loss: 0.001063\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002145, T: 341352, Avg. loss: 0.001062\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001854, T: 56892, Avg. loss: 0.001108\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002242, T: 113784, Avg. loss: 0.001084\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002847, T: 170676, Avg. loss: 0.001083\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002301, T: 227568, Avg. loss: 0.001083\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002551, T: 284460, Avg. loss: 0.001083\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002253, T: 341352, Avg. loss: 0.001083\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001085, T: 56892, Avg. loss: 0.001012\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000837, T: 113784, Avg. loss: 0.000986\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002432, T: 170676, Avg. loss: 0.000985\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001728, T: 227568, Avg. loss: 0.000985\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001706, T: 284460, Avg. loss: 0.000985\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001659, T: 341352, Avg. loss: 0.000985\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.94, NNZs: 1, Bias: -0.001668, T: 56892, Avg. loss: 0.001081\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.11, NNZs: 1, Bias: -0.001507, T: 113784, Avg. loss: 0.001056\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.21, NNZs: 1, Bias: -0.002096, T: 170676, Avg. loss: 0.001056\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.27, NNZs: 1, Bias: -0.002670, T: 227568, Avg. loss: 0.001055\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4.33, NNZs: 1, Bias: -0.001537, T: 284460, Avg. loss: 0.001056\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.37, NNZs: 1, Bias: -0.002541, T: 341352, Avg. loss: 0.001055\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.96, NNZs: 1, Bias: -0.004020, T: 56892, Avg. loss: 0.001114\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.13, NNZs: 1, Bias: -0.001638, T: 113784, Avg. loss: 0.001088\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.22, NNZs: 1, Bias: -0.004738, T: 170676, Avg. loss: 0.001086\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.29, NNZs: 1, Bias: -0.002666, T: 227568, Avg. loss: 0.001088\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4.34, NNZs: 1, Bias: -0.003029, T: 284460, Avg. loss: 0.001087\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.38, NNZs: 1, Bias: -0.002573, T: 341352, Avg. loss: 0.001087\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.97, NNZs: 1, Bias: -0.000872, T: 56892, Avg. loss: 0.001091\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.14, NNZs: 1, Bias: 0.000312, T: 113784, Avg. loss: 0.001065\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.24, NNZs: 1, Bias: -0.001144, T: 170676, Avg. loss: 0.001063\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.30, NNZs: 1, Bias: -0.001400, T: 227568, Avg. loss: 0.001064\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4.35, NNZs: 1, Bias: -0.001590, T: 284460, Avg. loss: 0.001064\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.40, NNZs: 1, Bias: -0.001387, T: 341352, Avg. loss: 0.001063\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.94, NNZs: 1, Bias: -0.000195, T: 56892, Avg. loss: 0.001112\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.11, NNZs: 1, Bias: -0.002450, T: 113784, Avg. loss: 0.001085\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 4.20, NNZs: 1, Bias: -0.001444, T: 170676, Avg. loss: 0.001085\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.27, NNZs: 1, Bias: -0.002653, T: 227568, Avg. loss: 0.001085\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4.32, NNZs: 1, Bias: -0.003132, T: 284460, Avg. loss: 0.001084\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.36, NNZs: 1, Bias: -0.003459, T: 341352, Avg. loss: 0.001084\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.96, NNZs: 1, Bias: -0.001512, T: 56892, Avg. loss: 0.001014\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.13, NNZs: 1, Bias: -0.001377, T: 113784, Avg. loss: 0.000987\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.23, NNZs: 1, Bias: -0.002287, T: 170676, Avg. loss: 0.000986\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.29, NNZs: 1, Bias: -0.001868, T: 227568, Avg. loss: 0.000986\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4.35, NNZs: 1, Bias: -0.001661, T: 284460, Avg. loss: 0.000987\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.39, NNZs: 1, Bias: -0.001644, T: 341352, Avg. loss: 0.000986\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.003748, T: 56892, Avg. loss: 0.001080\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002582, T: 113784, Avg. loss: 0.001055\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002833, T: 170676, Avg. loss: 0.001054\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.003242, T: 227568, Avg. loss: 0.001055\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001902, T: 284460, Avg. loss: 0.001054\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002460, T: 341352, Avg. loss: 0.001054\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001586, T: 56892, Avg. loss: 0.001113\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.004588, T: 113784, Avg. loss: 0.001086\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002745, T: 170676, Avg. loss: 0.001086\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001798, T: 227568, Avg. loss: 0.001086\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002707, T: 284460, Avg. loss: 0.001086\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002476, T: 341352, Avg. loss: 0.001086\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.003238, T: 56892, Avg. loss: 0.001088\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001665, T: 113784, Avg. loss: 0.001064\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001194, T: 170676, Avg. loss: 0.001063\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001774, T: 227568, Avg. loss: 0.001062\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002625, T: 284460, Avg. loss: 0.001062\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001689, T: 341352, Avg. loss: 0.001064\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001768, T: 56892, Avg. loss: 0.001109\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002909, T: 113784, Avg. loss: 0.001084\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.003939, T: 170676, Avg. loss: 0.001084\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001738, T: 227568, Avg. loss: 0.001084\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002662, T: 284460, Avg. loss: 0.001083\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002532, T: 341352, Avg. loss: 0.001083\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002666, T: 56892, Avg. loss: 0.001011\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000382, T: 113784, Avg. loss: 0.000986\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002036, T: 170676, Avg. loss: 0.000985\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.07, NNZs: 1, Bias: -0.003224, T: 227568, Avg. loss: 0.000985\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001457, T: 284460, Avg. loss: 0.000986\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001464, T: 341352, Avg. loss: 0.000984\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.034829, T: 56892, Avg. loss: 0.005410\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.026407, T: 113784, Avg. loss: 0.001733\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.026528, T: 170676, Avg. loss: 0.001724\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.024395, T: 227568, Avg. loss: 0.001720\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.021510, T: 284460, Avg. loss: 0.001725\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.025118, T: 341352, Avg. loss: 0.001724\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.023357, T: 398244, Avg. loss: 0.001713\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.016141, T: 56892, Avg. loss: 0.005978\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.020835, T: 113784, Avg. loss: 0.001823\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.022359, T: 170676, Avg. loss: 0.001810\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.019278, T: 227568, Avg. loss: 0.001805\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.017496, T: 284460, Avg. loss: 0.001808\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.018849, T: 341352, Avg. loss: 0.001799\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.019868, T: 398244, Avg. loss: 0.001805\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.020590, T: 56892, Avg. loss: 0.005305\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.023788, T: 113784, Avg. loss: 0.001789\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.027895, T: 170676, Avg. loss: 0.001783\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.027335, T: 227568, Avg. loss: 0.001779\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.026648, T: 284460, Avg. loss: 0.001774\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.020675, T: 341352, Avg. loss: 0.001773\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.023619, T: 398244, Avg. loss: 0.001770\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.021737, T: 56892, Avg. loss: 0.005584\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.015203, T: 113784, Avg. loss: 0.001827\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.017155, T: 170676, Avg. loss: 0.001818\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.018465, T: 227568, Avg. loss: 0.001815\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.018895, T: 284460, Avg. loss: 0.001808\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.020071, T: 341352, Avg. loss: 0.001810\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.019462, T: 398244, Avg. loss: 0.001813\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.020481, T: 56892, Avg. loss: 0.005180\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.023409, T: 113784, Avg. loss: 0.001192\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.017525, T: 170676, Avg. loss: 0.001186\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.017597, T: 227568, Avg. loss: 0.001177\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.019894, T: 284460, Avg. loss: 0.001183\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.022457, T: 341352, Avg. loss: 0.001178\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.019875, T: 398244, Avg. loss: 0.001180\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7.21, NNZs: 1, Bias: 0.015954, T: 56892, Avg. loss: 0.005378\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 7.31, NNZs: 1, Bias: 0.028599, T: 113784, Avg. loss: 0.001745\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 7.36, NNZs: 1, Bias: 0.024085, T: 170676, Avg. loss: 0.001725\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 7.40, NNZs: 1, Bias: 0.025229, T: 227568, Avg. loss: 0.001723\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.43, NNZs: 1, Bias: 0.025637, T: 284460, Avg. loss: 0.001719\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 7.46, NNZs: 1, Bias: 0.022416, T: 341352, Avg. loss: 0.001721\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Norm: 7.48, NNZs: 1, Bias: 0.024065, T: 398244, Avg. loss: 0.001716\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 6.67, NNZs: 1, Bias: 0.011691, T: 56892, Avg. loss: 0.005336\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 6.77, NNZs: 1, Bias: 0.017903, T: 113784, Avg. loss: 0.001828\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 6.83, NNZs: 1, Bias: 0.019356, T: 170676, Avg. loss: 0.001811\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.87, NNZs: 1, Bias: 0.017064, T: 227568, Avg. loss: 0.001807\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 6.90, NNZs: 1, Bias: 0.020836, T: 284460, Avg. loss: 0.001798\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 6.93, NNZs: 1, Bias: 0.018466, T: 341352, Avg. loss: 0.001806\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 6.95, NNZs: 1, Bias: 0.017522, T: 398244, Avg. loss: 0.001802\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7.65, NNZs: 1, Bias: 0.024152, T: 56892, Avg. loss: 0.005665\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 7.74, NNZs: 1, Bias: 0.027310, T: 113784, Avg. loss: 0.001790\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 7.79, NNZs: 1, Bias: 0.021552, T: 170676, Avg. loss: 0.001781\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 7.83, NNZs: 1, Bias: 0.024381, T: 227568, Avg. loss: 0.001778\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.86, NNZs: 1, Bias: 0.026068, T: 284460, Avg. loss: 0.001777\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 7.88, NNZs: 1, Bias: 0.023413, T: 341352, Avg. loss: 0.001777\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 7.90, NNZs: 1, Bias: 0.025468, T: 398244, Avg. loss: 0.001770\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 6.63, NNZs: 1, Bias: 0.022678, T: 56892, Avg. loss: 0.005666\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 6.73, NNZs: 1, Bias: 0.016505, T: 113784, Avg. loss: 0.001831\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 6.79, NNZs: 1, Bias: 0.020961, T: 170676, Avg. loss: 0.001823\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 6.83, NNZs: 1, Bias: 0.017892, T: 227568, Avg. loss: 0.001817\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 6.86, NNZs: 1, Bias: 0.020569, T: 284460, Avg. loss: 0.001811\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 6.89, NNZs: 1, Bias: 0.020587, T: 341352, Avg. loss: 0.001812\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 6.91, NNZs: 1, Bias: 0.020411, T: 398244, Avg. loss: 0.001813\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7.15, NNZs: 1, Bias: 0.020862, T: 56892, Avg. loss: 0.004833\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 7.24, NNZs: 1, Bias: 0.023692, T: 113784, Avg. loss: 0.001193\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 7.30, NNZs: 1, Bias: 0.017243, T: 170676, Avg. loss: 0.001188\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 7.34, NNZs: 1, Bias: 0.019198, T: 227568, Avg. loss: 0.001186\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 7.37, NNZs: 1, Bias: 0.022176, T: 284460, Avg. loss: 0.001183\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 7.39, NNZs: 1, Bias: 0.021591, T: 341352, Avg. loss: 0.001184\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 7.41, NNZs: 1, Bias: 0.018364, T: 398244, Avg. loss: 0.001179\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.025626, T: 56892, Avg. loss: 0.005813\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.020763, T: 113784, Avg. loss: 0.001736\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.023405, T: 170676, Avg. loss: 0.001730\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.022895, T: 227568, Avg. loss: 0.001720\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.021647, T: 284460, Avg. loss: 0.001724\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.023704, T: 341352, Avg. loss: 0.001723\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.026143, T: 398244, Avg. loss: 0.001711\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.07, NNZs: 1, Bias: 0.022019, T: 56892, Avg. loss: 0.005388\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.016860, T: 113784, Avg. loss: 0.001827\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.020436, T: 170676, Avg. loss: 0.001813\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.019968, T: 227568, Avg. loss: 0.001808\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.017989, T: 284460, Avg. loss: 0.001803\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.021052, T: 341352, Avg. loss: 0.001802\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.019188, T: 398244, Avg. loss: 0.001798\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.022967, T: 56892, Avg. loss: 0.005193\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.022474, T: 113784, Avg. loss: 0.001795\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.022251, T: 170676, Avg. loss: 0.001780\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.026971, T: 227568, Avg. loss: 0.001775\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.024278, T: 284460, Avg. loss: 0.001778\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.022138, T: 341352, Avg. loss: 0.001770\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.024650, T: 398244, Avg. loss: 0.001775\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.015598, T: 56892, Avg. loss: 0.005764\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.017898, T: 113784, Avg. loss: 0.001829\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.022864, T: 170676, Avg. loss: 0.001819\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.018434, T: 227568, Avg. loss: 0.001815\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.016911, T: 284460, Avg. loss: 0.001817\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.019004, T: 341352, Avg. loss: 0.001811\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.015806, T: 398244, Avg. loss: 0.001811\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.025525, T: 56892, Avg. loss: 0.005299\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.021386, T: 113784, Avg. loss: 0.001191\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.015079, T: 170676, Avg. loss: 0.001191\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.022324, T: 227568, Avg. loss: 0.001181\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.021552, T: 284460, Avg. loss: 0.001185\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.022465, T: 341352, Avg. loss: 0.001185\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.017429, T: 398244, Avg. loss: 0.001180\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000905, T: 56892, Avg. loss: 0.002597\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000662, T: 113784, Avg. loss: 0.001272\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000913, T: 170676, Avg. loss: 0.001271\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000329, T: 227568, Avg. loss: 0.001272\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000394, T: 284460, Avg. loss: 0.001271\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001038, T: 341352, Avg. loss: 0.001272\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.99, NNZs: 1, Bias: -0.000777, T: 398244, Avg. loss: 0.001271\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000613, T: 56892, Avg. loss: 0.002706\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000349, T: 113784, Avg. loss: 0.001301\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000163, T: 170676, Avg. loss: 0.001301\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000931, T: 227568, Avg. loss: 0.001301\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000553, T: 284460, Avg. loss: 0.001300\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000031, T: 341352, Avg. loss: 0.001302\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001785, T: 398244, Avg. loss: 0.001300\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000229, T: 56892, Avg. loss: 0.002690\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000423, T: 113784, Avg. loss: 0.001296\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001170, T: 170676, Avg. loss: 0.001296\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000744, T: 227568, Avg. loss: 0.001296\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000031, T: 284460, Avg. loss: 0.001295\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001000, T: 341352, Avg. loss: 0.001297\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000499, T: 398244, Avg. loss: 0.001295\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000071, T: 56892, Avg. loss: 0.002625\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000270, T: 113784, Avg. loss: 0.001304\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000432, T: 170676, Avg. loss: 0.001304\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000476, T: 227568, Avg. loss: 0.001304\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000408, T: 284460, Avg. loss: 0.001304\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000291, T: 341352, Avg. loss: 0.001304\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000342, T: 398244, Avg. loss: 0.001304\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001424, T: 56892, Avg. loss: 0.002391\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.99, NNZs: 1, Bias: 0.000575, T: 113784, Avg. loss: 0.001095\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000395, T: 170676, Avg. loss: 0.001094\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000062, T: 227568, Avg. loss: 0.001094\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000803, T: 284460, Avg. loss: 0.001094\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000130, T: 341352, Avg. loss: 0.001094\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000407, T: 398244, Avg. loss: 0.001094\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.39, NNZs: 1, Bias: -0.000473, T: 56892, Avg. loss: 0.002609\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.61, NNZs: 1, Bias: -0.001614, T: 113784, Avg. loss: 0.001272\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.78, NNZs: 1, Bias: 0.000297, T: 170676, Avg. loss: 0.001273\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.93, NNZs: 1, Bias: -0.000007, T: 227568, Avg. loss: 0.001273\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.05, NNZs: 1, Bias: -0.001946, T: 284460, Avg. loss: 0.001272\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.16, NNZs: 1, Bias: -0.000679, T: 341352, Avg. loss: 0.001273\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.27, NNZs: 1, Bias: 0.000066, T: 398244, Avg. loss: 0.001273\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.39, NNZs: 1, Bias: -0.000548, T: 56892, Avg. loss: 0.002648\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.61, NNZs: 1, Bias: 0.000622, T: 113784, Avg. loss: 0.001303\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.78, NNZs: 1, Bias: 0.000535, T: 170676, Avg. loss: 0.001302\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.92, NNZs: 1, Bias: -0.000353, T: 227568, Avg. loss: 0.001301\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.05, NNZs: 1, Bias: -0.000425, T: 284460, Avg. loss: 0.001303\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.16, NNZs: 1, Bias: -0.000633, T: 341352, Avg. loss: 0.001302\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.27, NNZs: 1, Bias: 0.000363, T: 398244, Avg. loss: 0.001302\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.39, NNZs: 1, Bias: 0.001314, T: 56892, Avg. loss: 0.002671\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.61, NNZs: 1, Bias: 0.000586, T: 113784, Avg. loss: 0.001297\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.78, NNZs: 1, Bias: 0.001661, T: 170676, Avg. loss: 0.001297\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.93, NNZs: 1, Bias: 0.000777, T: 227568, Avg. loss: 0.001297\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.05, NNZs: 1, Bias: 0.001003, T: 284460, Avg. loss: 0.001296\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.16, NNZs: 1, Bias: 0.001016, T: 341352, Avg. loss: 0.001297\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.27, NNZs: 1, Bias: 0.001191, T: 398244, Avg. loss: 0.001296\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.39, NNZs: 1, Bias: -0.001741, T: 56892, Avg. loss: 0.002715\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.61, NNZs: 1, Bias: -0.000933, T: 113784, Avg. loss: 0.001305\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.78, NNZs: 1, Bias: -0.000880, T: 170676, Avg. loss: 0.001305\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.92, NNZs: 1, Bias: -0.000126, T: 227568, Avg. loss: 0.001305\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.05, NNZs: 1, Bias: -0.000228, T: 284460, Avg. loss: 0.001305\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.16, NNZs: 1, Bias: -0.000197, T: 341352, Avg. loss: 0.001305\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.27, NNZs: 1, Bias: -0.000742, T: 398244, Avg. loss: 0.001305\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.39, NNZs: 1, Bias: 0.000654, T: 56892, Avg. loss: 0.002510\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.61, NNZs: 1, Bias: -0.000597, T: 113784, Avg. loss: 0.001095\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.78, NNZs: 1, Bias: 0.000025, T: 170676, Avg. loss: 0.001095\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.92, NNZs: 1, Bias: -0.000172, T: 227568, Avg. loss: 0.001095\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.05, NNZs: 1, Bias: -0.000590, T: 284460, Avg. loss: 0.001095\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.16, NNZs: 1, Bias: -0.000292, T: 341352, Avg. loss: 0.001095\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.27, NNZs: 1, Bias: -0.000155, T: 398244, Avg. loss: 0.001095\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.000739, T: 56892, Avg. loss: 0.002587\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.000771, T: 113784, Avg. loss: 0.001271\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.000370, T: 170676, Avg. loss: 0.001272\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000878, T: 227568, Avg. loss: 0.001271\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000530, T: 284460, Avg. loss: 0.001271\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000913, T: 341352, Avg. loss: 0.001271\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000684, T: 398244, Avg. loss: 0.001271\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.001370, T: 56892, Avg. loss: 0.002664\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.000975, T: 113784, Avg. loss: 0.001302\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.000939, T: 170676, Avg. loss: 0.001301\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000747, T: 227568, Avg. loss: 0.001302\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000090, T: 284460, Avg. loss: 0.001301\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001216, T: 341352, Avg. loss: 0.001301\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000343, T: 398244, Avg. loss: 0.001302\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.000099, T: 56892, Avg. loss: 0.002593\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.000831, T: 113784, Avg. loss: 0.001296\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.001585, T: 170676, Avg. loss: 0.001296\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.001571, T: 227568, Avg. loss: 0.001296\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000488, T: 284460, Avg. loss: 0.001296\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000375, T: 341352, Avg. loss: 0.001295\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000730, T: 398244, Avg. loss: 0.001296\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.001143, T: 56892, Avg. loss: 0.002696\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.001064, T: 113784, Avg. loss: 0.001304\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.001023, T: 170676, Avg. loss: 0.001304\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.001082, T: 227568, Avg. loss: 0.001304\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000998, T: 284460, Avg. loss: 0.001305\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001029, T: 341352, Avg. loss: 0.001303\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001183, T: 398244, Avg. loss: 0.001305\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.04, NNZs: 1, Bias: 0.000160, T: 56892, Avg. loss: 0.002437\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.000354, T: 113784, Avg. loss: 0.001094\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.001579, T: 170676, Avg. loss: 0.001094\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000143, T: 227568, Avg. loss: 0.001095\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000962, T: 284460, Avg. loss: 0.001094\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000583, T: 341352, Avg. loss: 0.001094\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000470, T: 398244, Avg. loss: 0.001094\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 7 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002673, T: 56892, Avg. loss: 0.006017\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002938, T: 113784, Avg. loss: 0.001054\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003775, T: 170676, Avg. loss: 0.001054\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001849, T: 227568, Avg. loss: 0.001054\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001867, T: 284460, Avg. loss: 0.001054\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002080, T: 341352, Avg. loss: 0.001054\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001933, T: 398244, Avg. loss: 0.001054\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001852, T: 56892, Avg. loss: 0.006041\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002469, T: 113784, Avg. loss: 0.001085\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.003047, T: 170676, Avg. loss: 0.001085\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002797, T: 227568, Avg. loss: 0.001086\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001754, T: 284460, Avg. loss: 0.001086\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002691, T: 341352, Avg. loss: 0.001085\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002223, T: 398244, Avg. loss: 0.001086\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000353, T: 56892, Avg. loss: 0.005982\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001170, T: 113784, Avg. loss: 0.001062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001290, T: 170676, Avg. loss: 0.001062\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000889, T: 227568, Avg. loss: 0.001062\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002863, T: 284460, Avg. loss: 0.001062\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001360, T: 341352, Avg. loss: 0.001063\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001668, T: 398244, Avg. loss: 0.001062\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.004045, T: 56892, Avg. loss: 0.006017\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002445, T: 113784, Avg. loss: 0.001084\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003087, T: 170676, Avg. loss: 0.001083\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001947, T: 227568, Avg. loss: 0.001084\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003583, T: 284460, Avg. loss: 0.001083\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.003544, T: 341352, Avg. loss: 0.001082\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003185, T: 398244, Avg. loss: 0.001084\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001961, T: 56892, Avg. loss: 0.005906\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000723, T: 113784, Avg. loss: 0.000985\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001070, T: 170676, Avg. loss: 0.000985\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002256, T: 227568, Avg. loss: 0.000985\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002010, T: 284460, Avg. loss: 0.000985\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001606, T: 341352, Avg. loss: 0.000984\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001046, T: 398244, Avg. loss: 0.000985\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.35, NNZs: 1, Bias: -0.002322, T: 56892, Avg. loss: 0.006614\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.57, NNZs: 1, Bias: -0.002111, T: 113784, Avg. loss: 0.001056\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.75, NNZs: 1, Bias: -0.002184, T: 170676, Avg. loss: 0.001055\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.89, NNZs: 1, Bias: -0.002604, T: 227568, Avg. loss: 0.001056\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.02, NNZs: 1, Bias: -0.002659, T: 284460, Avg. loss: 0.001055\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.13, NNZs: 1, Bias: -0.002237, T: 341352, Avg. loss: 0.001056\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.24, NNZs: 1, Bias: -0.002540, T: 398244, Avg. loss: 0.001056\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.35, NNZs: 1, Bias: -0.002674, T: 56892, Avg. loss: 0.006592\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.57, NNZs: 1, Bias: -0.002028, T: 113784, Avg. loss: 0.001087\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.75, NNZs: 1, Bias: -0.002996, T: 170676, Avg. loss: 0.001087\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.89, NNZs: 1, Bias: -0.002363, T: 227568, Avg. loss: 0.001088\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.02, NNZs: 1, Bias: -0.002663, T: 284460, Avg. loss: 0.001087\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.13, NNZs: 1, Bias: -0.002909, T: 341352, Avg. loss: 0.001087\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.24, NNZs: 1, Bias: -0.003811, T: 398244, Avg. loss: 0.001087\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.35, NNZs: 1, Bias: -0.001872, T: 56892, Avg. loss: 0.006617\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.57, NNZs: 1, Bias: -0.001050, T: 113784, Avg. loss: 0.001064\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.75, NNZs: 1, Bias: -0.001755, T: 170676, Avg. loss: 0.001064\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.89, NNZs: 1, Bias: -0.002607, T: 227568, Avg. loss: 0.001064\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.02, NNZs: 1, Bias: -0.001888, T: 284460, Avg. loss: 0.001064\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.14, NNZs: 1, Bias: -0.001852, T: 341352, Avg. loss: 0.001063\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.24, NNZs: 1, Bias: -0.001286, T: 398244, Avg. loss: 0.001064\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.35, NNZs: 1, Bias: -0.000953, T: 56892, Avg. loss: 0.006602\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.57, NNZs: 1, Bias: -0.002921, T: 113784, Avg. loss: 0.001085\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.75, NNZs: 1, Bias: -0.002180, T: 170676, Avg. loss: 0.001085\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.89, NNZs: 1, Bias: -0.001670, T: 227568, Avg. loss: 0.001084\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.02, NNZs: 1, Bias: -0.002673, T: 284460, Avg. loss: 0.001084\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 2.13, NNZs: 1, Bias: -0.002642, T: 341352, Avg. loss: 0.001085\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.24, NNZs: 1, Bias: -0.001435, T: 398244, Avg. loss: 0.001085\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.35, NNZs: 1, Bias: -0.002295, T: 56892, Avg. loss: 0.006539\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.57, NNZs: 1, Bias: -0.002201, T: 113784, Avg. loss: 0.000987\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.75, NNZs: 1, Bias: -0.001476, T: 170676, Avg. loss: 0.000986\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.89, NNZs: 1, Bias: -0.002472, T: 227568, Avg. loss: 0.000986\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.02, NNZs: 1, Bias: -0.001394, T: 284460, Avg. loss: 0.000987\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.13, NNZs: 1, Bias: -0.002041, T: 341352, Avg. loss: 0.000985\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.24, NNZs: 1, Bias: -0.002285, T: 398244, Avg. loss: 0.000987\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.002714, T: 56892, Avg. loss: 0.006076\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.003366, T: 113784, Avg. loss: 0.001054\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.001930, T: 170676, Avg. loss: 0.001055\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.001991, T: 227568, Avg. loss: 0.001054\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.002615, T: 284460, Avg. loss: 0.001054\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002353, T: 341352, Avg. loss: 0.001055\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002239, T: 398244, Avg. loss: 0.001054\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.002375, T: 56892, Avg. loss: 0.006092\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.001737, T: 113784, Avg. loss: 0.001087\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.002130, T: 170676, Avg. loss: 0.001086\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.002887, T: 227568, Avg. loss: 0.001086\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.06, NNZs: 1, Bias: -0.003170, T: 284460, Avg. loss: 0.001086\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002702, T: 341352, Avg. loss: 0.001086\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.003607, T: 398244, Avg. loss: 0.001086\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.000866, T: 56892, Avg. loss: 0.006101\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.001300, T: 113784, Avg. loss: 0.001063\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.001256, T: 170676, Avg. loss: 0.001062\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.002334, T: 227568, Avg. loss: 0.001063\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001911, T: 284460, Avg. loss: 0.001062\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001833, T: 341352, Avg. loss: 0.001063\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002291, T: 398244, Avg. loss: 0.001062\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.002617, T: 56892, Avg. loss: 0.006107\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.002442, T: 113784, Avg. loss: 0.001083\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.002936, T: 170676, Avg. loss: 0.001083\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.002510, T: 227568, Avg. loss: 0.001083\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.003009, T: 284460, Avg. loss: 0.001083\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002772, T: 341352, Avg. loss: 0.001084\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002151, T: 398244, Avg. loss: 0.001084\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.000997, T: 56892, Avg. loss: 0.005994\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.001214, T: 113784, Avg. loss: 0.000985\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.001624, T: 170676, Avg. loss: 0.000985\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.001172, T: 227568, Avg. loss: 0.000985\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001637, T: 284460, Avg. loss: 0.000984\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001696, T: 341352, Avg. loss: 0.000985\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001097, T: 398244, Avg. loss: 0.000985\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.022943, T: 56892, Avg. loss: 0.003775\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.022470, T: 113784, Avg. loss: 0.001721\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.019648, T: 170676, Avg. loss: 0.001727\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.020858, T: 227568, Avg. loss: 0.001728\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.020576, T: 284460, Avg. loss: 0.001722\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.021952, T: 341352, Avg. loss: 0.001724\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.024801, T: 398244, Avg. loss: 0.001726\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.018135, T: 56892, Avg. loss: 0.003805\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.018716, T: 113784, Avg. loss: 0.001810\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.018196, T: 170676, Avg. loss: 0.001805\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.018689, T: 227568, Avg. loss: 0.001809\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.016955, T: 284460, Avg. loss: 0.001804\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.017446, T: 341352, Avg. loss: 0.001806\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.015908, T: 398244, Avg. loss: 0.001805\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.026594, T: 56892, Avg. loss: 0.003868\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.024519, T: 113784, Avg. loss: 0.001780\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.025924, T: 170676, Avg. loss: 0.001776\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.026219, T: 227568, Avg. loss: 0.001776\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.024792, T: 284460, Avg. loss: 0.001773\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.021865, T: 341352, Avg. loss: 0.001780\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.021923, T: 398244, Avg. loss: 0.001770\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.021752, T: 56892, Avg. loss: 0.003860\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.99, NNZs: 1, Bias: 0.019765, T: 113784, Avg. loss: 0.001821\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.020685, T: 170676, Avg. loss: 0.001815\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.022405, T: 227568, Avg. loss: 0.001809\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.019630, T: 284460, Avg. loss: 0.001816\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.015061, T: 341352, Avg. loss: 0.001811\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.021178, T: 398244, Avg. loss: 0.001813\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.021714, T: 56892, Avg. loss: 0.003292\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.021383, T: 113784, Avg. loss: 0.001184\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.017840, T: 170676, Avg. loss: 0.001191\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.022074, T: 227568, Avg. loss: 0.001180\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.021975, T: 284460, Avg. loss: 0.001180\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.022293, T: 341352, Avg. loss: 0.001184\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.019407, T: 398244, Avg. loss: 0.001179\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.39, NNZs: 1, Bias: 0.024478, T: 56892, Avg. loss: 0.003790\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.62, NNZs: 1, Bias: 0.021061, T: 113784, Avg. loss: 0.001727\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.78, NNZs: 1, Bias: 0.022246, T: 170676, Avg. loss: 0.001721\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.93, NNZs: 1, Bias: 0.025549, T: 227568, Avg. loss: 0.001727\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.05, NNZs: 1, Bias: 0.022858, T: 284460, Avg. loss: 0.001726\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.17, NNZs: 1, Bias: 0.025784, T: 341352, Avg. loss: 0.001723\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.27, NNZs: 1, Bias: 0.024505, T: 398244, Avg. loss: 0.001721\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.40, NNZs: 1, Bias: 0.020650, T: 56892, Avg. loss: 0.003827\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.62, NNZs: 1, Bias: 0.017615, T: 113784, Avg. loss: 0.001810\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.79, NNZs: 1, Bias: 0.020191, T: 170676, Avg. loss: 0.001811\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.93, NNZs: 1, Bias: 0.017806, T: 227568, Avg. loss: 0.001805\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.06, NNZs: 1, Bias: 0.020011, T: 284460, Avg. loss: 0.001802\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.17, NNZs: 1, Bias: 0.018308, T: 341352, Avg. loss: 0.001806\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.27, NNZs: 1, Bias: 0.021092, T: 398244, Avg. loss: 0.001801\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.39, NNZs: 1, Bias: 0.022793, T: 56892, Avg. loss: 0.003891\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.61, NNZs: 1, Bias: 0.022371, T: 113784, Avg. loss: 0.001775\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.79, NNZs: 1, Bias: 0.023024, T: 170676, Avg. loss: 0.001780\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.93, NNZs: 1, Bias: 0.023979, T: 227568, Avg. loss: 0.001771\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.05, NNZs: 1, Bias: 0.024427, T: 284460, Avg. loss: 0.001776\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.17, NNZs: 1, Bias: 0.023178, T: 341352, Avg. loss: 0.001777\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.27, NNZs: 1, Bias: 0.027970, T: 398244, Avg. loss: 0.001773\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.40, NNZs: 1, Bias: 0.021513, T: 56892, Avg. loss: 0.003883\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.62, NNZs: 1, Bias: 0.018969, T: 113784, Avg. loss: 0.001819\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.79, NNZs: 1, Bias: 0.018046, T: 170676, Avg. loss: 0.001821\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.93, NNZs: 1, Bias: 0.021295, T: 227568, Avg. loss: 0.001813\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.06, NNZs: 1, Bias: 0.019029, T: 284460, Avg. loss: 0.001816\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.17, NNZs: 1, Bias: 0.017803, T: 341352, Avg. loss: 0.001813\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.28, NNZs: 1, Bias: 0.019453, T: 398244, Avg. loss: 0.001815\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.40, NNZs: 1, Bias: 0.017959, T: 56892, Avg. loss: 0.003287\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.62, NNZs: 1, Bias: 0.016193, T: 113784, Avg. loss: 0.001191\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.79, NNZs: 1, Bias: 0.017005, T: 170676, Avg. loss: 0.001185\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.93, NNZs: 1, Bias: 0.020850, T: 227568, Avg. loss: 0.001182\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.06, NNZs: 1, Bias: 0.019949, T: 284460, Avg. loss: 0.001185\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.17, NNZs: 1, Bias: 0.022429, T: 341352, Avg. loss: 0.001183\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 2.28, NNZs: 1, Bias: 0.018759, T: 398244, Avg. loss: 0.001184\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.025403, T: 56892, Avg. loss: 0.003804\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.025118, T: 113784, Avg. loss: 0.001725\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.024020, T: 170676, Avg. loss: 0.001727\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.024433, T: 227568, Avg. loss: 0.001721\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.019629, T: 284460, Avg. loss: 0.001724\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.023118, T: 341352, Avg. loss: 0.001724\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.022346, T: 398244, Avg. loss: 0.001723\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.018960, T: 56892, Avg. loss: 0.003903\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.017814, T: 113784, Avg. loss: 0.001812\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.020353, T: 170676, Avg. loss: 0.001807\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.016581, T: 227568, Avg. loss: 0.001804\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.021866, T: 284460, Avg. loss: 0.001800\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.016783, T: 341352, Avg. loss: 0.001808\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.017683, T: 398244, Avg. loss: 0.001811\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.023083, T: 56892, Avg. loss: 0.003811\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.022658, T: 113784, Avg. loss: 0.001778\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.019365, T: 170676, Avg. loss: 0.001779\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.023783, T: 227568, Avg. loss: 0.001772\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.026395, T: 284460, Avg. loss: 0.001776\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.025036, T: 341352, Avg. loss: 0.001771\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.025395, T: 398244, Avg. loss: 0.001777\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.016775, T: 56892, Avg. loss: 0.003776\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.06, NNZs: 1, Bias: 0.018731, T: 113784, Avg. loss: 0.001814\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.021680, T: 170676, Avg. loss: 0.001811\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.021044, T: 227568, Avg. loss: 0.001813\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.023536, T: 284460, Avg. loss: 0.001811\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.018816, T: 341352, Avg. loss: 0.001817\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.016048, T: 398244, Avg. loss: 0.001812\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.023674, T: 56892, Avg. loss: 0.003277\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.017665, T: 113784, Avg. loss: 0.001186\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.020343, T: 170676, Avg. loss: 0.001186\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.022587, T: 227568, Avg. loss: 0.001180\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.019845, T: 284460, Avg. loss: 0.001181\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.017789, T: 341352, Avg. loss: 0.001181\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.019060, T: 398244, Avg. loss: 0.001181\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.007392, T: 56892, Avg. loss: 0.001685\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002780, T: 113784, Avg. loss: 0.001236\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004115, T: 170676, Avg. loss: 0.001237\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004420, T: 227568, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001375, T: 284460, Avg. loss: 0.001236\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003920, T: 341352, Avg. loss: 0.001236\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000357, T: 56892, Avg. loss: 0.001713\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002693, T: 113784, Avg. loss: 0.001266\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000262, T: 170676, Avg. loss: 0.001267\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003388, T: 227568, Avg. loss: 0.001267\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000522, T: 284460, Avg. loss: 0.001265\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001235, T: 341352, Avg. loss: 0.001267\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.007726, T: 56892, Avg. loss: 0.001702\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000573, T: 113784, Avg. loss: 0.001261\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001730, T: 170676, Avg. loss: 0.001262\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.99, NNZs: 1, Bias: -0.005761, T: 227568, Avg. loss: 0.001262\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000873, T: 284460, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002519, T: 341352, Avg. loss: 0.001262\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001969, T: 56892, Avg. loss: 0.001708\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000502, T: 113784, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000877, T: 170676, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001389, T: 227568, Avg. loss: 0.001270\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000799, T: 284460, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002202, T: 341352, Avg. loss: 0.001270\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003744, T: 56892, Avg. loss: 0.001503\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002886, T: 113784, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000457, T: 170676, Avg. loss: 0.001056\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002043, T: 227568, Avg. loss: 0.001057\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.005265, T: 284460, Avg. loss: 0.001058\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004879, T: 341352, Avg. loss: 0.001057\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.46, NNZs: 1, Bias: -0.004242, T: 56892, Avg. loss: 0.001680\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.81, NNZs: 1, Bias: -0.001067, T: 113784, Avg. loss: 0.001237\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.10, NNZs: 1, Bias: -0.004741, T: 170676, Avg. loss: 0.001236\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.35, NNZs: 1, Bias: 0.000272, T: 227568, Avg. loss: 0.001236\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.58, NNZs: 1, Bias: -0.000726, T: 284460, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.79, NNZs: 1, Bias: 0.000998, T: 341352, Avg. loss: 0.001237\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.46, NNZs: 1, Bias: 0.000036, T: 56892, Avg. loss: 0.001711\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.81, NNZs: 1, Bias: -0.002434, T: 113784, Avg. loss: 0.001266\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.09, NNZs: 1, Bias: -0.006740, T: 170676, Avg. loss: 0.001268\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.35, NNZs: 1, Bias: -0.001228, T: 227568, Avg. loss: 0.001266\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.58, NNZs: 1, Bias: -0.005311, T: 284460, Avg. loss: 0.001266\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.79, NNZs: 1, Bias: -0.001357, T: 341352, Avg. loss: 0.001267\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.46, NNZs: 1, Bias: 0.003137, T: 56892, Avg. loss: 0.001709\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.81, NNZs: 1, Bias: 0.004072, T: 113784, Avg. loss: 0.001261\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.10, NNZs: 1, Bias: 0.003669, T: 170676, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.35, NNZs: 1, Bias: 0.003224, T: 227568, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.58, NNZs: 1, Bias: -0.005207, T: 284460, Avg. loss: 0.001262\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.79, NNZs: 1, Bias: 0.003370, T: 341352, Avg. loss: 0.001261\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.46, NNZs: 1, Bias: 0.004238, T: 56892, Avg. loss: 0.001717\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.81, NNZs: 1, Bias: -0.003664, T: 113784, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.10, NNZs: 1, Bias: 0.002699, T: 170676, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.35, NNZs: 1, Bias: -0.000572, T: 227568, Avg. loss: 0.001270\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.58, NNZs: 1, Bias: -0.004013, T: 284460, Avg. loss: 0.001270\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 2.79, NNZs: 1, Bias: -0.001496, T: 341352, Avg. loss: 0.001269\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.46, NNZs: 1, Bias: 0.004337, T: 56892, Avg. loss: 0.001502\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.81, NNZs: 1, Bias: 0.001242, T: 113784, Avg. loss: 0.001056\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.10, NNZs: 1, Bias: -0.001146, T: 170676, Avg. loss: 0.001057\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.35, NNZs: 1, Bias: -0.002030, T: 227568, Avg. loss: 0.001057\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.58, NNZs: 1, Bias: -0.001841, T: 284460, Avg. loss: 0.001058\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.79, NNZs: 1, Bias: -0.000028, T: 341352, Avg. loss: 0.001058\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.000079, T: 56892, Avg. loss: 0.001675\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.000912, T: 113784, Avg. loss: 0.001237\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.001840, T: 170676, Avg. loss: 0.001237\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001224, T: 227568, Avg. loss: 0.001237\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.004724, T: 284460, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.002150, T: 341352, Avg. loss: 0.001236\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.002724, T: 56892, Avg. loss: 0.001708\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.006855, T: 113784, Avg. loss: 0.001267\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001551, T: 170676, Avg. loss: 0.001266\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002768, T: 227568, Avg. loss: 0.001267\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.004607, T: 284460, Avg. loss: 0.001267\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.09, NNZs: 1, Bias: -0.002480, T: 341352, Avg. loss: 0.001267\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.000434, T: 56892, Avg. loss: 0.001705\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.005341, T: 113784, Avg. loss: 0.001262\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.000840, T: 170676, Avg. loss: 0.001259\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.002833, T: 227568, Avg. loss: 0.001262\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.004372, T: 284460, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.000663, T: 341352, Avg. loss: 0.001261\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.001689, T: 56892, Avg. loss: 0.001717\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.002779, T: 113784, Avg. loss: 0.001270\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.009716, T: 170676, Avg. loss: 0.001268\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.004147, T: 227568, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.002483, T: 284460, Avg. loss: 0.001270\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.002661, T: 341352, Avg. loss: 0.001269\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.000016, T: 56892, Avg. loss: 0.001499\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002841, T: 113784, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.003710, T: 170676, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.001947, T: 227568, Avg. loss: 0.001057\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.002177, T: 284460, Avg. loss: 0.001057\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001070, T: 341352, Avg. loss: 0.001057\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.005516, T: 56892, Avg. loss: 0.001791\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004321, T: 113784, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003440, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.001933, T: 227568, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002494, T: 284460, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001490, T: 341352, Avg. loss: 0.001011\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000218, T: 56892, Avg. loss: 0.001830\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001924, T: 113784, Avg. loss: 0.001043\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.010741, T: 170676, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004444, T: 227568, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000643, T: 284460, Avg. loss: 0.001043\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003130, T: 341352, Avg. loss: 0.001043\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002494, T: 56892, Avg. loss: 0.001801\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003168, T: 113784, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001282, T: 170676, Avg. loss: 0.001020\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001300, T: 227568, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002973, T: 284460, Avg. loss: 0.001020\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000002, T: 341352, Avg. loss: 0.001018\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001251, T: 56892, Avg. loss: 0.001817\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000331, T: 113784, Avg. loss: 0.001041\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001917, T: 170676, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002703, T: 227568, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004468, T: 284460, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001023, T: 341352, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002447, T: 56892, Avg. loss: 0.001724\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001297, T: 113784, Avg. loss: 0.000942\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003469, T: 170676, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002985, T: 227568, Avg. loss: 0.000942\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001738, T: 284460, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.006746, T: 341352, Avg. loss: 0.000942\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.46, NNZs: 1, Bias: -0.001689, T: 56892, Avg. loss: 0.001797\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.80, NNZs: 1, Bias: -0.006981, T: 113784, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.09, NNZs: 1, Bias: 0.001669, T: 170676, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.35, NNZs: 1, Bias: -0.004581, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.58, NNZs: 1, Bias: -0.002285, T: 284460, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.79, NNZs: 1, Bias: -0.003061, T: 341352, Avg. loss: 0.001011\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.45, NNZs: 1, Bias: -0.001139, T: 56892, Avg. loss: 0.001832\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.80, NNZs: 1, Bias: -0.005260, T: 113784, Avg. loss: 0.001043\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.09, NNZs: 1, Bias: -0.005519, T: 170676, Avg. loss: 0.001043\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.35, NNZs: 1, Bias: -0.005773, T: 227568, Avg. loss: 0.001043\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.58, NNZs: 1, Bias: -0.005278, T: 284460, Avg. loss: 0.001043\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.79, NNZs: 1, Bias: -0.004480, T: 341352, Avg. loss: 0.001043\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.45, NNZs: 1, Bias: -0.000217, T: 56892, Avg. loss: 0.001807\n",
            "Total training time: 0.00 seconds."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch 2\n",
            "Norm: 1.80, NNZs: 1, Bias: 0.001579, T: 113784, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.09, NNZs: 1, Bias: -0.004677, T: 170676, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.35, NNZs: 1, Bias: -0.004370, T: 227568, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.58, NNZs: 1, Bias: -0.001726, T: 284460, Avg. loss: 0.001019\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.79, NNZs: 1, Bias: -0.001352, T: 341352, Avg. loss: 0.001018\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.45, NNZs: 1, Bias: -0.003080, T: 56892, Avg. loss: 0.001827\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.80, NNZs: 1, Bias: -0.002507, T: 113784, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.09, NNZs: 1, Bias: -0.002831, T: 170676, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.35, NNZs: 1, Bias: -0.004823, T: 227568, Avg. loss: 0.001041\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.58, NNZs: 1, Bias: -0.000076, T: 284460, Avg. loss: 0.001041\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.79, NNZs: 1, Bias: -0.000720, T: 341352, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.46, NNZs: 1, Bias: 0.000392, T: 56892, Avg. loss: 0.001729\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.80, NNZs: 1, Bias: 0.001539, T: 113784, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.09, NNZs: 1, Bias: 0.005264, T: 170676, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.35, NNZs: 1, Bias: 0.000165, T: 227568, Avg. loss: 0.000942\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.58, NNZs: 1, Bias: 0.001354, T: 284460, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.79, NNZs: 1, Bias: 0.006224, T: 341352, Avg. loss: 0.000941\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.002476, T: 56892, Avg. loss: 0.001795\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000668, T: 113784, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.004116, T: 170676, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.007311, T: 227568, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.001325, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.003930, T: 341352, Avg. loss: 0.001011\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.005234, T: 56892, Avg. loss: 0.001824\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000288, T: 113784, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.003654, T: 170676, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.002291, T: 227568, Avg. loss: 0.001043\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.005430, T: 284460, Avg. loss: 0.001043\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.002906, T: 341352, Avg. loss: 0.001043\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.002222, T: 56892, Avg. loss: 0.001803\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000840, T: 113784, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.003916, T: 170676, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.001053, T: 227568, Avg. loss: 0.001020\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.001749, T: 284460, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.000523, T: 341352, Avg. loss: 0.001019\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.006359, T: 56892, Avg. loss: 0.001822\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.001528, T: 113784, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001594, T: 170676, Avg. loss: 0.001041\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.002024, T: 227568, Avg. loss: 0.001040\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.004024, T: 284460, Avg. loss: 0.001040\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.003828, T: 341352, Avg. loss: 0.001040\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.002563, T: 56892, Avg. loss: 0.001721\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001049, T: 113784, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.000236, T: 170676, Avg. loss: 0.000942\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.001870, T: 227568, Avg. loss: 0.000942\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001908, T: 284460, Avg. loss: 0.000941\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.006073, T: 341352, Avg. loss: 0.000940\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002574\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.001817\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001827\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000000, T: 227568, Avg. loss: 0.001817\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001830\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001820\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002646\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001942\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.010000, T: 170676, Avg. loss: 0.001927\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.000000, T: 227568, Avg. loss: 0.001936\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001946\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001931\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.002611\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001901\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001890\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.001880\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001902\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.030000, T: 341352, Avg. loss: 0.001896\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002684\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.010000, T: 113784, Avg. loss: 0.001949\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001945\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.001952\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001955\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000000, T: 341352, Avg. loss: 0.001934\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.001996\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.030000, T: 113784, Avg. loss: 0.001276\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001253\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000000, T: 284460, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.001280\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.49, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002573\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.82, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001824\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.12, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001834\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.36, NNZs: 1, Bias: 0.000000, T: 227568, Avg. loss: 0.001818\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.59, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001821\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.81, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001833\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.49, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002660\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.82, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001950\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.12, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001949\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.37, NNZs: 1, Bias: 0.000000, T: 227568, Avg. loss: 0.001928\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.60, NNZs: 1, Bias: 0.000000, T: 284460, Avg. loss: 0.001947\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.80, NNZs: 1, Bias: -0.010000, T: 341352, Avg. loss: 0.001959\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.47, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002628\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.83, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001871\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.11, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001894\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.37, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001904\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.59, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001896\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.81, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001894\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.47, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002657\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.81, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001961\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.11, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001946\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.37, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001956\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.60, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001938\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.81, NNZs: 1, Bias: -0.010000, T: 341352, Avg. loss: 0.001931\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.48, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002011\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.83, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001281\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.12, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001268\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.37, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.61, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001289\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2.82, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001255\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002554\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.030000, T: 113784, Avg. loss: 0.001824\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.09, NNZs: 1, Bias: -0.010000, T: 170676, Avg. loss: 0.001824\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001844\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.09, NNZs: 1, Bias: -0.000000, T: 284460, Avg. loss: 0.001837\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.09, NNZs: 1, Bias: -0.000000, T: 341352, Avg. loss: 0.001830\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002699\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001949\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.000000, T: 170676, Avg. loss: 0.001937\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.09, NNZs: 1, Bias: -0.010000, T: 227568, Avg. loss: 0.001950\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001932\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.11, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.001949\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002633\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001908\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001883\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001886\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.030000, T: 284460, Avg. loss: 0.001883\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.010000, T: 341352, Avg. loss: 0.001896\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.06, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.002663\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.001960\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.030000, T: 170676, Avg. loss: 0.001930\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.09, NNZs: 1, Bias: -0.000000, T: 227568, Avg. loss: 0.001918\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000000, T: 284460, Avg. loss: 0.001943\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001952\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002007\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001276\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.010000, T: 170676, Avg. loss: 0.001282\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.010000, T: 227568, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001282\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001273\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: nan, NNZs: 1, Bias: -0.000724, T: 56892, Avg. loss: 40590790283467320983552.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: nan, NNZs: 1, Bias: 0.003599, T: 113784, Avg. loss: 0.001239\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: nan, NNZs: 1, Bias: -0.002320, T: 170676, Avg. loss: 0.001232\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: nan, NNZs: 1, Bias: -0.001064, T: 227568, Avg. loss: 0.001231\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: nan, NNZs: 1, Bias: 0.001161, T: 284460, Avg. loss: 0.001227\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: nan, NNZs: 1, Bias: 0.001082, T: 341352, Avg. loss: 0.001226\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: nan, NNZs: 1, Bias: -0.001827, T: 398244, Avg. loss: 0.001226\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1159.11, NNZs: 1, Bias: 0.007068, T: 56892, Avg. loss: 42436034749175835918336.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 580.46, NNZs: 1, Bias: 0.002466, T: 113784, Avg. loss: 0.001271\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 387.17, NNZs: 1, Bias: -0.003470, T: 170676, Avg. loss: 0.001262\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 290.45, NNZs: 1, Bias: 0.001854, T: 227568, Avg. loss: 0.001259\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 232.40, NNZs: 1, Bias: -0.002370, T: 284460, Avg. loss: 0.001258\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 193.69, NNZs: 1, Bias: -0.000825, T: 341352, Avg. loss: 0.001257\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 166.03, NNZs: 1, Bias: -0.002367, T: 398244, Avg. loss: 0.001256\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: nan, NNZs: 1, Bias: -0.003553, T: 56892, Avg. loss: 39746850504423711440896.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: nan, NNZs: 1, Bias: 0.000418, T: 113784, Avg. loss: 0.001264\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: nan, NNZs: 1, Bias: -0.005918, T: 170676, Avg. loss: 0.001257\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: nan, NNZs: 1, Bias: -0.001532, T: 227568, Avg. loss: 0.001254\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: nan, NNZs: 1, Bias: 0.001782, T: 284460, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: nan, NNZs: 1, Bias: 0.000328, T: 341352, Avg. loss: 0.001251\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: nan, NNZs: 1, Bias: -0.000195, T: 398244, Avg. loss: 0.001250\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1413.12, NNZs: 1, Bias: -0.000881, T: 56892, Avg. loss: 36698979574608100851712.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 707.66, NNZs: 1, Bias: 0.000144, T: 113784, Avg. loss: 0.001274\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 472.02, NNZs: 1, Bias: 0.002478, T: 170676, Avg. loss: 0.001264\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 354.10, NNZs: 1, Bias: -0.000961, T: 227568, Avg. loss: 0.001262\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 283.33, NNZs: 1, Bias: 0.001289, T: 284460, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 236.13, NNZs: 1, Bias: -0.000569, T: 341352, Avg. loss: 0.001260\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 202.41, NNZs: 1, Bias: -0.001511, T: 398244, Avg. loss: 0.001258\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: nan, NNZs: 1, Bias: 0.005629, T: 56892, Avg. loss: 37835807475486894850048.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: nan, NNZs: 1, Bias: -0.003086, T: 113784, Avg. loss: 0.001060\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: nan, NNZs: 1, Bias: 0.001088, T: 170676, Avg. loss: 0.001054\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: nan, NNZs: 1, Bias: -0.001658, T: 227568, Avg. loss: 0.001051\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: nan, NNZs: 1, Bias: 0.001531, T: 284460, Avg. loss: 0.001050\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: nan, NNZs: 1, Bias: -0.001176, T: 341352, Avg. loss: 0.001048\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: nan, NNZs: 1, Bias: -0.000537, T: 398244, Avg. loss: 0.001048\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 34722289.16, NNZs: 1, Bias: 0.004133, T: 56892, Avg. loss: 38900423929144446812160.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 34722289.16, NNZs: 1, Bias: 0.001399, T: 113784, Avg. loss: 0.001239\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 34722289.16, NNZs: 1, Bias: 0.001117, T: 170676, Avg. loss: 0.001232\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 34722289.16, NNZs: 1, Bias: 0.000529, T: 227568, Avg. loss: 0.001229\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 34722289.16, NNZs: 1, Bias: -0.000304, T: 284460, Avg. loss: 0.001228\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 34722289.16, NNZs: 1, Bias: 0.000229, T: 341352, Avg. loss: 0.001227\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 34722289.16, NNZs: 1, Bias: 0.000541, T: 398244, Avg. loss: 0.001227\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 37513527.52, NNZs: 1, Bias: -0.008228, T: 56892, Avg. loss: 37608479068746470653952.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 37513527.52, NNZs: 1, Bias: -0.001434, T: 113784, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 37513527.52, NNZs: 1, Bias: 0.001653, T: 170676, Avg. loss: 0.001263\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 37513527.52, NNZs: 1, Bias: -0.002152, T: 227568, Avg. loss: 0.001259\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 37513527.52, NNZs: 1, Bias: -0.000898, T: 284460, Avg. loss: 0.001258\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 37513527.52, NNZs: 1, Bias: 0.000335, T: 341352, Avg. loss: 0.001257\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 37513527.52, NNZs: 1, Bias: -0.001596, T: 398244, Avg. loss: 0.001256\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 35443353.13, NNZs: 1, Bias: 0.000627, T: 56892, Avg. loss: 36980931960616928673792.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 35443353.13, NNZs: 1, Bias: 0.000281, T: 113784, Avg. loss: 0.001264\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 35443353.13, NNZs: 1, Bias: 0.000247, T: 170676, Avg. loss: 0.001258\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 35443353.13, NNZs: 1, Bias: 0.001860, T: 227568, Avg. loss: 0.001254\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 35443353.13, NNZs: 1, Bias: 0.003973, T: 284460, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 35443353.13, NNZs: 1, Bias: 0.000591, T: 341352, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 35443353.13, NNZs: 1, Bias: -0.001003, T: 398244, Avg. loss: 0.001251\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 31621975.80, NNZs: 1, Bias: 0.004935, T: 56892, Avg. loss: 40171675751944290304000.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 31621975.80, NNZs: 1, Bias: 0.004975, T: 113784, Avg. loss: 0.001273\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 31621975.80, NNZs: 1, Bias: 0.001420, T: 170676, Avg. loss: 0.001266\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 31621975.80, NNZs: 1, Bias: -0.000778, T: 227568, Avg. loss: 0.001263\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 31621975.80, NNZs: 1, Bias: 0.003609, T: 284460, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 31621975.80, NNZs: 1, Bias: 0.001150, T: 341352, Avg. loss: 0.001259\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 31621975.80, NNZs: 1, Bias: 0.002945, T: 398244, Avg. loss: 0.001259\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 37088403.18, NNZs: 1, Bias: -0.003571, T: 56892, Avg. loss: 36769417240178744885248.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 37088403.18, NNZs: 1, Bias: 0.001179, T: 113784, Avg. loss: 0.001059\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 37088403.18, NNZs: 1, Bias: -0.001374, T: 170676, Avg. loss: 0.001054\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 37088403.18, NNZs: 1, Bias: -0.002551, T: 227568, Avg. loss: 0.001052\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 37088403.18, NNZs: 1, Bias: 0.001397, T: 284460, Avg. loss: 0.001050\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 37088403.18, NNZs: 1, Bias: -0.000816, T: 341352, Avg. loss: 0.001048\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 37088403.18, NNZs: 1, Bias: 0.000641, T: 398244, Avg. loss: 0.001048\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 252655.07, NNZs: 1, Bias: 0.001785, T: 56892, Avg. loss: 40843981895733683945472.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 140354.10, NNZs: 1, Bias: 0.002013, T: 113784, Avg. loss: 0.001240\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 99480.65, NNZs: 1, Bias: 0.000009, T: 170676, Avg. loss: 0.001234\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 77917.72, NNZs: 1, Bias: -0.001352, T: 227568, Avg. loss: 0.001229\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 64464.42, NNZs: 1, Bias: -0.001557, T: 284460, Avg. loss: 0.001228\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 55214.64, NNZs: 1, Bias: 0.002875, T: 341352, Avg. loss: 0.001227\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 48436.95, NNZs: 1, Bias: 0.000524, T: 398244, Avg. loss: 0.001226\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 244562.58, NNZs: 1, Bias: 0.001947, T: 56892, Avg. loss: 40545868515286462758912.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 135858.59, NNZs: 1, Bias: 0.000277, T: 113784, Avg. loss: 0.001270\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 96294.30, NNZs: 1, Bias: -0.001621, T: 170676, Avg. loss: 0.001262\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 75422.03, NNZs: 1, Bias: -0.001052, T: 227568, Avg. loss: 0.001259\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 62399.64, NNZs: 1, Bias: -0.003677, T: 284460, Avg. loss: 0.001258\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 53446.13, NNZs: 1, Bias: -0.000957, T: 341352, Avg. loss: 0.001256\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 46885.53, NNZs: 1, Bias: 0.001161, T: 398244, Avg. loss: 0.001256\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 323402.65, NNZs: 1, Bias: 0.006260, T: 56892, Avg. loss: 40764596276769721417728.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 179655.56, NNZs: 1, Bias: 0.003459, T: 113784, Avg. loss: 0.001265\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 127336.87, NNZs: 1, Bias: 0.005618, T: 170676, Avg. loss: 0.001256\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 99735.97, NNZs: 1, Bias: -0.001441, T: 227568, Avg. loss: 0.001253\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 82515.52, NNZs: 1, Bias: -0.003963, T: 284460, Avg. loss: 0.001251\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 70675.65, NNZs: 1, Bias: 0.002394, T: 341352, Avg. loss: 0.001251\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 62000.10, NNZs: 1, Bias: 0.002393, T: 398244, Avg. loss: 0.001250\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 273788.83, NNZs: 1, Bias: -0.005688, T: 56892, Avg. loss: 39180627836118222503936.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 152094.26, NNZs: 1, Bias: 0.004633, T: 113784, Avg. loss: 0.001272\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 107801.88, NNZs: 1, Bias: -0.002842, T: 170676, Avg. loss: 0.001266\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 84435.28, NNZs: 1, Bias: -0.007004, T: 227568, Avg. loss: 0.001263\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 69856.66, NNZs: 1, Bias: -0.000441, T: 284460, Avg. loss: 0.001261\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 59833.17, NNZs: 1, Bias: -0.001362, T: 341352, Avg. loss: 0.001260\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 52488.54, NNZs: 1, Bias: -0.002914, T: 398244, Avg. loss: 0.001259\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 254360.72, NNZs: 1, Bias: -0.006425, T: 56892, Avg. loss: 36613149001557777317888.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 141301.62, NNZs: 1, Bias: 0.000776, T: 113784, Avg. loss: 0.001060\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 100152.23, NNZs: 1, Bias: 0.001080, T: 170676, Avg. loss: 0.001053\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 78443.74, NNZs: 1, Bias: 0.000723, T: 227568, Avg. loss: 0.001051\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 64899.62, NNZs: 1, Bias: 0.000041, T: 284460, Avg. loss: 0.001049\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 55587.39, NNZs: 1, Bias: 0.003890, T: 341352, Avg. loss: 0.001049\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 48763.95, NNZs: 1, Bias: 0.000333, T: 398244, Avg. loss: 0.001048\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000619, T: 56892, Avg. loss: 0.001281\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005290, T: 113784, Avg. loss: 0.001013\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: 0.003751, T: 170676, Avg. loss: 0.001008\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000640, T: 227568, Avg. loss: 0.001007\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001790, T: 284460, Avg. loss: 0.001005\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003376, T: 341352, Avg. loss: 0.001005\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001933, T: 56892, Avg. loss: 0.001314\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003445, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003096, T: 170676, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000385, T: 227568, Avg. loss: 0.001038\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001538, T: 284460, Avg. loss: 0.001037\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.005783, T: 341352, Avg. loss: 0.001036\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000675, T: 56892, Avg. loss: 0.001281\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004277, T: 113784, Avg. loss: 0.001021\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000553, T: 170676, Avg. loss: 0.001016\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003379, T: 227568, Avg. loss: 0.001014\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001799, T: 284460, Avg. loss: 0.001014\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001678, T: 341352, Avg. loss: 0.001013\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001128, T: 56892, Avg. loss: 0.001302\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.005339, T: 113784, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003507, T: 170676, Avg. loss: 0.001038\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001347, T: 227568, Avg. loss: 0.001036\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004959, T: 284460, Avg. loss: 0.001035\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003961, T: 341352, Avg. loss: 0.001034\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001235, T: 56892, Avg. loss: 0.001210\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000790, T: 113784, Avg. loss: 0.000944\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004146, T: 170676, Avg. loss: 0.000938\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001676, T: 227568, Avg. loss: 0.000937\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001493, T: 284460, Avg. loss: 0.000936\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001367, T: 341352, Avg. loss: 0.000936\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.54, NNZs: 1, Bias: -0.001104, T: 56892, Avg. loss: 0.001283\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.73, NNZs: 1, Bias: -0.003400, T: 113784, Avg. loss: 0.001013\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 3.84, NNZs: 1, Bias: -0.004090, T: 170676, Avg. loss: 0.001009\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 3.91, NNZs: 1, Bias: -0.000345, T: 227568, Avg. loss: 0.001006\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 3.97, NNZs: 1, Bias: -0.000417, T: 284460, Avg. loss: 0.001006\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.01, NNZs: 1, Bias: -0.002786, T: 341352, Avg. loss: 0.001005\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.54, NNZs: 1, Bias: -0.004958, T: 56892, Avg. loss: 0.001313\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.73, NNZs: 1, Bias: 0.006216, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 3.83, NNZs: 1, Bias: -0.001815, T: 170676, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 3.91, NNZs: 1, Bias: -0.002570, T: 227568, Avg. loss: 0.001038\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 3.96, NNZs: 1, Bias: -0.001769, T: 284460, Avg. loss: 0.001037\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.01, NNZs: 1, Bias: -0.001768, T: 341352, Avg. loss: 0.001037\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.53, NNZs: 1, Bias: -0.003409, T: 56892, Avg. loss: 0.001287\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 3.72, NNZs: 1, Bias: -0.002481, T: 113784, Avg. loss: 0.001021\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 3.83, NNZs: 1, Bias: -0.005472, T: 170676, Avg. loss: 0.001017\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 3.90, NNZs: 1, Bias: -0.001782, T: 227568, Avg. loss: 0.001015\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 3.96, NNZs: 1, Bias: -0.001033, T: 284460, Avg. loss: 0.001014\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.00, NNZs: 1, Bias: -0.000185, T: 341352, Avg. loss: 0.001013\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.54, NNZs: 1, Bias: -0.001796, T: 56892, Avg. loss: 0.001309\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.73, NNZs: 1, Bias: -0.004884, T: 113784, Avg. loss: 0.001043\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 3.84, NNZs: 1, Bias: 0.000983, T: 170676, Avg. loss: 0.001037\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 3.91, NNZs: 1, Bias: -0.001864, T: 227568, Avg. loss: 0.001035\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 3.97, NNZs: 1, Bias: -0.000388, T: 284460, Avg. loss: 0.001035\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.01, NNZs: 1, Bias: -0.002381, T: 341352, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.53, NNZs: 1, Bias: 0.003080, T: 56892, Avg. loss: 0.001216\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.72, NNZs: 1, Bias: 0.002966, T: 113784, Avg. loss: 0.000944\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 3.82, NNZs: 1, Bias: -0.001109, T: 170676, Avg. loss: 0.000939\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 3.90, NNZs: 1, Bias: -0.003201, T: 227568, Avg. loss: 0.000937\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 3.95, NNZs: 1, Bias: 0.000286, T: 284460, Avg. loss: 0.000936\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.00, NNZs: 1, Bias: -0.002915, T: 341352, Avg. loss: 0.000936\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.006131, T: 56892, Avg. loss: 0.001285\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001127, T: 113784, Avg. loss: 0.001013\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.004579, T: 170676, Avg. loss: 0.001009\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000349, T: 227568, Avg. loss: 0.001006\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000548, T: 284460, Avg. loss: 0.001006\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.003432, T: 341352, Avg. loss: 0.001005\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001499, T: 56892, Avg. loss: 0.001311\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001834, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.000825, T: 170676, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001934, T: 227568, Avg. loss: 0.001038\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000861, T: 284460, Avg. loss: 0.001038\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.003224, T: 341352, Avg. loss: 0.001037\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001767, T: 56892, Avg. loss: 0.001281\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001018, T: 113784, Avg. loss: 0.001021\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.004185, T: 170676, Avg. loss: 0.001017\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.001291, T: 227568, Avg. loss: 0.001015\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.001009, T: 284460, Avg. loss: 0.001014\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.003497, T: 341352, Avg. loss: 0.001013\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.002126, T: 56892, Avg. loss: 0.001318\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.004687, T: 113784, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000290, T: 170676, Avg. loss: 0.001038\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000047, T: 227568, Avg. loss: 0.001036\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.003439, T: 284460, Avg. loss: 0.001034\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.002820, T: 341352, Avg. loss: 0.001034\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.005530, T: 56892, Avg. loss: 0.001204\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.002253, T: 113784, Avg. loss: 0.000943\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.000469, T: 170676, Avg. loss: 0.000939\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000553, T: 227568, Avg. loss: 0.000937\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.003172, T: 284460, Avg. loss: 0.000936\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.000726, T: 341352, Avg. loss: 0.000935\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008855, T: 56892, Avg. loss: 0.046439\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000157, T: 113784, Avg. loss: 0.001896\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003053, T: 170676, Avg. loss: 0.001762\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008650, T: 227568, Avg. loss: 0.001710\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001867, T: 284460, Avg. loss: 0.001698\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008705, T: 341352, Avg. loss: 0.001687\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008704, T: 398244, Avg. loss: 0.001674\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.043000, T: 56892, Avg. loss: 0.046843\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007005, T: 113784, Avg. loss: 0.002007\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000418, T: 170676, Avg. loss: 0.001877\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010183, T: 227568, Avg. loss: 0.001818\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.005123, T: 284460, Avg. loss: 0.001796\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.016551, T: 341352, Avg. loss: 0.001779\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002096, T: 398244, Avg. loss: 0.001773\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.007984, T: 56892, Avg. loss: 0.041427\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009394, T: 113784, Avg. loss: 0.001948\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.009188, T: 170676, Avg. loss: 0.001829\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.018072, T: 227568, Avg. loss: 0.001783\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.016370, T: 284460, Avg. loss: 0.001758\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.015232, T: 341352, Avg. loss: 0.001748\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009424, T: 398244, Avg. loss: 0.001737\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.007773, T: 56892, Avg. loss: 0.045124\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.007072, T: 113784, Avg. loss: 0.001990\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.000441, T: 170676, Avg. loss: 0.001864\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.023263, T: 227568, Avg. loss: 0.001832\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.012427, T: 284460, Avg. loss: 0.001795\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000667, T: 341352, Avg. loss: 0.001786\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000073, T: 398244, Avg. loss: 0.001774\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004684, T: 56892, Avg. loss: 0.046860\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.013787, T: 113784, Avg. loss: 0.001341\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.016466, T: 170676, Avg. loss: 0.001216\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000084, T: 227568, Avg. loss: 0.001159\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000529, T: 284460, Avg. loss: 0.001146\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.02, NNZs: 1, Bias: -0.005064, T: 341352, Avg. loss: 0.001123\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001002, T: 398244, Avg. loss: 0.001116\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 23.35, NNZs: 1, Bias: 0.040941, T: 56892, Avg. loss: 0.043285\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 23.38, NNZs: 1, Bias: 0.007329, T: 113784, Avg. loss: 0.001869\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 23.40, NNZs: 1, Bias: 0.019285, T: 170676, Avg. loss: 0.001760\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 23.41, NNZs: 1, Bias: 0.016486, T: 227568, Avg. loss: 0.001729\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 23.42, NNZs: 1, Bias: 0.011304, T: 284460, Avg. loss: 0.001698\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 23.43, NNZs: 1, Bias: 0.010814, T: 341352, Avg. loss: 0.001690\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 23.44, NNZs: 1, Bias: 0.000382, T: 398244, Avg. loss: 0.001675\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 22.45, NNZs: 1, Bias: 0.006946, T: 56892, Avg. loss: 0.040380\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 22.48, NNZs: 1, Bias: 0.023604, T: 113784, Avg. loss: 0.001995\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 22.50, NNZs: 1, Bias: 0.005704, T: 170676, Avg. loss: 0.001862\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 22.51, NNZs: 1, Bias: -0.003649, T: 227568, Avg. loss: 0.001802\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 22.53, NNZs: 1, Bias: 0.008228, T: 284460, Avg. loss: 0.001788\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 22.53, NNZs: 1, Bias: -0.007222, T: 341352, Avg. loss: 0.001776\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 22.54, NNZs: 1, Bias: -0.003183, T: 398244, Avg. loss: 0.001769\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 24.67, NNZs: 1, Bias: 0.027485, T: 56892, Avg. loss: 0.044659\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 24.70, NNZs: 1, Bias: 0.009734, T: 113784, Avg. loss: 0.001949\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 24.72, NNZs: 1, Bias: 0.009540, T: 170676, Avg. loss: 0.001822\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 24.73, NNZs: 1, Bias: 0.013857, T: 227568, Avg. loss: 0.001784\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 24.74, NNZs: 1, Bias: 0.016432, T: 284460, Avg. loss: 0.001764\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 24.75, NNZs: 1, Bias: 0.012530, T: 341352, Avg. loss: 0.001751\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 24.75, NNZs: 1, Bias: 0.004669, T: 398244, Avg. loss: 0.001735\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 24.23, NNZs: 1, Bias: 0.025178, T: 56892, Avg. loss: 0.042600\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 24.26, NNZs: 1, Bias: 0.006709, T: 113784, Avg. loss: 0.002017\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 24.27, NNZs: 1, Bias: -0.005450, T: 170676, Avg. loss: 0.001871\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 24.29, NNZs: 1, Bias: 0.005876, T: 227568, Avg. loss: 0.001821\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 24.30, NNZs: 1, Bias: 0.001990, T: 284460, Avg. loss: 0.001799\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 24.30, NNZs: 1, Bias: 0.002484, T: 341352, Avg. loss: 0.001787\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 24.31, NNZs: 1, Bias: 0.010171, T: 398244, Avg. loss: 0.001775\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 23.69, NNZs: 1, Bias: -0.011459, T: 56892, Avg. loss: 0.042065\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 23.72, NNZs: 1, Bias: -0.002817, T: 113784, Avg. loss: 0.001331\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 23.74, NNZs: 1, Bias: 0.016906, T: 170676, Avg. loss: 0.001203\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 23.75, NNZs: 1, Bias: 0.004785, T: 227568, Avg. loss: 0.001157\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 23.76, NNZs: 1, Bias: 0.007850, T: 284460, Avg. loss: 0.001144\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 23.77, NNZs: 1, Bias: 0.001140, T: 341352, Avg. loss: 0.001128\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 23.78, NNZs: 1, Bias: 0.001260, T: 398244, Avg. loss: 0.001113\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.14, NNZs: 1, Bias: 0.009064, T: 56892, Avg. loss: 0.044098\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.017818, T: 113784, Avg. loss: 0.001886\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.002776, T: 170676, Avg. loss: 0.001768\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.012921, T: 227568, Avg. loss: 0.001730\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.008450, T: 284460, Avg. loss: 0.001693\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.005426, T: 341352, Avg. loss: 0.001694\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.10, NNZs: 1, Bias: 0.003286, T: 398244, Avg. loss: 0.001679\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.008228, T: 56892, Avg. loss: 0.045261\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.006915, T: 113784, Avg. loss: 0.001988\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.011756, T: 170676, Avg. loss: 0.001882\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.018576, T: 227568, Avg. loss: 0.001816\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.005127, T: 284460, Avg. loss: 0.001807\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.003900, T: 341352, Avg. loss: 0.001764\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.004675, T: 398244, Avg. loss: 0.001766\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.005130, T: 56892, Avg. loss: 0.048341\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.09, NNZs: 1, Bias: -0.010282, T: 113784, Avg. loss: 0.001950\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.009997, T: 170676, Avg. loss: 0.001838\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.007960, T: 227568, Avg. loss: 0.001780\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.004917, T: 284460, Avg. loss: 0.001757\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.014434, T: 341352, Avg. loss: 0.001736\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.013736, T: 398244, Avg. loss: 0.001737\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.11, NNZs: 1, Bias: 0.022812, T: 56892, Avg. loss: 0.046899\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.005259, T: 113784, Avg. loss: 0.001998\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.006456, T: 170676, Avg. loss: 0.001862\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.012537, T: 227568, Avg. loss: 0.001833\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.008329, T: 284460, Avg. loss: 0.001807\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.013412, T: 341352, Avg. loss: 0.001785\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.014677, T: 398244, Avg. loss: 0.001774\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.13, NNZs: 1, Bias: -0.009124, T: 56892, Avg. loss: 0.043233\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.11, NNZs: 1, Bias: -0.001575, T: 113784, Avg. loss: 0.001325\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.000161, T: 170676, Avg. loss: 0.001208\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.001047, T: 227568, Avg. loss: 0.001163\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.004935, T: 284460, Avg. loss: 0.001134\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.001414, T: 341352, Avg. loss: 0.001132\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.003508, T: 398244, Avg. loss: 0.001122\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001157, T: 56892, Avg. loss: 0.002518\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000623, T: 113784, Avg. loss: 0.001224\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000021, T: 170676, Avg. loss: 0.001223\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000545, T: 227568, Avg. loss: 0.001223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000517, T: 284460, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000656, T: 341352, Avg. loss: 0.001223\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000963, T: 398244, Avg. loss: 0.001223\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000412, T: 56892, Avg. loss: 0.002619\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000203, T: 113784, Avg. loss: 0.001253\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000082, T: 170676, Avg. loss: 0.001252\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000565, T: 227568, Avg. loss: 0.001253\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000987, T: 284460, Avg. loss: 0.001253\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001292, T: 341352, Avg. loss: 0.001252\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000899, T: 398244, Avg. loss: 0.001252\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000867, T: 56892, Avg. loss: 0.002619\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000924, T: 113784, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000972, T: 170676, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001551, T: 227568, Avg. loss: 0.001247\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001446, T: 284460, Avg. loss: 0.001247\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000397, T: 341352, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000239, T: 398244, Avg. loss: 0.001247\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000804, T: 56892, Avg. loss: 0.002552\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000850, T: 113784, Avg. loss: 0.001256\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000285, T: 170676, Avg. loss: 0.001255\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000475, T: 227568, Avg. loss: 0.001256\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000240, T: 284460, Avg. loss: 0.001256\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000772, T: 341352, Avg. loss: 0.001255\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000272, T: 398244, Avg. loss: 0.001256\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000610, T: 56892, Avg. loss: 0.002312\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: 0.001056, T: 113784, Avg. loss: 0.001046\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000006, T: 170676, Avg. loss: 0.001046\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000851, T: 227568, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000241, T: 284460, Avg. loss: 0.001046\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000581, T: 341352, Avg. loss: 0.001045\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000238, T: 398244, Avg. loss: 0.001045\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.000353, T: 56892, Avg. loss: 0.002537\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000974, T: 113784, Avg. loss: 0.001223\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.000511, T: 170676, Avg. loss: 0.001223\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.13, NNZs: 1, Bias: -0.001097, T: 227568, Avg. loss: 0.001223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.15, NNZs: 1, Bias: 0.000265, T: 284460, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.17, NNZs: 1, Bias: 0.000649, T: 341352, Avg. loss: 0.001223\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.19, NNZs: 1, Bias: -0.000851, T: 398244, Avg. loss: 0.001223\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.000343, T: 56892, Avg. loss: 0.002567\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000739, T: 113784, Avg. loss: 0.001253\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.001181, T: 170676, Avg. loss: 0.001253\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.13, NNZs: 1, Bias: 0.000065, T: 227568, Avg. loss: 0.001253\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.15, NNZs: 1, Bias: -0.000207, T: 284460, Avg. loss: 0.001253\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.17, NNZs: 1, Bias: -0.000516, T: 341352, Avg. loss: 0.001253\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.19, NNZs: 1, Bias: -0.000616, T: 398244, Avg. loss: 0.001253\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.000846, T: 56892, Avg. loss: 0.002566\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000133, T: 113784, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.000588, T: 170676, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.13, NNZs: 1, Bias: 0.000880, T: 227568, Avg. loss: 0.001247\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.15, NNZs: 1, Bias: 0.000698, T: 284460, Avg. loss: 0.001247\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.17, NNZs: 1, Bias: 0.000071, T: 341352, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.19, NNZs: 1, Bias: 0.001931, T: 398244, Avg. loss: 0.001247\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.000457, T: 56892, Avg. loss: 0.002616\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.001792, T: 113784, Avg. loss: 0.001256\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.000174, T: 170676, Avg. loss: 0.001256\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.13, NNZs: 1, Bias: -0.000036, T: 227568, Avg. loss: 0.001256\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.15, NNZs: 1, Bias: -0.001286, T: 284460, Avg. loss: 0.001255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.17, NNZs: 1, Bias: -0.000699, T: 341352, Avg. loss: 0.001256\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.19, NNZs: 1, Bias: -0.000614, T: 398244, Avg. loss: 0.001255\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.000440, T: 56892, Avg. loss: 0.002395\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000199, T: 113784, Avg. loss: 0.001046\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.000261, T: 170676, Avg. loss: 0.001046\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.13, NNZs: 1, Bias: 0.000521, T: 227568, Avg. loss: 0.001045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.15, NNZs: 1, Bias: -0.000723, T: 284460, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.17, NNZs: 1, Bias: 0.000752, T: 341352, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.19, NNZs: 1, Bias: 0.000318, T: 398244, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001596, T: 56892, Avg. loss: 0.002546\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000811, T: 113784, Avg. loss: 0.001223\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000150, T: 170676, Avg. loss: 0.001223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000683, T: 227568, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000341, T: 284460, Avg. loss: 0.001223\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000433, T: 341352, Avg. loss: 0.001223\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000118, T: 398244, Avg. loss: 0.001223\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002016, T: 56892, Avg. loss: 0.002628\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001606, T: 113784, Avg. loss: 0.001253\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000173, T: 170676, Avg. loss: 0.001253\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001357, T: 227568, Avg. loss: 0.001253\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001496, T: 284460, Avg. loss: 0.001253\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000878, T: 341352, Avg. loss: 0.001253\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001638, T: 398244, Avg. loss: 0.001253\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000824, T: 56892, Avg. loss: 0.002560\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002216, T: 113784, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000383, T: 170676, Avg. loss: 0.001247\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001801, T: 227568, Avg. loss: 0.001247\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001270, T: 284460, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000138, T: 341352, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000603, T: 398244, Avg. loss: 0.001247\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000333, T: 56892, Avg. loss: 0.002586\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000981, T: 113784, Avg. loss: 0.001256\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001889, T: 170676, Avg. loss: 0.001255\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000082, T: 227568, Avg. loss: 0.001256\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001289, T: 284460, Avg. loss: 0.001255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000371, T: 341352, Avg. loss: 0.001255\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000041, T: 398244, Avg. loss: 0.001256\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000649, T: 56892, Avg. loss: 0.002376\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000554, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: 0.000478, T: 170676, Avg. loss: 0.001046\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001022, T: 227568, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000173, T: 284460, Avg. loss: 0.001045\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000128, T: 341352, Avg. loss: 0.001046\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000656, T: 398244, Avg. loss: 0.001045\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 7 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002665, T: 56892, Avg. loss: 0.005758\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001381, T: 113784, Avg. loss: 0.001003\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002425, T: 170676, Avg. loss: 0.001003\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002138, T: 227568, Avg. loss: 0.001002\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003129, T: 284460, Avg. loss: 0.001002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001328, T: 341352, Avg. loss: 0.001003\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002084, T: 398244, Avg. loss: 0.001003\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002343, T: 56892, Avg. loss: 0.005756\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002086, T: 113784, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002571, T: 170676, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001079, T: 227568, Avg. loss: 0.001034\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001453, T: 284460, Avg. loss: 0.001034\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003695, T: 341352, Avg. loss: 0.001034\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002620, T: 398244, Avg. loss: 0.001034\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000411, T: 56892, Avg. loss: 0.005728\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001412, T: 113784, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001021, T: 170676, Avg. loss: 0.001011\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001254, T: 227568, Avg. loss: 0.001011\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001716, T: 284460, Avg. loss: 0.001011\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.99, NNZs: 1, Bias: -0.001723, T: 341352, Avg. loss: 0.001011\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001517, T: 398244, Avg. loss: 0.001011\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000648, T: 56892, Avg. loss: 0.005780\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003281, T: 113784, Avg. loss: 0.001032\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001799, T: 170676, Avg. loss: 0.001032\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001748, T: 227568, Avg. loss: 0.001031\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001582, T: 284460, Avg. loss: 0.001031\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002297, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002813, T: 398244, Avg. loss: 0.001031\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002606, T: 56892, Avg. loss: 0.005651\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002797, T: 113784, Avg. loss: 0.000933\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000256, T: 170676, Avg. loss: 0.000933\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001922, T: 227568, Avg. loss: 0.000933\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001361, T: 284460, Avg. loss: 0.000933\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001550, T: 341352, Avg. loss: 0.000933\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002853, T: 398244, Avg. loss: 0.000933\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.001952, T: 56892, Avg. loss: 0.005762\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001728, T: 113784, Avg. loss: 0.001003\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.001473, T: 170676, Avg. loss: 0.001003\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.12, NNZs: 1, Bias: -0.002114, T: 227568, Avg. loss: 0.001003\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.14, NNZs: 1, Bias: -0.002235, T: 284460, Avg. loss: 0.001002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.16, NNZs: 1, Bias: -0.001970, T: 341352, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.18, NNZs: 1, Bias: -0.002549, T: 398244, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.002533, T: 56892, Avg. loss: 0.005804\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001924, T: 113784, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.002957, T: 170676, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.12, NNZs: 1, Bias: -0.002177, T: 227568, Avg. loss: 0.001034\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.14, NNZs: 1, Bias: -0.001999, T: 284460, Avg. loss: 0.001034\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.16, NNZs: 1, Bias: -0.002490, T: 341352, Avg. loss: 0.001034\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.18, NNZs: 1, Bias: -0.002488, T: 398244, Avg. loss: 0.001034\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.000476, T: 56892, Avg. loss: 0.005769\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001570, T: 113784, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.000738, T: 170676, Avg. loss: 0.001011\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.12, NNZs: 1, Bias: -0.001210, T: 227568, Avg. loss: 0.001011\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.14, NNZs: 1, Bias: -0.000805, T: 284460, Avg. loss: 0.001011\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.16, NNZs: 1, Bias: -0.000538, T: 341352, Avg. loss: 0.001011\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.18, NNZs: 1, Bias: -0.001041, T: 398244, Avg. loss: 0.001011\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.002422, T: 56892, Avg. loss: 0.005768\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.001755, T: 113784, Avg. loss: 0.001032\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.002550, T: 170676, Avg. loss: 0.001032\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.12, NNZs: 1, Bias: -0.002183, T: 227568, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.14, NNZs: 1, Bias: -0.001962, T: 284460, Avg. loss: 0.001032\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.16, NNZs: 1, Bias: -0.001269, T: 341352, Avg. loss: 0.001032\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.18, NNZs: 1, Bias: -0.001568, T: 398244, Avg. loss: 0.001031\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.000376, T: 56892, Avg. loss: 0.005706\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.07, NNZs: 1, Bias: -0.001880, T: 113784, Avg. loss: 0.000933\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.001046, T: 170676, Avg. loss: 0.000933\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.12, NNZs: 1, Bias: -0.000069, T: 227568, Avg. loss: 0.000933\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.14, NNZs: 1, Bias: -0.001065, T: 284460, Avg. loss: 0.000933\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.16, NNZs: 1, Bias: -0.001501, T: 341352, Avg. loss: 0.000933\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.18, NNZs: 1, Bias: -0.001317, T: 398244, Avg. loss: 0.000933\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003195, T: 56892, Avg. loss: 0.005761\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001418, T: 113784, Avg. loss: 0.001003\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.003081, T: 170676, Avg. loss: 0.001003\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002508, T: 227568, Avg. loss: 0.001002\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001319, T: 284460, Avg. loss: 0.001002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001439, T: 341352, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001751, T: 398244, Avg. loss: 0.001002\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001101, T: 56892, Avg. loss: 0.005764\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002874, T: 113784, Avg. loss: 0.001034\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002575, T: 170676, Avg. loss: 0.001034\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.003009, T: 227568, Avg. loss: 0.001034\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.003104, T: 284460, Avg. loss: 0.001034\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002366, T: 341352, Avg. loss: 0.001034\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002517, T: 398244, Avg. loss: 0.001034\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.002695, T: 56892, Avg. loss: 0.005677\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001159, T: 113784, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000380, T: 170676, Avg. loss: 0.001011\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000987, T: 227568, Avg. loss: 0.001011\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000415, T: 284460, Avg. loss: 0.001011\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001582, T: 341352, Avg. loss: 0.001011\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000858, T: 398244, Avg. loss: 0.001011\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001746, T: 56892, Avg. loss: 0.005808\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001845, T: 113784, Avg. loss: 0.001032\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001418, T: 170676, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001746, T: 227568, Avg. loss: 0.001031\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002645, T: 284460, Avg. loss: 0.001032\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.003055, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002986, T: 398244, Avg. loss: 0.001031\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001327, T: 56892, Avg. loss: 0.005663\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000777, T: 113784, Avg. loss: 0.000933\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001672, T: 170676, Avg. loss: 0.000933\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001594, T: 227568, Avg. loss: 0.000933\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001802, T: 284460, Avg. loss: 0.000933\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001134, T: 341352, Avg. loss: 0.000933\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001656, T: 398244, Avg. loss: 0.000933\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010938, T: 56892, Avg. loss: 0.003645\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: 0.009675, T: 113784, Avg. loss: 0.001642\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.012425, T: 170676, Avg. loss: 0.001636\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006377, T: 227568, Avg. loss: 0.001640\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.011697, T: 284460, Avg. loss: 0.001637\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009915, T: 341352, Avg. loss: 0.001638\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010279, T: 398244, Avg. loss: 0.001636\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002902, T: 56892, Avg. loss: 0.003791\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002980, T: 113784, Avg. loss: 0.001723\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002479, T: 170676, Avg. loss: 0.001720\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000189, T: 227568, Avg. loss: 0.001717\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003007, T: 284460, Avg. loss: 0.001718\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000696, T: 341352, Avg. loss: 0.001716\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003809, T: 398244, Avg. loss: 0.001716\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008246, T: 56892, Avg. loss: 0.003772\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.011295, T: 113784, Avg. loss: 0.001698\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010802, T: 170676, Avg. loss: 0.001695\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.011720, T: 227568, Avg. loss: 0.001695\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.012964, T: 284460, Avg. loss: 0.001693\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007122, T: 341352, Avg. loss: 0.001697\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010844, T: 398244, Avg. loss: 0.001694\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005429, T: 56892, Avg. loss: 0.003756\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.012768, T: 113784, Avg. loss: 0.001731\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001181, T: 170676, Avg. loss: 0.001728\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002303, T: 227568, Avg. loss: 0.001729\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002786, T: 284460, Avg. loss: 0.001725\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.004475, T: 341352, Avg. loss: 0.001725\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000104, T: 398244, Avg. loss: 0.001725\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.003743, T: 56892, Avg. loss: 0.003141\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001728, T: 113784, Avg. loss: 0.001077\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001886, T: 170676, Avg. loss: 0.001077\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000058, T: 227568, Avg. loss: 0.001074\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002634, T: 284460, Avg. loss: 0.001071\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000033, T: 341352, Avg. loss: 0.001071\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002798, T: 398244, Avg. loss: 0.001076\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.007899, T: 56892, Avg. loss: 0.003719\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.013925, T: 113784, Avg. loss: 0.001641\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.11, NNZs: 1, Bias: 0.009582, T: 170676, Avg. loss: 0.001638\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.13, NNZs: 1, Bias: 0.012255, T: 227568, Avg. loss: 0.001640\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.16, NNZs: 1, Bias: 0.008672, T: 284460, Avg. loss: 0.001637\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.18, NNZs: 1, Bias: 0.006240, T: 341352, Avg. loss: 0.001638\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.20, NNZs: 1, Bias: 0.010294, T: 398244, Avg. loss: 0.001638\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.002951, T: 56892, Avg. loss: 0.003720\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.006700, T: 113784, Avg. loss: 0.001720\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.11, NNZs: 1, Bias: 0.000545, T: 170676, Avg. loss: 0.001720\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.14, NNZs: 1, Bias: 0.002535, T: 227568, Avg. loss: 0.001718\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.16, NNZs: 1, Bias: -0.000457, T: 284460, Avg. loss: 0.001718\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.18, NNZs: 1, Bias: 0.003820, T: 341352, Avg. loss: 0.001717\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.20, NNZs: 1, Bias: -0.000201, T: 398244, Avg. loss: 0.001716\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.05, NNZs: 1, Bias: 0.010606, T: 56892, Avg. loss: 0.003702\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.011699, T: 113784, Avg. loss: 0.001697\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.11, NNZs: 1, Bias: 0.005732, T: 170676, Avg. loss: 0.001695\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.14, NNZs: 1, Bias: 0.009237, T: 227568, Avg. loss: 0.001695\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.16, NNZs: 1, Bias: 0.008479, T: 284460, Avg. loss: 0.001697\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.18, NNZs: 1, Bias: 0.010604, T: 341352, Avg. loss: 0.001694\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.20, NNZs: 1, Bias: 0.009033, T: 398244, Avg. loss: 0.001695\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.005041, T: 56892, Avg. loss: 0.003774\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.002205, T: 113784, Avg. loss: 0.001728\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.005306, T: 170676, Avg. loss: 0.001725\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.14, NNZs: 1, Bias: 0.003850, T: 227568, Avg. loss: 0.001726\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.16, NNZs: 1, Bias: 0.003887, T: 284460, Avg. loss: 0.001728\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.18, NNZs: 1, Bias: 0.004312, T: 341352, Avg. loss: 0.001726\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.21, NNZs: 1, Bias: 0.002742, T: 398244, Avg. loss: 0.001725\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000996, T: 56892, Avg. loss: 0.003071\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.001967, T: 113784, Avg. loss: 0.001077\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.12, NNZs: 1, Bias: -0.001109, T: 170676, Avg. loss: 0.001076\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.15, NNZs: 1, Bias: -0.000982, T: 227568, Avg. loss: 0.001072\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.17, NNZs: 1, Bias: -0.001396, T: 284460, Avg. loss: 0.001075\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.19, NNZs: 1, Bias: -0.002160, T: 341352, Avg. loss: 0.001074\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.21, NNZs: 1, Bias: 0.000317, T: 398244, Avg. loss: 0.001073\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.007504, T: 56892, Avg. loss: 0.003672\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010932, T: 113784, Avg. loss: 0.001641\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.006876, T: 170676, Avg. loss: 0.001638\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008403, T: 227568, Avg. loss: 0.001637\n",
            "Total training time: 0.03 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008895, T: 284460, Avg. loss: 0.001640\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.007267, T: 341352, Avg. loss: 0.001639\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.011711, T: 398244, Avg. loss: 0.001639\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000631, T: 56892, Avg. loss: 0.003788\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000047, T: 113784, Avg. loss: 0.001722\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.004068, T: 170676, Avg. loss: 0.001720\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.004064, T: 227568, Avg. loss: 0.001720\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.004445, T: 284460, Avg. loss: 0.001717\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.001920, T: 341352, Avg. loss: 0.001717\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.001548, T: 398244, Avg. loss: 0.001715\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.017508, T: 56892, Avg. loss: 0.003722\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010634, T: 113784, Avg. loss: 0.001699\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008188, T: 170676, Avg. loss: 0.001696\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010186, T: 227568, Avg. loss: 0.001694\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008939, T: 284460, Avg. loss: 0.001696\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.007376, T: 341352, Avg. loss: 0.001696\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.009916, T: 398244, Avg. loss: 0.001694\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.007146, T: 56892, Avg. loss: 0.003795\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.005589, T: 113784, Avg. loss: 0.001727\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.003046, T: 170676, Avg. loss: 0.001730\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.005358, T: 227568, Avg. loss: 0.001727\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.001053, T: 284460, Avg. loss: 0.001725\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.002395, T: 341352, Avg. loss: 0.001724\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.004824, T: 398244, Avg. loss: 0.001721\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001352, T: 56892, Avg. loss: 0.003117\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.001579, T: 113784, Avg. loss: 0.001077\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.001906, T: 170676, Avg. loss: 0.001073\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.000464, T: 227568, Avg. loss: 0.001075\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.001709, T: 284460, Avg. loss: 0.001073\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.002490, T: 341352, Avg. loss: 0.001072\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.001596, T: 398244, Avg. loss: 0.001074\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003882, T: 56892, Avg. loss: 0.001678\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005239, T: 113784, Avg. loss: 0.001235\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004191, T: 170676, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.006233, T: 227568, Avg. loss: 0.001237\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003051, T: 284460, Avg. loss: 0.001238\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000238, T: 341352, Avg. loss: 0.001237\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000930, T: 56892, Avg. loss: 0.001713\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.004063, T: 113784, Avg. loss: 0.001265\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000811, T: 170676, Avg. loss: 0.001266\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004189, T: 227568, Avg. loss: 0.001265\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003106, T: 284460, Avg. loss: 0.001264\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000553, T: 341352, Avg. loss: 0.001266\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001559, T: 56892, Avg. loss: 0.001707\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008164, T: 113784, Avg. loss: 0.001260\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001680, T: 170676, Avg. loss: 0.001260\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.004651, T: 227568, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001423, T: 284460, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001970, T: 341352, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002789, T: 56892, Avg. loss: 0.001713\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.007834, T: 113784, Avg. loss: 0.001268\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002494, T: 170676, Avg. loss: 0.001270\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005085, T: 227568, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002614, T: 284460, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000788, T: 341352, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004931, T: 56892, Avg. loss: 0.001501\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001976, T: 113784, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: 0.002515, T: 170676, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002023, T: 227568, Avg. loss: 0.001054\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002436, T: 284460, Avg. loss: 0.001056\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002084, T: 341352, Avg. loss: 0.001055\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.002081, T: 56892, Avg. loss: 0.001681\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.11, NNZs: 1, Bias: 0.005003, T: 113784, Avg. loss: 0.001236\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.16, NNZs: 1, Bias: 0.002037, T: 170676, Avg. loss: 0.001236\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.20, NNZs: 1, Bias: -0.001208, T: 227568, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.25, NNZs: 1, Bias: -0.003232, T: 284460, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.30, NNZs: 1, Bias: 0.007892, T: 341352, Avg. loss: 0.001236\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.005888, T: 56892, Avg. loss: 0.001714\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.004300, T: 113784, Avg. loss: 0.001266\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.16, NNZs: 1, Bias: 0.004240, T: 170676, Avg. loss: 0.001266\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.21, NNZs: 1, Bias: 0.000145, T: 227568, Avg. loss: 0.001267\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.25, NNZs: 1, Bias: 0.002840, T: 284460, Avg. loss: 0.001266\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.30, NNZs: 1, Bias: 0.004072, T: 341352, Avg. loss: 0.001266\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.003888, T: 56892, Avg. loss: 0.001705\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.006968, T: 113784, Avg. loss: 0.001260\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.16, NNZs: 1, Bias: -0.000441, T: 170676, Avg. loss: 0.001260\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.20, NNZs: 1, Bias: 0.000437, T: 227568, Avg. loss: 0.001259\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.25, NNZs: 1, Bias: 0.001805, T: 284460, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.29, NNZs: 1, Bias: 0.004312, T: 341352, Avg. loss: 0.001261\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.000212, T: 56892, Avg. loss: 0.001712\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.004326, T: 113784, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.16, NNZs: 1, Bias: -0.000511, T: 170676, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.21, NNZs: 1, Bias: -0.001005, T: 227568, Avg. loss: 0.001267\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.25, NNZs: 1, Bias: -0.000399, T: 284460, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.30, NNZs: 1, Bias: -0.001818, T: 341352, Avg. loss: 0.001270\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.000549, T: 56892, Avg. loss: 0.001498\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.001853, T: 113784, Avg. loss: 0.001056\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.16, NNZs: 1, Bias: 0.001364, T: 170676, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.20, NNZs: 1, Bias: 0.002463, T: 227568, Avg. loss: 0.001057\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.25, NNZs: 1, Bias: -0.002313, T: 284460, Avg. loss: 0.001057\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.29, NNZs: 1, Bias: 0.000583, T: 341352, Avg. loss: 0.001056\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001905, T: 56892, Avg. loss: 0.001682\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000254, T: 113784, Avg. loss: 0.001236\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.001067, T: 170676, Avg. loss: 0.001237\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000320, T: 227568, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.000111, T: 284460, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.001817, T: 341352, Avg. loss: 0.001237\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.003218, T: 56892, Avg. loss: 0.001708\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000738, T: 113784, Avg. loss: 0.001266\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.002518, T: 170676, Avg. loss: 0.001265\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001549, T: 227568, Avg. loss: 0.001266\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.005004, T: 284460, Avg. loss: 0.001266\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.002659, T: 341352, Avg. loss: 0.001266\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002945, T: 56892, Avg. loss: 0.001704\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002096, T: 113784, Avg. loss: 0.001260\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.003473, T: 170676, Avg. loss: 0.001259\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.002309, T: 227568, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000327, T: 284460, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.003539, T: 341352, Avg. loss: 0.001261\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002281, T: 56892, Avg. loss: 0.001715\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002544, T: 113784, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001376, T: 170676, Avg. loss: 0.001268\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.003896, T: 227568, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.002675, T: 284460, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.002011, T: 341352, Avg. loss: 0.001269\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003964, T: 56892, Avg. loss: 0.001501\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.002170, T: 113784, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000637, T: 170676, Avg. loss: 0.001058\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.000154, T: 227568, Avg. loss: 0.001056\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.001713, T: 284460, Avg. loss: 0.001057\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.002200, T: 341352, Avg. loss: 0.001056\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.007184, T: 56892, Avg. loss: 0.001787\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004669, T: 113784, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002374, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.006516, T: 227568, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002381, T: 284460, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002860, T: 341352, Avg. loss: 0.001010\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001982, T: 56892, Avg. loss: 0.001819\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000821, T: 113784, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005051, T: 170676, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.007482, T: 227568, Avg. loss: 0.001043\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000077, T: 284460, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.005247, T: 341352, Avg. loss: 0.001042\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001882, T: 56892, Avg. loss: 0.001802\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000930, T: 113784, Avg. loss: 0.001018\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004273, T: 170676, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001145, T: 227568, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001500, T: 284460, Avg. loss: 0.001019\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.006143, T: 341352, Avg. loss: 0.001019\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.007852, T: 56892, Avg. loss: 0.001818\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004231, T: 113784, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000252, T: 170676, Avg. loss: 0.001041\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004984, T: 227568, Avg. loss: 0.001039\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000917, T: 284460, Avg. loss: 0.001039\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004214, T: 341352, Avg. loss: 0.001039\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004731, T: 56892, Avg. loss: 0.001717\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002568, T: 113784, Avg. loss: 0.000940\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004285, T: 170676, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003848, T: 227568, Avg. loss: 0.000942\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003520, T: 284460, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002770, T: 341352, Avg. loss: 0.000941\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.000804, T: 56892, Avg. loss: 0.001788\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.004373, T: 113784, Avg. loss: 0.001010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.16, NNZs: 1, Bias: -0.004174, T: 170676, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.20, NNZs: 1, Bias: -0.003126, T: 227568, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.25, NNZs: 1, Bias: 0.001116, T: 284460, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.30, NNZs: 1, Bias: 0.001784, T: 341352, Avg. loss: 0.001011\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.002401, T: 56892, Avg. loss: 0.001821\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.000863, T: 113784, Avg. loss: 0.001043\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.15, NNZs: 1, Bias: -0.006238, T: 170676, Avg. loss: 0.001043\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.20, NNZs: 1, Bias: 0.000996, T: 227568, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.25, NNZs: 1, Bias: -0.001233, T: 284460, Avg. loss: 0.001043\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.29, NNZs: 1, Bias: 0.000509, T: 341352, Avg. loss: 0.001043\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.002362, T: 56892, Avg. loss: 0.001799\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.000870, T: 113784, Avg. loss: 0.001018\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.15, NNZs: 1, Bias: -0.001048, T: 170676, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.21, NNZs: 1, Bias: 0.002705, T: 227568, Avg. loss: 0.001018\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.25, NNZs: 1, Bias: 0.000239, T: 284460, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.29, NNZs: 1, Bias: -0.003806, T: 341352, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.005832, T: 56892, Avg. loss: 0.001818\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.000422, T: 113784, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.15, NNZs: 1, Bias: 0.001007, T: 170676, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.20, NNZs: 1, Bias: -0.000592, T: 227568, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.25, NNZs: 1, Bias: 0.003755, T: 284460, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.29, NNZs: 1, Bias: -0.001070, T: 341352, Avg. loss: 0.001039\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.003592, T: 56892, Avg. loss: 0.001720\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.004143, T: 113784, Avg. loss: 0.000940\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.16, NNZs: 1, Bias: -0.006208, T: 170676, Avg. loss: 0.000940\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.20, NNZs: 1, Bias: -0.004295, T: 227568, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.25, NNZs: 1, Bias: -0.003453, T: 284460, Avg. loss: 0.000941\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.30, NNZs: 1, Bias: 0.001227, T: 341352, Avg. loss: 0.000941\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003404, T: 56892, Avg. loss: 0.001786\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.004649, T: 113784, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002221, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.006811, T: 227568, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.002364, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.000486, T: 341352, Avg. loss: 0.001011\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005197, T: 56892, Avg. loss: 0.001817\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.005499, T: 113784, Avg. loss: 0.001043\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.002656, T: 170676, Avg. loss: 0.001043\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.002761, T: 227568, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000615, T: 284460, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.006116, T: 341352, Avg. loss: 0.001043\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001901, T: 56892, Avg. loss: 0.001797\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001559, T: 113784, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000090, T: 170676, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000907, T: 227568, Avg. loss: 0.001019\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.003195, T: 284460, Avg. loss: 0.001018\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.005474, T: 341352, Avg. loss: 0.001018\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001955, T: 56892, Avg. loss: 0.001819\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000530, T: 113784, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.004739, T: 170676, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000378, T: 227568, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.000700, T: 284460, Avg. loss: 0.001039\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.000535, T: 341352, Avg. loss: 0.001040\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000832, T: 56892, Avg. loss: 0.001723\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000962, T: 113784, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000569, T: 170676, Avg. loss: 0.000940\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.03, NNZs: 1, Bias: -0.000191, T: 227568, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.002471, T: 284460, Avg. loss: 0.000941\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.002119, T: 341352, Avg. loss: 0.000941\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002541\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000000, T: 113784, Avg. loss: 0.001825\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000000, T: 170676, Avg. loss: 0.001823\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001834\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001835\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000000, T: 341352, Avg. loss: 0.001841\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.002676\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001937\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001942\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001938\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.010000, T: 284460, Avg. loss: 0.001945\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001949\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.002635\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000000, T: 113784, Avg. loss: 0.001890\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001906\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000000, T: 227568, Avg. loss: 0.001876\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.040000, T: 284460, Avg. loss: 0.001890\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001877\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002679\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000000, T: 113784, Avg. loss: 0.001956\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000000, T: 170676, Avg. loss: 0.001944\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001945\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001940\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001955\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000000, T: 56892, Avg. loss: 0.002006\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000000, T: 113784, Avg. loss: 0.001258\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.001254\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000000, T: 227568, Avg. loss: 0.001276\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.010000, T: 284460, Avg. loss: 0.001271\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000000, T: 341352, Avg. loss: 0.001267\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002562\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.12, NNZs: 1, Bias: -0.000000, T: 113784, Avg. loss: 0.001839\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.16, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.001820\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.21, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001821\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.26, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001833\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.30, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.001830\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002663\n",
            "Total training time: 0.00 seconds."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch 2\n",
            "Norm: 1.11, NNZs: 1, Bias: -0.010000, T: 113784, Avg. loss: 0.001951\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.16, NNZs: 1, Bias: -0.010000, T: 170676, Avg. loss: 0.001943\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.20, NNZs: 1, Bias: 0.000000, T: 227568, Avg. loss: 0.001935\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.26, NNZs: 1, Bias: 0.030000, T: 284460, Avg. loss: 0.001937\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.28, NNZs: 1, Bias: -0.020000, T: 341352, Avg. loss: 0.001930\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002613\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.11, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001890\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.16, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001896\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.21, NNZs: 1, Bias: -0.010000, T: 227568, Avg. loss: 0.001894\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.26, NNZs: 1, Bias: 0.000000, T: 284460, Avg. loss: 0.001887\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.30, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.001880\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002665\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001942\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.15, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001949\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.21, NNZs: 1, Bias: 0.000000, T: 227568, Avg. loss: 0.001952\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.26, NNZs: 1, Bias: 0.000000, T: 284460, Avg. loss: 0.001932\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.32, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001939\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.000000, T: 56892, Avg. loss: 0.001989\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.11, NNZs: 1, Bias: -0.000000, T: 113784, Avg. loss: 0.001270\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.16, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001264\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.22, NNZs: 1, Bias: -0.000000, T: 227568, Avg. loss: 0.001272\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.27, NNZs: 1, Bias: -0.000000, T: 284460, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.30, NNZs: 1, Bias: -0.010000, T: 341352, Avg. loss: 0.001264\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002561\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001825\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001832\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001833\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001831\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001832\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002666\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001940\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001932\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.000000, T: 227568, Avg. loss: 0.001944\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.000000, T: 284460, Avg. loss: 0.001933\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001932\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002616\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.001889\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001892\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.001891\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.001893\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001885\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002668\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001951\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.03, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001939\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001958\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.010000, T: 284460, Avg. loss: 0.001928\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001942\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002007\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001273\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001270\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001266\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001281\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001280\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3989.26, NNZs: 1, Bias: -0.000415, T: 56892, Avg. loss: 971205626467820431736832.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 2011.99, NNZs: 1, Bias: -0.011852, T: 113784, Avg. loss: 0.001420\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1345.23, NNZs: 1, Bias: 0.016734, T: 170676, Avg. loss: 0.001327\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1010.39, NNZs: 1, Bias: 0.004751, T: 227568, Avg. loss: 0.001294\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 809.02, NNZs: 1, Bias: -0.002104, T: 284460, Avg. loss: 0.001278\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 674.58, NNZs: 1, Bias: -0.002873, T: 341352, Avg. loss: 0.001268\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 578.45, NNZs: 1, Bias: -0.004069, T: 398244, Avg. loss: 0.001263\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 9214.59, NNZs: 1, Bias: 0.015095, T: 56892, Avg. loss: 1005467114061616440672256.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4647.40, NNZs: 1, Bias: 0.003336, T: 113784, Avg. loss: 0.001452\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 3107.28, NNZs: 1, Bias: -0.010796, T: 170676, Avg. loss: 0.001360\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2333.85, NNZs: 1, Bias: 0.001018, T: 227568, Avg. loss: 0.001332\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1868.72, NNZs: 1, Bias: -0.000333, T: 284460, Avg. loss: 0.001309\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1558.17, NNZs: 1, Bias: 0.015939, T: 341352, Avg. loss: 0.001300\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1336.13, NNZs: 1, Bias: -0.006583, T: 398244, Avg. loss: 0.001290\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 30099.27, NNZs: 1, Bias: 0.031940, T: 56892, Avg. loss: 983047758509282064072704.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 15180.62, NNZs: 1, Bias: -0.002839, T: 113784, Avg. loss: 0.001450\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 10149.86, NNZs: 1, Bias: -0.010947, T: 170676, Avg. loss: 0.001356\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 7623.49, NNZs: 1, Bias: 0.007962, T: 227568, Avg. loss: 0.001321\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 6104.12, NNZs: 1, Bias: 0.007505, T: 284460, Avg. loss: 0.001302\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5089.74, NNZs: 1, Bias: 0.002599, T: 341352, Avg. loss: 0.001293\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 4364.45, NNZs: 1, Bias: -0.000446, T: 398244, Avg. loss: 0.001285\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: nan, NNZs: 1, Bias: -0.008601, T: 56892, Avg. loss: 1013371026282945177452544.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: nan, NNZs: 1, Bias: -0.015936, T: 113784, Avg. loss: 0.001456\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: nan, NNZs: 1, Bias: 0.012597, T: 170676, Avg. loss: 0.001368\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: nan, NNZs: 1, Bias: 0.000851, T: 227568, Avg. loss: 0.001329\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: nan, NNZs: 1, Bias: 0.015785, T: 284460, Avg. loss: 0.001311\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: nan, NNZs: 1, Bias: -0.006484, T: 341352, Avg. loss: 0.001302\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: nan, NNZs: 1, Bias: -0.004509, T: 398244, Avg. loss: 0.001294\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 14517.95, NNZs: 1, Bias: 0.027905, T: 56892, Avg. loss: 968264223050302035591168.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 7322.15, NNZs: 1, Bias: -0.027003, T: 113784, Avg. loss: 0.001211\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4895.64, NNZs: 1, Bias: -0.016576, T: 170676, Avg. loss: 0.001137\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 3677.08, NNZs: 1, Bias: 0.006112, T: 227568, Avg. loss: 0.001107\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2944.24, NNZs: 1, Bias: -0.001952, T: 284460, Avg. loss: 0.001093\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 2454.96, NNZs: 1, Bias: -0.003003, T: 341352, Avg. loss: 0.001085\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2105.13, NNZs: 1, Bias: 0.011828, T: 398244, Avg. loss: 0.001077\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 147546773.58, NNZs: 1, Bias: 0.010309, T: 56892, Avg. loss: 993564419258250816389120.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 147546773.58, NNZs: 1, Bias: -0.012749, T: 113784, Avg. loss: 0.001419\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 147546773.58, NNZs: 1, Bias: -0.012948, T: 170676, Avg. loss: 0.001331\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 147546773.58, NNZs: 1, Bias: 0.017842, T: 227568, Avg. loss: 0.001297\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 147546773.58, NNZs: 1, Bias: -0.001492, T: 284460, Avg. loss: 0.001281\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 147546773.58, NNZs: 1, Bias: 0.006181, T: 341352, Avg. loss: 0.001266\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 147546773.58, NNZs: 1, Bias: -0.010072, T: 398244, Avg. loss: 0.001260\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 147854802.52, NNZs: 1, Bias: 0.024714, T: 56892, Avg. loss: 974837585300085333295104.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 147854802.52, NNZs: 1, Bias: 0.008070, T: 113784, Avg. loss: 0.001463\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 147854802.52, NNZs: 1, Bias: -0.005268, T: 170676, Avg. loss: 0.001361\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 147854802.52, NNZs: 1, Bias: -0.000973, T: 227568, Avg. loss: 0.001327\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 147854802.52, NNZs: 1, Bias: -0.009781, T: 284460, Avg. loss: 0.001312\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 147854802.52, NNZs: 1, Bias: -0.000345, T: 341352, Avg. loss: 0.001300\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 147854802.52, NNZs: 1, Bias: -0.003360, T: 398244, Avg. loss: 0.001291\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 149233755.93, NNZs: 1, Bias: -0.017588, T: 56892, Avg. loss: 968016009838786473099264.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 149233755.93, NNZs: 1, Bias: -0.000139, T: 113784, Avg. loss: 0.001449\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 149233755.93, NNZs: 1, Bias: -0.011614, T: 170676, Avg. loss: 0.001358\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 149233755.93, NNZs: 1, Bias: 0.011766, T: 227568, Avg. loss: 0.001322\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 149233755.93, NNZs: 1, Bias: 0.013302, T: 284460, Avg. loss: 0.001306\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 149233755.93, NNZs: 1, Bias: 0.016385, T: 341352, Avg. loss: 0.001293\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 149233755.93, NNZs: 1, Bias: 0.006415, T: 398244, Avg. loss: 0.001283\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 148250474.05, NNZs: 1, Bias: -0.007662, T: 56892, Avg. loss: 963600231475174422085632.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 148250474.05, NNZs: 1, Bias: -0.000171, T: 113784, Avg. loss: 0.001449\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 148250474.05, NNZs: 1, Bias: -0.000373, T: 170676, Avg. loss: 0.001362\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 148250474.05, NNZs: 1, Bias: 0.006914, T: 227568, Avg. loss: 0.001329\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 148250474.05, NNZs: 1, Bias: 0.005415, T: 284460, Avg. loss: 0.001311\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 148250474.05, NNZs: 1, Bias: 0.003865, T: 341352, Avg. loss: 0.001301\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 148250474.05, NNZs: 1, Bias: -0.007237, T: 398244, Avg. loss: 0.001294\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 149412399.64, NNZs: 1, Bias: -0.001088, T: 56892, Avg. loss: 974873178867837689659392.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 149412399.64, NNZs: 1, Bias: 0.001988, T: 113784, Avg. loss: 0.001220\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 149412399.64, NNZs: 1, Bias: -0.002617, T: 170676, Avg. loss: 0.001140\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 149412399.64, NNZs: 1, Bias: -0.000995, T: 227568, Avg. loss: 0.001109\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 149412399.64, NNZs: 1, Bias: 0.005135, T: 284460, Avg. loss: 0.001092\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 149412399.64, NNZs: 1, Bias: -0.002254, T: 341352, Avg. loss: 0.001085\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 149412399.64, NNZs: 1, Bias: 0.005339, T: 398244, Avg. loss: 0.001078\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7330477.98, NNZs: 1, Bias: -0.014304, T: 56892, Avg. loss: 985496395531681422901248.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4096905.90, NNZs: 1, Bias: -0.010530, T: 113784, Avg. loss: 0.001418\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2909718.71, NNZs: 1, Bias: -0.004491, T: 170676, Avg. loss: 0.001328\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2281342.79, NNZs: 1, Bias: -0.002655, T: 227568, Avg. loss: 0.001296\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1888599.58, NNZs: 1, Bias: -0.001597, T: 284460, Avg. loss: 0.001280\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1618270.90, NNZs: 1, Bias: -0.004002, T: 341352, Avg. loss: 0.001267\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1420039.36, NNZs: 1, Bias: 0.001045, T: 398244, Avg. loss: 0.001258\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7122958.89, NNZs: 1, Bias: -0.009376, T: 56892, Avg. loss: 965986076690290445385728.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3980926.26, NNZs: 1, Bias: 0.006042, T: 113784, Avg. loss: 0.001456\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2827347.25, NNZs: 1, Bias: -0.000489, T: 170676, Avg. loss: 0.001359\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2216760.07, NNZs: 1, Bias: 0.000815, T: 227568, Avg. loss: 0.001328\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1835135.07, NNZs: 1, Bias: -0.003827, T: 284460, Avg. loss: 0.001310\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1572459.14, NNZs: 1, Bias: 0.004210, T: 341352, Avg. loss: 0.001297\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1379839.35, NNZs: 1, Bias: 0.003998, T: 398244, Avg. loss: 0.001291\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7469582.24, NNZs: 1, Bias: 0.016686, T: 56892, Avg. loss: 954731984937911507222528.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4174649.41, NNZs: 1, Bias: 0.000315, T: 113784, Avg. loss: 0.001448\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2964933.97, NNZs: 1, Bias: -0.016225, T: 170676, Avg. loss: 0.001354\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2324633.89, NNZs: 1, Bias: -0.005170, T: 227568, Avg. loss: 0.001319\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1924437.94, NNZs: 1, Bias: 0.001970, T: 284460, Avg. loss: 0.001304\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1648979.45, NNZs: 1, Bias: 0.003264, T: 341352, Avg. loss: 0.001294\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1446986.24, NNZs: 1, Bias: 0.000067, T: 398244, Avg. loss: 0.001286\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7229331.27, NNZs: 1, Bias: 0.005278, T: 56892, Avg. loss: 955518552510732961841152.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4040376.36, NNZs: 1, Bias: -0.002271, T: 113784, Avg. loss: 0.001454\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2869570.10, NNZs: 1, Bias: -0.018550, T: 170676, Avg. loss: 0.001365\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2249864.58, NNZs: 1, Bias: 0.001799, T: 227568, Avg. loss: 0.001331\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1862540.49, NNZs: 1, Bias: -0.015111, T: 284460, Avg. loss: 0.001315\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1595941.82, NNZs: 1, Bias: -0.000003, T: 341352, Avg. loss: 0.001302\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1400445.51, NNZs: 1, Bias: 0.003826, T: 398244, Avg. loss: 0.001293\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7031137.47, NNZs: 1, Bias: 0.017739, T: 56892, Avg. loss: 981344470125959345864704.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3929608.50, NNZs: 1, Bias: -0.014578, T: 113784, Avg. loss: 0.001213\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2790900.17, NNZs: 1, Bias: -0.004999, T: 170676, Avg. loss: 0.001137\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2188184.02, NNZs: 1, Bias: -0.006481, T: 227568, Avg. loss: 0.001109\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1811478.51, NNZs: 1, Bias: 0.005718, T: 284460, Avg. loss: 0.001096\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1552188.71, NNZs: 1, Bias: -0.009158, T: 341352, Avg. loss: 0.001084\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1362051.97, NNZs: 1, Bias: -0.005039, T: 398244, Avg. loss: 0.001077\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.007605, T: 56892, Avg. loss: 0.004260\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.008612, T: 113784, Avg. loss: 0.001126\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002370, T: 170676, Avg. loss: 0.001070\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.004020, T: 227568, Avg. loss: 0.001048\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010532, T: 284460, Avg. loss: 0.001038\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.011683, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001169, T: 398244, Avg. loss: 0.001026\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.002252, T: 56892, Avg. loss: 0.004246\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.008414, T: 113784, Avg. loss: 0.001160\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004811, T: 170676, Avg. loss: 0.001101\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000594, T: 227568, Avg. loss: 0.001081\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002125, T: 284460, Avg. loss: 0.001070\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003351, T: 341352, Avg. loss: 0.001064\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003074, T: 398244, Avg. loss: 0.001058\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.013187, T: 56892, Avg. loss: 0.004290\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.017956, T: 113784, Avg. loss: 0.001134\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002215, T: 170676, Avg. loss: 0.001074\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.010434, T: 227568, Avg. loss: 0.001058\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001562, T: 284460, Avg. loss: 0.001046\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001900, T: 341352, Avg. loss: 0.001039\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002191, T: 398244, Avg. loss: 0.001035\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.012848, T: 56892, Avg. loss: 0.004253\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000837, T: 113784, Avg. loss: 0.001158\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.007614, T: 170676, Avg. loss: 0.001104\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.009586, T: 227568, Avg. loss: 0.001079\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.010094, T: 284460, Avg. loss: 0.001069\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000327, T: 341352, Avg. loss: 0.001060\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.007000, T: 398244, Avg. loss: 0.001056\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.007435, T: 56892, Avg. loss: 0.004185\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.008137, T: 113784, Avg. loss: 0.001054\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.006474, T: 170676, Avg. loss: 0.000999\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.003603, T: 227568, Avg. loss: 0.000978\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002703, T: 284460, Avg. loss: 0.000967\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001268, T: 341352, Avg. loss: 0.000961\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001076, T: 398244, Avg. loss: 0.000957\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4.75, NNZs: 1, Bias: 0.012617, T: 56892, Avg. loss: 0.004243\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.89, NNZs: 1, Bias: -0.010390, T: 113784, Avg. loss: 0.001123\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.97, NNZs: 1, Bias: 0.008414, T: 170676, Avg. loss: 0.001069\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.03, NNZs: 1, Bias: 0.002398, T: 227568, Avg. loss: 0.001049\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.07, NNZs: 1, Bias: -0.006122, T: 284460, Avg. loss: 0.001039\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5.11, NNZs: 1, Bias: -0.000139, T: 341352, Avg. loss: 0.001032\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 5.14, NNZs: 1, Bias: -0.011202, T: 398244, Avg. loss: 0.001024\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 5.02, NNZs: 1, Bias: 0.006919, T: 56892, Avg. loss: 0.004270\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 5.15, NNZs: 1, Bias: -0.001636, T: 113784, Avg. loss: 0.001160\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5.23, NNZs: 1, Bias: -0.008754, T: 170676, Avg. loss: 0.001103\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.29, NNZs: 1, Bias: -0.000457, T: 227568, Avg. loss: 0.001082\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.33, NNZs: 1, Bias: -0.001486, T: 284460, Avg. loss: 0.001070\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5.36, NNZs: 1, Bias: -0.011092, T: 341352, Avg. loss: 0.001063\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 5.39, NNZs: 1, Bias: 0.001408, T: 398244, Avg. loss: 0.001060\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4.71, NNZs: 1, Bias: -0.003456, T: 56892, Avg. loss: 0.004241\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.85, NNZs: 1, Bias: -0.009467, T: 113784, Avg. loss: 0.001132\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.93, NNZs: 1, Bias: -0.007094, T: 170676, Avg. loss: 0.001076\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.99, NNZs: 1, Bias: 0.004635, T: 227568, Avg. loss: 0.001056\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.03, NNZs: 1, Bias: 0.004759, T: 284460, Avg. loss: 0.001046\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5.07, NNZs: 1, Bias: -0.007678, T: 341352, Avg. loss: 0.001039\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 5.10, NNZs: 1, Bias: -0.005130, T: 398244, Avg. loss: 0.001035\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4.41, NNZs: 1, Bias: -0.004734, T: 56892, Avg. loss: 0.004287\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.56, NNZs: 1, Bias: -0.004882, T: 113784, Avg. loss: 0.001157\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.65, NNZs: 1, Bias: -0.007630, T: 170676, Avg. loss: 0.001099\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.71, NNZs: 1, Bias: -0.010292, T: 227568, Avg. loss: 0.001079\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4.75, NNZs: 1, Bias: -0.004476, T: 284460, Avg. loss: 0.001068\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.79, NNZs: 1, Bias: -0.000317, T: 341352, Avg. loss: 0.001062\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 4.82, NNZs: 1, Bias: -0.010811, T: 398244, Avg. loss: 0.001056\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4.76, NNZs: 1, Bias: 0.011065, T: 56892, Avg. loss: 0.004246\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.90, NNZs: 1, Bias: -0.011726, T: 113784, Avg. loss: 0.001054\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.98, NNZs: 1, Bias: -0.000082, T: 170676, Avg. loss: 0.000996\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 5.03, NNZs: 1, Bias: 0.011259, T: 227568, Avg. loss: 0.000980\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.08, NNZs: 1, Bias: -0.007823, T: 284460, Avg. loss: 0.000969\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5.11, NNZs: 1, Bias: -0.001040, T: 341352, Avg. loss: 0.000961\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 5.14, NNZs: 1, Bias: 0.001529, T: 398244, Avg. loss: 0.000954\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.09, NNZs: 1, Bias: -0.016125, T: 56892, Avg. loss: 0.004274\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.003427, T: 113784, Avg. loss: 0.001123\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.003134, T: 170676, Avg. loss: 0.001069\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.007898, T: 227568, Avg. loss: 0.001050\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.006731, T: 284460, Avg. loss: 0.001038\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.008939, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.003872, T: 398244, Avg. loss: 0.001026\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.014676, T: 56892, Avg. loss: 0.004283\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002072, T: 113784, Avg. loss: 0.001157\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.007713, T: 170676, Avg. loss: 0.001103\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.001613, T: 227568, Avg. loss: 0.001082\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.08, NNZs: 1, Bias: -0.011085, T: 284460, Avg. loss: 0.001071\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001072, T: 341352, Avg. loss: 0.001062\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.003382, T: 398244, Avg. loss: 0.001059\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.006431, T: 56892, Avg. loss: 0.004259\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.002849, T: 113784, Avg. loss: 0.001132\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.007499, T: 170676, Avg. loss: 0.001078\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.008374, T: 227568, Avg. loss: 0.001056\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.006609, T: 284460, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.000365, T: 341352, Avg. loss: 0.001040\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.007207, T: 398244, Avg. loss: 0.001034\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.001252, T: 56892, Avg. loss: 0.004302\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.001180, T: 113784, Avg. loss: 0.001159\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.09, NNZs: 1, Bias: -0.003072, T: 170676, Avg. loss: 0.001099\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.003443, T: 227568, Avg. loss: 0.001079\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.011613, T: 284460, Avg. loss: 0.001068\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.002133, T: 341352, Avg. loss: 0.001059\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.002097, T: 398244, Avg. loss: 0.001056\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.005764, T: 56892, Avg. loss: 0.004228\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.003933, T: 113784, Avg. loss: 0.001052\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.002462, T: 170676, Avg. loss: 0.000997\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.016392, T: 227568, Avg. loss: 0.000979\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.004151, T: 284460, Avg. loss: 0.000968\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.004938, T: 341352, Avg. loss: 0.000961\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.002917, T: 398244, Avg. loss: 0.000957\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 7 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010218, T: 56892, Avg. loss: 0.474041\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.164296, T: 113784, Avg. loss: 0.014631\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008743, T: 170676, Avg. loss: 0.005650\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.051941, T: 227568, Avg. loss: 0.003626\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.026834, T: 284460, Avg. loss: 0.002972\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.96, NNZs: 1, Bias: -0.020798, T: 341352, Avg. loss: 0.002671\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.033673, T: 398244, Avg. loss: 0.002400\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.008661, T: 455136, Avg. loss: 0.002254\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.028152, T: 512028, Avg. loss: 0.002147\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.92, NNZs: 1, Bias: 0.179961, T: 56892, Avg. loss: 0.485022\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.007359, T: 113784, Avg. loss: 0.015504\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.006403, T: 170676, Avg. loss: 0.006056\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.006173, T: 227568, Avg. loss: 0.003925\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006166, T: 284460, Avg. loss: 0.003217\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.035548, T: 341352, Avg. loss: 0.002765\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.031463, T: 398244, Avg. loss: 0.002572\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006451, T: 455136, Avg. loss: 0.002409\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.006510, T: 512028, Avg. loss: 0.002293\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 9 epochs took 0.03 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.008077, T: 56892, Avg. loss: 0.485677\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.008312, T: 113784, Avg. loss: 0.014433\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.007604, T: 170676, Avg. loss: 0.005615\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007521, T: 227568, Avg. loss: 0.003761\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.007558, T: 284460, Avg. loss: 0.003039\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.021392, T: 341352, Avg. loss: 0.002652\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.033105, T: 398244, Avg. loss: 0.002466\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008220, T: 455136, Avg. loss: 0.002274\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.011166, T: 512028, Avg. loss: 0.002223\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.161293, T: 56892, Avg. loss: 0.481982\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 1, Bias: -0.077232, T: 113784, Avg. loss: 0.016035\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.90, NNZs: 1, Bias: -0.049642, T: 170676, Avg. loss: 0.006035\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008021, T: 227568, Avg. loss: 0.003943\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.027283, T: 284460, Avg. loss: 0.003160\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.021398, T: 341352, Avg. loss: 0.002767\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.007809, T: 398244, Avg. loss: 0.002508\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.014172, T: 455136, Avg. loss: 0.002383\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 0.97, NNZs: 1, Bias: -0.011928, T: 512028, Avg. loss: 0.002285\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.008082, T: 56892, Avg. loss: 0.468246\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.008314, T: 113784, Avg. loss: 0.013717\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.007583, T: 170676, Avg. loss: 0.004954\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.007331, T: 227568, Avg. loss: 0.002992\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.007327, T: 284460, Avg. loss: 0.002354\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.007363, T: 341352, Avg. loss: 0.002032\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.007419, T: 398244, Avg. loss: 0.001823\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.014532, T: 455136, Avg. loss: 0.001652\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.026864, T: 512028, Avg. loss: 0.001625\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 101.56, NNZs: 1, Bias: -0.166521, T: 56892, Avg. loss: 0.462647\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 101.57, NNZs: 1, Bias: -0.080164, T: 113784, Avg. loss: 0.014611\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 101.57, NNZs: 1, Bias: 0.006637, T: 170676, Avg. loss: 0.005562\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 101.58, NNZs: 1, Bias: 0.006505, T: 227568, Avg. loss: 0.003600\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 101.58, NNZs: 1, Bias: 0.006819, T: 284460, Avg. loss: 0.002977\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 101.58, NNZs: 1, Bias: -0.022051, T: 341352, Avg. loss: 0.002612\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 101.58, NNZs: 1, Bias: 0.007361, T: 398244, Avg. loss: 0.002372\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 101.58, NNZs: 1, Bias: 0.007617, T: 455136, Avg. loss: 0.002230\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 101.58, NNZs: 1, Bias: 0.007701, T: 512028, Avg. loss: 0.002157\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 99.04, NNZs: 1, Bias: 0.010183, T: 56892, Avg. loss: 0.446540\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 99.05, NNZs: 1, Bias: 0.009176, T: 113784, Avg. loss: 0.015678\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 99.05, NNZs: 1, Bias: -0.050461, T: 170676, Avg. loss: 0.005997\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 99.06, NNZs: 1, Bias: -0.036502, T: 227568, Avg. loss: 0.003871\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 99.06, NNZs: 1, Bias: 0.007120, T: 284460, Avg. loss: 0.003208\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 99.06, NNZs: 1, Bias: 0.007123, T: 341352, Avg. loss: 0.002814\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 99.06, NNZs: 1, Bias: 0.032047, T: 398244, Avg. loss: 0.002555\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 99.06, NNZs: 1, Bias: 0.028905, T: 455136, Avg. loss: 0.002410\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 99.07, NNZs: 1, Bias: 0.006984, T: 512028, Avg. loss: 0.002313\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 100.98, NNZs: 1, Bias: 0.008205, T: 56892, Avg. loss: 0.456308\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 100.99, NNZs: 1, Bias: 0.008733, T: 113784, Avg. loss: 0.014818\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 100.99, NNZs: 1, Bias: 0.008123, T: 170676, Avg. loss: 0.005581\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 101.00, NNZs: 1, Bias: -0.036035, T: 227568, Avg. loss: 0.003653\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 101.00, NNZs: 1, Bias: 0.008095, T: 284460, Avg. loss: 0.003071\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 101.00, NNZs: 1, Bias: -0.050299, T: 341352, Avg. loss: 0.002657\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 101.00, NNZs: 1, Bias: -0.016720, T: 398244, Avg. loss: 0.002408\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 101.00, NNZs: 1, Bias: -0.013500, T: 455136, Avg. loss: 0.002320\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 101.01, NNZs: 1, Bias: 0.027953, T: 512028, Avg. loss: 0.002209\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 9 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 99.42, NNZs: 1, Bias: 0.010653, T: 56892, Avg. loss: 0.439911\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 99.43, NNZs: 1, Bias: 0.009546, T: 113784, Avg. loss: 0.015739\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 99.43, NNZs: 1, Bias: 0.008292, T: 170676, Avg. loss: 0.006004\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 99.43, NNZs: 1, Bias: 0.051359, T: 227568, Avg. loss: 0.003898\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 99.44, NNZs: 1, Bias: 0.007495, T: 284460, Avg. loss: 0.003186\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 99.44, NNZs: 1, Bias: -0.021892, T: 341352, Avg. loss: 0.002789\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 99.44, NNZs: 1, Bias: 0.007428, T: 398244, Avg. loss: 0.002545\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 99.44, NNZs: 1, Bias: 0.007382, T: 455136, Avg. loss: 0.002416\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 99.44, NNZs: 1, Bias: 0.026839, T: 512028, Avg. loss: 0.002292\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 9 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 102.16, NNZs: 1, Bias: 0.008901, T: 56892, Avg. loss: 0.451776\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 102.16, NNZs: 1, Bias: 0.008536, T: 113784, Avg. loss: 0.013908\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 102.17, NNZs: 1, Bias: 0.066103, T: 170676, Avg. loss: 0.004884\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 102.17, NNZs: 1, Bias: 0.007429, T: 227568, Avg. loss: 0.003077\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 102.17, NNZs: 1, Bias: 0.007407, T: 284460, Avg. loss: 0.002347\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 102.17, NNZs: 1, Bias: 0.007529, T: 341352, Avg. loss: 0.002045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 102.17, NNZs: 1, Bias: -0.017438, T: 398244, Avg. loss: 0.001842\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 102.18, NNZs: 1, Bias: 0.007660, T: 455136, Avg. loss: 0.001688\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 102.18, NNZs: 1, Bias: 0.007512, T: 512028, Avg. loss: 0.001558\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 6.77, NNZs: 1, Bias: 0.009140, T: 56892, Avg. loss: 0.468076\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.92, NNZs: 1, Bias: 0.009154, T: 113784, Avg. loss: 0.014534\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.87, NNZs: 1, Bias: 0.008335, T: 170676, Avg. loss: 0.005623\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.36, NNZs: 1, Bias: 0.008081, T: 227568, Avg. loss: 0.003625\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.03, NNZs: 1, Bias: -0.026952, T: 284460, Avg. loss: 0.002979\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.82, NNZs: 1, Bias: -0.021116, T: 341352, Avg. loss: 0.002533\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.70, NNZs: 1, Bias: -0.016729, T: 398244, Avg. loss: 0.002394\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.60, NNZs: 1, Bias: -0.013552, T: 455136, Avg. loss: 0.002240\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.52, NNZs: 1, Bias: 0.027866, T: 512028, Avg. loss: 0.002136\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7.00, NNZs: 1, Bias: 0.008283, T: 56892, Avg. loss: 0.486703\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.02, NNZs: 1, Bias: 0.007898, T: 113784, Avg. loss: 0.015562\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 2.96, NNZs: 1, Bias: 0.006890, T: 170676, Avg. loss: 0.006133\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.42, NNZs: 1, Bias: 0.006694, T: 227568, Avg. loss: 0.003880\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.07, NNZs: 1, Bias: 0.006615, T: 284460, Avg. loss: 0.003187\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.88, NNZs: 1, Bias: 0.006513, T: 341352, Avg. loss: 0.002755\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.73, NNZs: 1, Bias: 0.006579, T: 398244, Avg. loss: 0.002568\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.63, NNZs: 1, Bias: 0.028414, T: 455136, Avg. loss: 0.002385\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.54, NNZs: 1, Bias: 0.025951, T: 512028, Avg. loss: 0.002285\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 9 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 6.74, NNZs: 1, Bias: 0.011355, T: 56892, Avg. loss: 0.459038\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.88, NNZs: 1, Bias: 0.010609, T: 113784, Avg. loss: 0.014818\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.85, NNZs: 1, Bias: 0.067769, T: 170676, Avg. loss: 0.005829\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.34, NNZs: 1, Bias: 0.009111, T: 227568, Avg. loss: 0.003679\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.05, NNZs: 1, Bias: 0.044192, T: 284460, Avg. loss: 0.003033\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.84, NNZs: 1, Bias: 0.038368, T: 341352, Avg. loss: 0.002630\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.68, NNZs: 1, Bias: 0.009231, T: 398244, Avg. loss: 0.002461\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.59, NNZs: 1, Bias: 0.031133, T: 455136, Avg. loss: 0.002267\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.49, NNZs: 1, Bias: -0.010283, T: 512028, Avg. loss: 0.002200\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 9 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 6.74, NNZs: 1, Bias: 0.008505, T: 56892, Avg. loss: 0.471122\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.87, NNZs: 1, Bias: 0.008067, T: 113784, Avg. loss: 0.016003\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.84, NNZs: 1, Bias: 0.007209, T: 170676, Avg. loss: 0.005971\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.34, NNZs: 1, Bias: 0.006926, T: 227568, Avg. loss: 0.003940\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.02, NNZs: 1, Bias: 0.006918, T: 284460, Avg. loss: 0.003124\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.82, NNZs: 1, Bias: 0.036244, T: 341352, Avg. loss: 0.002782\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.71, NNZs: 1, Bias: 0.007107, T: 398244, Avg. loss: 0.002533\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.57, NNZs: 1, Bias: -0.014862, T: 455136, Avg. loss: 0.002408\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.49, NNZs: 1, Bias: -0.012529, T: 512028, Avg. loss: 0.002276\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7.00, NNZs: 1, Bias: 0.007898, T: 56892, Avg. loss: 0.485698\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.01, NNZs: 1, Bias: 0.007911, T: 113784, Avg. loss: 0.013562\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.96, NNZs: 1, Bias: 0.007454, T: 170676, Avg. loss: 0.004915\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.41, NNZs: 1, Bias: 0.007277, T: 227568, Avg. loss: 0.003050\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.09, NNZs: 1, Bias: 0.007295, T: 284460, Avg. loss: 0.002382\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.87, NNZs: 1, Bias: 0.007324, T: 341352, Avg. loss: 0.002028\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.74, NNZs: 1, Bias: 0.007567, T: 398244, Avg. loss: 0.001825\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.62, NNZs: 1, Bias: 0.007540, T: 455136, Avg. loss: 0.001702\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.55, NNZs: 1, Bias: -0.031484, T: 512028, Avg. loss: 0.001591\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000192, T: 56892, Avg. loss: 0.002556\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000878, T: 113784, Avg. loss: 0.001223\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001532, T: 170676, Avg. loss: 0.001223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000515, T: 227568, Avg. loss: 0.001223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: 0.001285, T: 284460, Avg. loss: 0.001222\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000924, T: 341352, Avg. loss: 0.001223\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000778, T: 398244, Avg. loss: 0.001222\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000598, T: 56892, Avg. loss: 0.002577\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000746, T: 113784, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000281, T: 170676, Avg. loss: 0.001252\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001299, T: 227568, Avg. loss: 0.001252\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001313, T: 284460, Avg. loss: 0.001252\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000425, T: 341352, Avg. loss: 0.001252\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001206, T: 398244, Avg. loss: 0.001252\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001227, T: 56892, Avg. loss: 0.002538\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000864, T: 113784, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001098, T: 170676, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000652, T: 227568, Avg. loss: 0.001247\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003108, T: 284460, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000191, T: 341352, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000204, T: 398244, Avg. loss: 0.001247\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002029, T: 56892, Avg. loss: 0.002615\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000712, T: 113784, Avg. loss: 0.001255\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000236, T: 170676, Avg. loss: 0.001255\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000740, T: 227568, Avg. loss: 0.001255\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000467, T: 284460, Avg. loss: 0.001255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.000433, T: 341352, Avg. loss: 0.001255\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001141, T: 398244, Avg. loss: 0.001255\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000212, T: 56892, Avg. loss: 0.002412\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000180, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000752, T: 170676, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000808, T: 227568, Avg. loss: 0.001045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000607, T: 284460, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000466, T: 341352, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000221, T: 398244, Avg. loss: 0.001045\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000318, T: 56892, Avg. loss: 0.002512\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000266, T: 113784, Avg. loss: 0.001223\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001255, T: 170676, Avg. loss: 0.001223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000073, T: 227568, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001019, T: 284460, Avg. loss: 0.001223\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000507, T: 341352, Avg. loss: 0.001222\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000481, T: 398244, Avg. loss: 0.001223\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001667, T: 56892, Avg. loss: 0.002492\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001026, T: 113784, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001113, T: 170676, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000648, T: 227568, Avg. loss: 0.001252\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000899, T: 284460, Avg. loss: 0.001252\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000323, T: 341352, Avg. loss: 0.001252\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.02, NNZs: 1, Bias: -0.000462, T: 398244, Avg. loss: 0.001252\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000193, T: 56892, Avg. loss: 0.002544\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000933, T: 113784, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001888, T: 170676, Avg. loss: 0.001247\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000479, T: 227568, Avg. loss: 0.001247\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001175, T: 284460, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000714, T: 341352, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000567, T: 398244, Avg. loss: 0.001247\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001226, T: 56892, Avg. loss: 0.002577\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000764, T: 113784, Avg. loss: 0.001255\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000295, T: 170676, Avg. loss: 0.001255\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001193, T: 227568, Avg. loss: 0.001255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000922, T: 284460, Avg. loss: 0.001255\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000708, T: 341352, Avg. loss: 0.001255\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000003, T: 398244, Avg. loss: 0.001255\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000264, T: 56892, Avg. loss: 0.002389\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000574, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000296, T: 170676, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000665, T: 227568, Avg. loss: 0.001045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000510, T: 284460, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000705, T: 341352, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.02, NNZs: 1, Bias: 0.000110, T: 398244, Avg. loss: 0.001045\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000971, T: 56892, Avg. loss: 0.002513\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001262, T: 113784, Avg. loss: 0.001222\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000680, T: 170676, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000200, T: 227568, Avg. loss: 0.001223\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000121, T: 284460, Avg. loss: 0.001223\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000349, T: 341352, Avg. loss: 0.001223\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001030, T: 398244, Avg. loss: 0.001223\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 7 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000460, T: 56892, Avg. loss: 0.002625\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000269, T: 113784, Avg. loss: 0.001253\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000697, T: 170676, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000577, T: 227568, Avg. loss: 0.001252\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000445, T: 284460, Avg. loss: 0.001252\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000149, T: 341352, Avg. loss: 0.001252\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000433, T: 398244, Avg. loss: 0.001252\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000403, T: 56892, Avg. loss: 0.002544\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000999, T: 113784, Avg. loss: 0.001247\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000284, T: 170676, Avg. loss: 0.001247\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001718, T: 227568, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: 0.000520, T: 284460, Avg. loss: 0.001247\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000570, T: 341352, Avg. loss: 0.001247\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000303, T: 398244, Avg. loss: 0.001247\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 7 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000857, T: 56892, Avg. loss: 0.002597\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001915, T: 113784, Avg. loss: 0.001255\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000558, T: 170676, Avg. loss: 0.001255\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000634, T: 227568, Avg. loss: 0.001255\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000642, T: 284460, Avg. loss: 0.001255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001374, T: 341352, Avg. loss: 0.001255\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000540, T: 398244, Avg. loss: 0.001255\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000743, T: 56892, Avg. loss: 0.002309\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000011, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001079, T: 170676, Avg. loss: 0.001045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001284, T: 227568, Avg. loss: 0.001045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001187, T: 284460, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000600, T: 341352, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000186, T: 398244, Avg. loss: 0.001045\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001703, T: 56892, Avg. loss: 0.005679\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002049, T: 113784, Avg. loss: 0.001002\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002189, T: 170676, Avg. loss: 0.001002\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001295, T: 227568, Avg. loss: 0.001002\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.001805, T: 284460, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001536, T: 341352, Avg. loss: 0.001002\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002439, T: 398244, Avg. loss: 0.001002\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002370, T: 56892, Avg. loss: 0.005747\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002199, T: 113784, Avg. loss: 0.001033\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002331, T: 170676, Avg. loss: 0.001033\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002106, T: 227568, Avg. loss: 0.001033\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001840, T: 284460, Avg. loss: 0.001033\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002505, T: 341352, Avg. loss: 0.001033\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002270, T: 398244, Avg. loss: 0.001033\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000131, T: 56892, Avg. loss: 0.005708\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000041, T: 113784, Avg. loss: 0.001010\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001087, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000763, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001356, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000922, T: 341352, Avg. loss: 0.001010\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001428, T: 398244, Avg. loss: 0.001010\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002187, T: 56892, Avg. loss: 0.005722\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001583, T: 113784, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002749, T: 170676, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001072, T: 227568, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002089, T: 284460, Avg. loss: 0.001031\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001568, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.001439, T: 398244, Avg. loss: 0.001031\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001946, T: 56892, Avg. loss: 0.005646\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001834, T: 113784, Avg. loss: 0.000933\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001310, T: 170676, Avg. loss: 0.000932\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001251, T: 227568, Avg. loss: 0.000933\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001506, T: 284460, Avg. loss: 0.000933\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001229, T: 341352, Avg. loss: 0.000932\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001945, T: 398244, Avg. loss: 0.000933\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002304, T: 56892, Avg. loss: 0.005774\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002693, T: 113784, Avg. loss: 0.001002\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002954, T: 170676, Avg. loss: 0.001002\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001443, T: 227568, Avg. loss: 0.001002\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000559, T: 284460, Avg. loss: 0.001002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001740, T: 341352, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001855, T: 398244, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003398, T: 56892, Avg. loss: 0.005714\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002375, T: 113784, Avg. loss: 0.001034\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002394, T: 170676, Avg. loss: 0.001033\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001181, T: 227568, Avg. loss: 0.001033\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001794, T: 284460, Avg. loss: 0.001033\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002021, T: 341352, Avg. loss: 0.001033\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002286, T: 398244, Avg. loss: 0.001033\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002163, T: 56892, Avg. loss: 0.005695\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001010, T: 113784, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001226, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001693, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002493, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000555, T: 341352, Avg. loss: 0.001010\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001404, T: 398244, Avg. loss: 0.001010\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002966, T: 56892, Avg. loss: 0.005700\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001241, T: 113784, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.003073, T: 170676, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001605, T: 227568, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001440, T: 284460, Avg. loss: 0.001031\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002078, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002128, T: 398244, Avg. loss: 0.001031\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001349, T: 56892, Avg. loss: 0.005641\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000810, T: 113784, Avg. loss: 0.000933\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001893, T: 170676, Avg. loss: 0.000933\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001556, T: 227568, Avg. loss: 0.000933\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000772, T: 284460, Avg. loss: 0.000933\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001636, T: 341352, Avg. loss: 0.000933\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000353, T: 398244, Avg. loss: 0.000932\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.002516, T: 56892, Avg. loss: 0.005679\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003266, T: 113784, Avg. loss: 0.001002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003402, T: 170676, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001713, T: 227568, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001191, T: 284460, Avg. loss: 0.001002\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001689, T: 341352, Avg. loss: 0.001002\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002481, T: 398244, Avg. loss: 0.001002\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 7 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002664, T: 56892, Avg. loss: 0.005707\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002661, T: 113784, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003088, T: 170676, Avg. loss: 0.001033\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001984, T: 227568, Avg. loss: 0.001033\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002219, T: 284460, Avg. loss: 0.001033\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002757, T: 341352, Avg. loss: 0.001034\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000752, T: 398244, Avg. loss: 0.001033\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000314, T: 56892, Avg. loss: 0.005762\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001566, T: 113784, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000822, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001532, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001428, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001007, T: 341352, Avg. loss: 0.001010\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001545, T: 398244, Avg. loss: 0.001010\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.002193, T: 56892, Avg. loss: 0.005730\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001264, T: 113784, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002706, T: 170676, Avg. loss: 0.001031\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001571, T: 227568, Avg. loss: 0.001031\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002890, T: 284460, Avg. loss: 0.001031\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002168, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001832, T: 398244, Avg. loss: 0.001031\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001724, T: 56892, Avg. loss: 0.005635\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001267, T: 113784, Avg. loss: 0.000932\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001313, T: 170676, Avg. loss: 0.000932\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000576, T: 227568, Avg. loss: 0.000933\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001131, T: 284460, Avg. loss: 0.000933\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000595, T: 341352, Avg. loss: 0.000932\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000784, T: 398244, Avg. loss: 0.000932\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008185, T: 56892, Avg. loss: 0.003670\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005321, T: 113784, Avg. loss: 0.001639\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006509, T: 170676, Avg. loss: 0.001638\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009196, T: 227568, Avg. loss: 0.001636\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002649, T: 284460, Avg. loss: 0.001633\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.013098, T: 341352, Avg. loss: 0.001634\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008547, T: 398244, Avg. loss: 0.001638\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001954, T: 56892, Avg. loss: 0.003787\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: 0.002167, T: 113784, Avg. loss: 0.001719\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000621, T: 170676, Avg. loss: 0.001720\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005625, T: 227568, Avg. loss: 0.001717\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000222, T: 284460, Avg. loss: 0.001718\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000156, T: 341352, Avg. loss: 0.001716\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001868, T: 398244, Avg. loss: 0.001717\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.011890, T: 56892, Avg. loss: 0.003713\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006366, T: 113784, Avg. loss: 0.001697\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007107, T: 170676, Avg. loss: 0.001696\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009030, T: 227568, Avg. loss: 0.001695\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009860, T: 284460, Avg. loss: 0.001694\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008161, T: 341352, Avg. loss: 0.001692\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008180, T: 398244, Avg. loss: 0.001693\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001596, T: 56892, Avg. loss: 0.003762\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005455, T: 113784, Avg. loss: 0.001728\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001722, T: 170676, Avg. loss: 0.001723\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000875, T: 227568, Avg. loss: 0.001726\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003934, T: 284460, Avg. loss: 0.001721\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005495, T: 341352, Avg. loss: 0.001726\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001419, T: 398244, Avg. loss: 0.001724\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001225, T: 56892, Avg. loss: 0.003100\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000948, T: 113784, Avg. loss: 0.001077\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.003659, T: 170676, Avg. loss: 0.001075\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001197, T: 227568, Avg. loss: 0.001074\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: -0.002472, T: 284460, Avg. loss: 0.001072\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.003644, T: 341352, Avg. loss: 0.001072\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.002028, T: 398244, Avg. loss: 0.001070\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009472, T: 56892, Avg. loss: 0.003652\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.004766, T: 113784, Avg. loss: 0.001641\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008823, T: 170676, Avg. loss: 0.001637\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.005003, T: 227568, Avg. loss: 0.001639\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.006414, T: 284460, Avg. loss: 0.001638\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.007271, T: 341352, Avg. loss: 0.001635\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.006849, T: 398244, Avg. loss: 0.001634\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001516, T: 56892, Avg. loss: 0.003771\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001496, T: 113784, Avg. loss: 0.001720\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.003406, T: 170676, Avg. loss: 0.001718\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.001422, T: 227568, Avg. loss: 0.001717\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.004404, T: 284460, Avg. loss: 0.001717\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.005056, T: 341352, Avg. loss: 0.001717\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.001761, T: 398244, Avg. loss: 0.001717\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007959, T: 56892, Avg. loss: 0.003709\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.005824, T: 113784, Avg. loss: 0.001694\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.009020, T: 170676, Avg. loss: 0.001693\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.009890, T: 227568, Avg. loss: 0.001696\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.006856, T: 284460, Avg. loss: 0.001694\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.013511, T: 341352, Avg. loss: 0.001691\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.005395, T: 398244, Avg. loss: 0.001693\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000107, T: 56892, Avg. loss: 0.003737\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.006146, T: 113784, Avg. loss: 0.001726\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000428, T: 170676, Avg. loss: 0.001726\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.003733, T: 227568, Avg. loss: 0.001727\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.002789, T: 284460, Avg. loss: 0.001725\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.000315, T: 341352, Avg. loss: 0.001723\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.003530, T: 398244, Avg. loss: 0.001724\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000304, T: 56892, Avg. loss: 0.003112\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.001220, T: 113784, Avg. loss: 0.001075\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.001396, T: 170676, Avg. loss: 0.001073\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.001383, T: 227568, Avg. loss: 0.001074\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000811, T: 284460, Avg. loss: 0.001070\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.005466, T: 341352, Avg. loss: 0.001073\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.000917, T: 398244, Avg. loss: 0.001071\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010602, T: 56892, Avg. loss: 0.003637\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008512, T: 113784, Avg. loss: 0.001637\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010293, T: 170676, Avg. loss: 0.001637\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009562, T: 227568, Avg. loss: 0.001639\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.007344, T: 284460, Avg. loss: 0.001635\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001949, T: 341352, Avg. loss: 0.001638\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008857, T: 398244, Avg. loss: 0.001638\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.02, NNZs: 1, Bias: -0.000868, T: 56892, Avg. loss: 0.003703\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001004, T: 113784, Avg. loss: 0.001719\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000501, T: 170676, Avg. loss: 0.001718\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001284, T: 227568, Avg. loss: 0.001720\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001854, T: 284460, Avg. loss: 0.001718\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001408, T: 341352, Avg. loss: 0.001717\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001791, T: 398244, Avg. loss: 0.001716\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009288, T: 56892, Avg. loss: 0.003688\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010309, T: 113784, Avg. loss: 0.001696\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008229, T: 170676, Avg. loss: 0.001695\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008747, T: 227568, Avg. loss: 0.001696\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006573, T: 284460, Avg. loss: 0.001692\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006657, T: 341352, Avg. loss: 0.001693\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008726, T: 398244, Avg. loss: 0.001692\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007161, T: 56892, Avg. loss: 0.003724\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002641, T: 113784, Avg. loss: 0.001726\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.005516, T: 170676, Avg. loss: 0.001727\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003022, T: 227568, Avg. loss: 0.001729\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000866, T: 284460, Avg. loss: 0.001725\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003801, T: 341352, Avg. loss: 0.001724\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.004528, T: 398244, Avg. loss: 0.001726\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001030, T: 56892, Avg. loss: 0.003155\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.003013, T: 113784, Avg. loss: 0.001075\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.002099, T: 170676, Avg. loss: 0.001075\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000382, T: 227568, Avg. loss: 0.001074\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000859, T: 284460, Avg. loss: 0.001074\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002938, T: 341352, Avg. loss: 0.001070\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.004068, T: 398244, Avg. loss: 0.001070\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000406, T: 56892, Avg. loss: 0.001679\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001803, T: 113784, Avg. loss: 0.001236\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001358, T: 170676, Avg. loss: 0.001236\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.008916, T: 227568, Avg. loss: 0.001236\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003156, T: 284460, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003327, T: 341352, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004403, T: 56892, Avg. loss: 0.001708\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001247, T: 113784, Avg. loss: 0.001267\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.004281, T: 170676, Avg. loss: 0.001267\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004060, T: 227568, Avg. loss: 0.001265\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.005666, T: 284460, Avg. loss: 0.001265\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004341, T: 341352, Avg. loss: 0.001266\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002522, T: 56892, Avg. loss: 0.001712\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000560, T: 113784, Avg. loss: 0.001260\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000028, T: 170676, Avg. loss: 0.001261\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001682, T: 227568, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003287, T: 284460, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001696, T: 341352, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.006168, T: 56892, Avg. loss: 0.001716\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001201, T: 113784, Avg. loss: 0.001268\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004333, T: 170676, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004561, T: 227568, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003750, T: 284460, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001518, T: 341352, Avg. loss: 0.001268\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002894, T: 56892, Avg. loss: 0.001502\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000681, T: 113784, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003504, T: 170676, Avg. loss: 0.001056\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000872, T: 227568, Avg. loss: 0.001056\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000931, T: 284460, Avg. loss: 0.001057\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003240, T: 341352, Avg. loss: 0.001057\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000756, T: 56892, Avg. loss: 0.001691\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000367, T: 113784, Avg. loss: 0.001236\n",
            "Total training time: 0.01 seconds."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.006625, T: 170676, Avg. loss: 0.001235\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002280, T: 227568, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.006081, T: 284460, Avg. loss: 0.001236\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.000628, T: 341352, Avg. loss: 0.001235\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000550, T: 56892, Avg. loss: 0.001708\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000742, T: 113784, Avg. loss: 0.001267\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000771, T: 170676, Avg. loss: 0.001266\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001564, T: 227568, Avg. loss: 0.001267\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.001964, T: 284460, Avg. loss: 0.001265\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.000641, T: 341352, Avg. loss: 0.001266\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000854, T: 56892, Avg. loss: 0.001698\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.006149, T: 113784, Avg. loss: 0.001261\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000677, T: 170676, Avg. loss: 0.001261\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000943, T: 227568, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001439, T: 284460, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.001909, T: 341352, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002326, T: 56892, Avg. loss: 0.001707\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002157, T: 113784, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.006747, T: 170676, Avg. loss: 0.001268\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.004433, T: 227568, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.000369, T: 284460, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.002561, T: 341352, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000438, T: 56892, Avg. loss: 0.001503\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.004345, T: 113784, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.005447, T: 170676, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002688, T: 227568, Avg. loss: 0.001058\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.003375, T: 284460, Avg. loss: 0.001057\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.002310, T: 341352, Avg. loss: 0.001057\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001287, T: 56892, Avg. loss: 0.001679\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000760, T: 113784, Avg. loss: 0.001237\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004341, T: 170676, Avg. loss: 0.001237\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000747, T: 227568, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002038, T: 284460, Avg. loss: 0.001237\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005082, T: 341352, Avg. loss: 0.001236\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: 0.005368, T: 56892, Avg. loss: 0.001712\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.004274, T: 113784, Avg. loss: 0.001265\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004598, T: 170676, Avg. loss: 0.001265\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000939, T: 227568, Avg. loss: 0.001266\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001877, T: 284460, Avg. loss: 0.001266\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001949, T: 341352, Avg. loss: 0.001266\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004441, T: 56892, Avg. loss: 0.001703\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000315, T: 113784, Avg. loss: 0.001260\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000374, T: 170676, Avg. loss: 0.001260\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000744, T: 227568, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002223, T: 284460, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003546, T: 341352, Avg. loss: 0.001261\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001305, T: 56892, Avg. loss: 0.001716\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001989, T: 113784, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002646, T: 170676, Avg. loss: 0.001268\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005314, T: 227568, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004014, T: 284460, Avg. loss: 0.001269\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000528, T: 341352, Avg. loss: 0.001268\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.008199, T: 56892, Avg. loss: 0.001498\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.004740, T: 113784, Avg. loss: 0.001056\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000933, T: 170676, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000027, T: 227568, Avg. loss: 0.001057\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001915, T: 284460, Avg. loss: 0.001056\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000867, T: 341352, Avg. loss: 0.001056\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002753, T: 56892, Avg. loss: 0.001787\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000778, T: 113784, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.006538, T: 170676, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.007181, T: 227568, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000174, T: 284460, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003591, T: 341352, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000918, T: 56892, Avg. loss: 0.001818\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002534, T: 113784, Avg. loss: 0.001041\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.006150, T: 170676, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003867, T: 227568, Avg. loss: 0.001043\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001607, T: 284460, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002869, T: 341352, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002738, T: 56892, Avg. loss: 0.001793\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.006871, T: 113784, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.005275, T: 170676, Avg. loss: 0.001020\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001562, T: 227568, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000028, T: 284460, Avg. loss: 0.001020\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000178, T: 341352, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: 0.002729, T: 56892, Avg. loss: 0.001817\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.008280, T: 113784, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001245, T: 170676, Avg. loss: 0.001039\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002526, T: 227568, Avg. loss: 0.001040\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000120, T: 284460, Avg. loss: 0.001039\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004004, T: 341352, Avg. loss: 0.001040\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003293, T: 56892, Avg. loss: 0.001717\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002317, T: 113784, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000169, T: 170676, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001881, T: 227568, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.006230, T: 284460, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004561, T: 341352, Avg. loss: 0.000940\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005427, T: 56892, Avg. loss: 0.001785\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001699, T: 113784, Avg. loss: 0.001010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.002101, T: 170676, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.003925, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.002855, T: 284460, Avg. loss: 0.001011\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.002681, T: 341352, Avg. loss: 0.001011\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003693, T: 56892, Avg. loss: 0.001822\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.007324, T: 113784, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001960, T: 170676, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.004106, T: 227568, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.003339, T: 284460, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.002223, T: 341352, Avg. loss: 0.001042\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002315, T: 56892, Avg. loss: 0.001800\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004878, T: 113784, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001084, T: 170676, Avg. loss: 0.001018\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000163, T: 227568, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.004612, T: 284460, Avg. loss: 0.001018\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000549, T: 341352, Avg. loss: 0.001018\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005637, T: 56892, Avg. loss: 0.001814\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.008028, T: 113784, Avg. loss: 0.001039\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.004557, T: 170676, Avg. loss: 0.001039\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000890, T: 227568, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.002147, T: 284460, Avg. loss: 0.001039\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000146, T: 341352, Avg. loss: 0.001040\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001788, T: 56892, Avg. loss: 0.001721\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005295, T: 113784, Avg. loss: 0.000940\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: -0.002615, T: 170676, Avg. loss: 0.000942\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.005152, T: 227568, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002745, T: 284460, Avg. loss: 0.000941\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.001085, T: 341352, Avg. loss: 0.000941\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001845, T: 56892, Avg. loss: 0.001792\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004105, T: 113784, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001319, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002817, T: 227568, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001656, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004330, T: 341352, Avg. loss: 0.001011\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000531, T: 56892, Avg. loss: 0.001819\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.008286, T: 113784, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002772, T: 170676, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005985, T: 227568, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004839, T: 284460, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004049, T: 341352, Avg. loss: 0.001042\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002747, T: 56892, Avg. loss: 0.001802\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001767, T: 113784, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001919, T: 170676, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000695, T: 227568, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003748, T: 284460, Avg. loss: 0.001020\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003898, T: 341352, Avg. loss: 0.001019\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002164, T: 56892, Avg. loss: 0.001816\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001853, T: 113784, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003543, T: 170676, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004668, T: 227568, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002253, T: 284460, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000078, T: 341352, Avg. loss: 0.001041\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000076, T: 56892, Avg. loss: 0.001721\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001498, T: 113784, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001388, T: 170676, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001412, T: 227568, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005147, T: 284460, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003335, T: 341352, Avg. loss: 0.000941\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.002536\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001826\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001820\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.001822\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001836\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001822\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.010000, T: 56892, Avg. loss: 0.002669\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.001949\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001951\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010000, T: 227568, Avg. loss: 0.001944\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.001933\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001952\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010000, T: 56892, Avg. loss: 0.002600\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001888\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001886\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001877\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.010000, T: 284460, Avg. loss: 0.001897\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.001887\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002676\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001924\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001935\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.010000, T: 227568, Avg. loss: 0.001935\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001920\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001943\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002011\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010000, T: 113784, Avg. loss: 0.001264\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001283\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 227568, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.010000, T: 284460, Avg. loss: 0.001263\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010000, T: 341352, Avg. loss: 0.001283\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002539\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030000, T: 113784, Avg. loss: 0.001826\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.000000, T: 170676, Avg. loss: 0.001822\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.010000, T: 227568, Avg. loss: 0.001827\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.000000, T: 284460, Avg. loss: 0.001813\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000000, T: 341352, Avg. loss: 0.001831\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002669\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001946\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.020000, T: 170676, Avg. loss: 0.001935\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001937\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.001951\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001936\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.002620\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001890\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.010000, T: 170676, Avg. loss: 0.001881\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001890\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.000000, T: 284460, Avg. loss: 0.001879\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001898\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.010000, T: 56892, Avg. loss: 0.002661\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.02, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.001954\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.030000, T: 227568, Avg. loss: 0.001945\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.001940\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.030000, T: 341352, Avg. loss: 0.001941\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002009\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001288\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.001267\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.001276\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.010000, T: 341352, Avg. loss: 0.001266\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.002570\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.010000, T: 113784, Avg. loss: 0.001830\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.001831\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001822\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.001824\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001829\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002689\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000000, T: 113784, Avg. loss: 0.001935\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010000, T: 170676, Avg. loss: 0.001939\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001936\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001937\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000000, T: 341352, Avg. loss: 0.001947\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002633\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.010000, T: 113784, Avg. loss: 0.001888\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001876\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.010000, T: 227568, Avg. loss: 0.001885\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001886\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001904\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010000, T: 56892, Avg. loss: 0.002679\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000000, T: 113784, Avg. loss: 0.001948\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.000000, T: 170676, Avg. loss: 0.001949\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001927\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000000, T: 284460, Avg. loss: 0.001943\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000000, T: 341352, Avg. loss: 0.001952\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002011\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001262\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001270\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 227568, Avg. loss: 0.001267\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001281\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.020000, T: 341352, Avg. loss: 0.001257\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 533620461371.51, NNZs: 1, Bias: 109295340247.412476, T: 56892, Avg. loss: 19562996402153975936188416.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: nan, NNZs: 1, Bias: -0.036989, T: 113784, Avg. loss: 283239269651626032365568.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: nan, NNZs: 1, Bias: -0.007763, T: 170676, Avg. loss: 0.018965\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: nan, NNZs: 1, Bias: 0.006890, T: 227568, Avg. loss: 0.003008\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: nan, NNZs: 1, Bias: -0.002239, T: 284460, Avg. loss: 0.002210\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: nan, NNZs: 1, Bias: 0.015030, T: 341352, Avg. loss: 0.001927\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: nan, NNZs: 1, Bias: -0.000717, T: 398244, Avg. loss: 0.001779\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: nan, NNZs: 1, Bias: 0.032642, T: 455136, Avg. loss: 0.001662\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: nan, NNZs: 1, Bias: -0.000741, T: 512028, Avg. loss: 0.001603\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 2527395964030.37, NNZs: 1, Bias: 795927500957.945557, T: 56892, Avg. loss: 19673619902550062772781056.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 86437.23, NNZs: 1, Bias: 0.069196, T: 113784, Avg. loss: 280035033124469271953408.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 58543.69, NNZs: 1, Bias: 0.020466, T: 170676, Avg. loss: 0.012368\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 44260.65, NNZs: 1, Bias: 0.015050, T: 227568, Avg. loss: 0.003117\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 35580.09, NNZs: 1, Bias: 0.065912, T: 284460, Avg. loss: 0.002286\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 29746.17, NNZs: 1, Bias: -0.022580, T: 341352, Avg. loss: 0.001989\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 25555.88, NNZs: 1, Bias: -0.016197, T: 398244, Avg. loss: 0.001810\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 22400.37, NNZs: 1, Bias: 0.018166, T: 455136, Avg. loss: 0.001709\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 19938.47, NNZs: 1, Bias: -0.008639, T: 512028, Avg. loss: 0.001639\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 9 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 2170983445031.81, NNZs: 1, Bias: 69128080954.983398, T: 56892, Avg. loss: 19557142443858833168138240.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: nan, NNZs: 1, Bias: -0.070738, T: 113784, Avg. loss: 280445530620893646028800.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: nan, NNZs: 1, Bias: -0.000316, T: 170676, Avg. loss: 0.010193\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: nan, NNZs: 1, Bias: 0.026711, T: 227568, Avg. loss: 0.003057\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: nan, NNZs: 1, Bias: -0.012067, T: 284460, Avg. loss: 0.002272\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: nan, NNZs: 1, Bias: 0.027896, T: 341352, Avg. loss: 0.001967\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: nan, NNZs: 1, Bias: -0.003486, T: 398244, Avg. loss: 0.001822\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: nan, NNZs: 1, Bias: -0.019192, T: 455136, Avg. loss: 0.001695\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: nan, NNZs: 1, Bias: -0.006001, T: 512028, Avg. loss: 0.001620\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 9 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 13275881125.86, NNZs: 1, Bias: 165807683404.143311, T: 56892, Avg. loss: 19740289804393530928398336.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 188569.03, NNZs: 1, Bias: -0.054039, T: 113784, Avg. loss: 278523369271136601767936.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 127717.27, NNZs: 1, Bias: -0.014838, T: 170676, Avg. loss: 0.016335\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 96557.79, NNZs: 1, Bias: 0.024435, T: 227568, Avg. loss: 0.003092\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 77620.53, NNZs: 1, Bias: -0.022726, T: 284460, Avg. loss: 0.002285\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 64893.41, NNZs: 1, Bias: -0.029743, T: 341352, Avg. loss: 0.001995\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 55751.98, NNZs: 1, Bias: -0.019716, T: 398244, Avg. loss: 0.001827\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 48868.02, NNZs: 1, Bias: -0.014667, T: 455136, Avg. loss: 0.001709\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 43497.22, NNZs: 1, Bias: 0.010638, T: 512028, Avg. loss: 0.001648\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 694404747093.57, NNZs: 1, Bias: 37599509574.665588, T: 56892, Avg. loss: 19939381426235794341756928.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 116347.94, NNZs: 1, Bias: 0.021557, T: 113784, Avg. loss: 279054849428450774614016.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 78802.13, NNZs: 1, Bias: -0.036249, T: 170676, Avg. loss: 0.014032\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 59576.59, NNZs: 1, Bias: 0.000206, T: 227568, Avg. loss: 0.002580\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 47892.22, NNZs: 1, Bias: -0.021656, T: 284460, Avg. loss: 0.001911\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 40039.52, NNZs: 1, Bias: -0.005329, T: 341352, Avg. loss: 0.001658\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 34399.22, NNZs: 1, Bias: 0.022147, T: 398244, Avg. loss: 0.001513\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Norm: 30151.79, NNZs: 1, Bias: -0.001774, T: 455136, Avg. loss: 0.001430\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 26837.98, NNZs: 1, Bias: -0.024375, T: 512028, Avg. loss: 0.001371\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 622906595855.05, NNZs: 1, Bias: -249453264770.268463, T: 56892, Avg. loss: 19817387640961130263740416.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 594535117.70, NNZs: 1, Bias: 0.149541, T: 113784, Avg. loss: 281403930949266840748032.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 594535117.70, NNZs: 1, Bias: 0.013468, T: 170676, Avg. loss: 0.012240\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 594535117.70, NNZs: 1, Bias: -0.012511, T: 227568, Avg. loss: 0.003002\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 594535117.70, NNZs: 1, Bias: 0.018738, T: 284460, Avg. loss: 0.002255\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 594535117.70, NNZs: 1, Bias: 0.009835, T: 341352, Avg. loss: 0.001927\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 594535117.70, NNZs: 1, Bias: -0.000891, T: 398244, Avg. loss: 0.001764\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 594535117.70, NNZs: 1, Bias: -0.001535, T: 455136, Avg. loss: 0.001666\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 594535117.70, NNZs: 1, Bias: -0.002820, T: 512028, Avg. loss: 0.001596\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 9 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 120936573515.82, NNZs: 1, Bias: 945881178209.846924, T: 56892, Avg. loss: 19447129339263001372393472.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 590828544.88, NNZs: 1, Bias: 0.270151, T: 113784, Avg. loss: 280099354332216808177664.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 590828544.88, NNZs: 1, Bias: 0.117696, T: 170676, Avg. loss: 0.012084\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 590828544.88, NNZs: 1, Bias: 0.014419, T: 227568, Avg. loss: 0.003094\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 590828544.88, NNZs: 1, Bias: 0.080534, T: 284460, Avg. loss: 0.002272\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 590828544.88, NNZs: 1, Bias: -0.017152, T: 341352, Avg. loss: 0.001977\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 590828544.88, NNZs: 1, Bias: 0.017242, T: 398244, Avg. loss: 0.001816\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 590828544.88, NNZs: 1, Bias: 0.002947, T: 455136, Avg. loss: 0.001708\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 590828544.88, NNZs: 1, Bias: 0.004984, T: 512028, Avg. loss: 0.001636\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1509486799937.66, NNZs: 1, Bias: -396659401857.263672, T: 56892, Avg. loss: 19648193104478757403492352.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 594562914.29, NNZs: 1, Bias: -0.046420, T: 113784, Avg. loss: 288173642544192012943360.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 594562914.29, NNZs: 1, Bias: 0.015061, T: 170676, Avg. loss: 0.010571\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 594562914.29, NNZs: 1, Bias: 0.045994, T: 227568, Avg. loss: 0.003093\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 594562914.29, NNZs: 1, Bias: 0.010062, T: 284460, Avg. loss: 0.002277\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 594562914.29, NNZs: 1, Bias: -0.033617, T: 341352, Avg. loss: 0.001964\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 594562914.29, NNZs: 1, Bias: 0.040749, T: 398244, Avg. loss: 0.001815\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 594562914.29, NNZs: 1, Bias: 0.012273, T: 455136, Avg. loss: 0.001698\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 594562914.29, NNZs: 1, Bias: -0.017741, T: 512028, Avg. loss: 0.001633\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 9 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1381269170938.59, NNZs: 1, Bias: -1064956414663.256470, T: 56892, Avg. loss: 19803695145770813354934272.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 593488500.67, NNZs: 1, Bias: 0.002524, T: 113784, Avg. loss: 281788310242037952675840.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 593488500.67, NNZs: 1, Bias: -0.003280, T: 170676, Avg. loss: 0.011791\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 593488500.67, NNZs: 1, Bias: -0.001210, T: 227568, Avg. loss: 0.003147\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 593488500.67, NNZs: 1, Bias: -0.028605, T: 284460, Avg. loss: 0.002303\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 593488500.67, NNZs: 1, Bias: -0.002826, T: 341352, Avg. loss: 0.001987\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 593488500.67, NNZs: 1, Bias: 0.015132, T: 398244, Avg. loss: 0.001822\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 593488500.67, NNZs: 1, Bias: 0.000391, T: 455136, Avg. loss: 0.001727\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 593488500.67, NNZs: 1, Bias: 0.004631, T: 512028, Avg. loss: 0.001654\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1875480297578.81, NNZs: 1, Bias: -592854155423.721924, T: 56892, Avg. loss: 19550551622767511171235840.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 589605769.51, NNZs: 1, Bias: 0.055722, T: 113784, Avg. loss: 286424846289614705524736.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 589605769.51, NNZs: 1, Bias: -0.003758, T: 170676, Avg. loss: 0.010755\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 589605769.51, NNZs: 1, Bias: 0.044095, T: 227568, Avg. loss: 0.002544\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 589605769.51, NNZs: 1, Bias: -0.026166, T: 284460, Avg. loss: 0.001924\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 589605769.51, NNZs: 1, Bias: -0.010328, T: 341352, Avg. loss: 0.001674\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 589605769.51, NNZs: 1, Bias: 0.030311, T: 398244, Avg. loss: 0.001516\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 589605769.51, NNZs: 1, Bias: -0.005631, T: 455136, Avg. loss: 0.001432\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 589605769.51, NNZs: 1, Bias: -0.010517, T: 512028, Avg. loss: 0.001371\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 9 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 512019498545.25, NNZs: 1, Bias: 2440181630727.904785, T: 56892, Avg. loss: 19755633386956309391212544.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 101128126.05, NNZs: 1, Bias: 0.191805, T: 113784, Avg. loss: 282741752439908606148608.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 72616346.82, NNZs: 1, Bias: 0.043099, T: 170676, Avg. loss: 0.015611\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 57252109.03, NNZs: 1, Bias: -0.013913, T: 227568, Avg. loss: 0.003021\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 47555681.69, NNZs: 1, Bias: -0.041084, T: 284460, Avg. loss: 0.002247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 40840663.06, NNZs: 1, Bias: 0.012047, T: 341352, Avg. loss: 0.001953\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 35895792.93, NNZs: 1, Bias: -0.025861, T: 398244, Avg. loss: 0.001764\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 32091746.55, NNZs: 1, Bias: 0.000055, T: 455136, Avg. loss: 0.001668\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 29067960.60, NNZs: 1, Bias: 0.027995, T: 512028, Avg. loss: 0.001603\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 486294834641.85, NNZs: 1, Bias: -1283751662102.646973, T: 56892, Avg. loss: 19655229755989421948141568.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 100830882.64, NNZs: 1, Bias: 0.068996, T: 113784, Avg. loss: 275596606845752333828096.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 72402907.38, NNZs: 1, Bias: 0.079989, T: 170676, Avg. loss: 0.014746\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 57083829.32, NNZs: 1, Bias: -0.020832, T: 227568, Avg. loss: 0.003107\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 47415902.44, NNZs: 1, Bias: -0.010244, T: 284460, Avg. loss: 0.002308\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 40720621.11, NNZs: 1, Bias: 0.016526, T: 341352, Avg. loss: 0.001979\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 35790285.32, NNZs: 1, Bias: 0.050211, T: 398244, Avg. loss: 0.001824\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 31997420.08, NNZs: 1, Bias: -0.017491, T: 455136, Avg. loss: 0.001718\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 28982521.86, NNZs: 1, Bias: 0.018464, T: 512028, Avg. loss: 0.001637\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 315054686475.20, NNZs: 1, Bias: 1128788691811.940186, T: 56892, Avg. loss: 19382619493590776126898176.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 100584765.42, NNZs: 1, Bias: 0.078343, T: 113784, Avg. loss: 284524038778557082632192.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 72226179.75, NNZs: 1, Bias: -0.051919, T: 170676, Avg. loss: 0.011510\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 56944493.90, NNZs: 1, Bias: -0.022913, T: 227568, Avg. loss: 0.003003\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 47300165.38, NNZs: 1, Bias: -0.016161, T: 284460, Avg. loss: 0.002261\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 40621226.50, NNZs: 1, Bias: -0.003269, T: 341352, Avg. loss: 0.001969\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 35702925.12, NNZs: 1, Bias: 0.009383, T: 398244, Avg. loss: 0.001810\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 31919317.85, NNZs: 1, Bias: -0.008268, T: 455136, Avg. loss: 0.001693\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 28911778.68, NNZs: 1, Bias: -0.007296, T: 512028, Avg. loss: 0.001626\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 9 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 509970809821.82, NNZs: 1, Bias: 20311300535.744598, T: 56892, Avg. loss: 19542745245491129011404800.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 101912132.06, NNZs: 1, Bias: -0.433166, T: 113784, Avg. loss: 288351233125860178395136.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 73179312.38, NNZs: 1, Bias: -0.024005, T: 170676, Avg. loss: 0.010810\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 57695961.79, NNZs: 1, Bias: -0.037194, T: 227568, Avg. loss: 0.003085\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 47924361.91, NNZs: 1, Bias: 0.023404, T: 284460, Avg. loss: 0.002300\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 41157284.42, NNZs: 1, Bias: 0.011849, T: 341352, Avg. loss: 0.001997\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 36174078.70, NNZs: 1, Bias: -0.011477, T: 398244, Avg. loss: 0.001825\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 32340541.06, NNZs: 1, Bias: 0.002434, T: 455136, Avg. loss: 0.001729\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 29293312.90, NNZs: 1, Bias: 0.003591, T: 512028, Avg. loss: 0.001655\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 9 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 546387828151.97, NNZs: 1, Bias: 1474887205004.029785, T: 56892, Avg. loss: 20063301679376083569344512.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 100471737.27, NNZs: 1, Bias: 0.221176, T: 113784, Avg. loss: 280791987436012089376768.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 72145018.44, NNZs: 1, Bias: 0.045867, T: 170676, Avg. loss: 0.009883\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 56880504.78, NNZs: 1, Bias: -0.027845, T: 227568, Avg. loss: 0.002615\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 47247013.69, NNZs: 1, Bias: 0.002158, T: 284460, Avg. loss: 0.001925\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 40575580.00, NNZs: 1, Bias: 0.017752, T: 341352, Avg. loss: 0.001668\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 35662805.37, NNZs: 1, Bias: -0.036662, T: 398244, Avg. loss: 0.001511\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 31883449.78, NNZs: 1, Bias: 0.011547, T: 455136, Avg. loss: 0.001429\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 28879290.21, NNZs: 1, Bias: 0.007621, T: 512028, Avg. loss: 0.001367\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 9 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.086971, T: 56892, Avg. loss: 0.034541\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.95, NNZs: 1, Bias: -0.090265, T: 113784, Avg. loss: 0.005234\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.026390, T: 170676, Avg. loss: 0.002507\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.010799, T: 227568, Avg. loss: 0.001788\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.023558, T: 284460, Avg. loss: 0.001531\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.021029, T: 341352, Avg. loss: 0.001396\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.027398, T: 398244, Avg. loss: 0.001320\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.006799, T: 455136, Avg. loss: 0.001266\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 8 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.90, NNZs: 1, Bias: 0.068599, T: 56892, Avg. loss: 0.034631\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.039197, T: 113784, Avg. loss: 0.005274\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.021492, T: 170676, Avg. loss: 0.002545\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008237, T: 227568, Avg. loss: 0.001846\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.017184, T: 284460, Avg. loss: 0.001577\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.024108, T: 341352, Avg. loss: 0.001441\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.017529, T: 398244, Avg. loss: 0.001357\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.011671, T: 455136, Avg. loss: 0.001305\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 8 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.09, NNZs: 1, Bias: -0.134480, T: 56892, Avg. loss: 0.034394\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.007626, T: 113784, Avg. loss: 0.005243\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.047614, T: 170676, Avg. loss: 0.002507\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010497, T: 227568, Avg. loss: 0.001806\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.97, NNZs: 1, Bias: -0.016122, T: 284460, Avg. loss: 0.001545\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.058790, T: 341352, Avg. loss: 0.001412\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.012621, T: 398244, Avg. loss: 0.001335\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.020677, T: 455136, Avg. loss: 0.001272\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 8 epochs took 0.05 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.109176, T: 56892, Avg. loss: 0.034581\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.024857, T: 113784, Avg. loss: 0.005268\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.018928, T: 170676, Avg. loss: 0.002517\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.005315, T: 227568, Avg. loss: 0.001834\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.012660, T: 284460, Avg. loss: 0.001575\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005584, T: 341352, Avg. loss: 0.001441\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.008585, T: 398244, Avg. loss: 0.001356\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.020838, T: 455136, Avg. loss: 0.001299\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 8 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.194575, T: 56892, Avg. loss: 0.034515\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.013520, T: 113784, Avg. loss: 0.005154\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.027443, T: 170676, Avg. loss: 0.002421\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.016596, T: 227568, Avg. loss: 0.001716\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.004121, T: 284460, Avg. loss: 0.001457\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002450, T: 341352, Avg. loss: 0.001334\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.011125, T: 398244, Avg. loss: 0.001245\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.012315, T: 455136, Avg. loss: 0.001192\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 8 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 29.49, NNZs: 1, Bias: -0.165338, T: 56892, Avg. loss: 0.033984\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 29.51, NNZs: 1, Bias: 0.003371, T: 113784, Avg. loss: 0.005249\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 29.52, NNZs: 1, Bias: 0.051935, T: 170676, Avg. loss: 0.002490\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 29.53, NNZs: 1, Bias: 0.028253, T: 227568, Avg. loss: 0.001810\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 29.54, NNZs: 1, Bias: -0.034233, T: 284460, Avg. loss: 0.001544\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 29.55, NNZs: 1, Bias: -0.017358, T: 341352, Avg. loss: 0.001398\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 29.55, NNZs: 1, Bias: -0.017044, T: 398244, Avg. loss: 0.001321\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 29.56, NNZs: 1, Bias: -0.005725, T: 455136, Avg. loss: 0.001263\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 8 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 29.74, NNZs: 1, Bias: -0.031059, T: 56892, Avg. loss: 0.033961\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 29.77, NNZs: 1, Bias: 0.026792, T: 113784, Avg. loss: 0.005277\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 29.78, NNZs: 1, Bias: 0.037042, T: 170676, Avg. loss: 0.002529\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 29.79, NNZs: 1, Bias: -0.013938, T: 227568, Avg. loss: 0.001842\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 29.80, NNZs: 1, Bias: -0.001442, T: 284460, Avg. loss: 0.001576\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 29.80, NNZs: 1, Bias: -0.027594, T: 341352, Avg. loss: 0.001438\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 29.81, NNZs: 1, Bias: 0.006609, T: 398244, Avg. loss: 0.001357\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 29.81, NNZs: 1, Bias: -0.035988, T: 455136, Avg. loss: 0.001303\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 8 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 29.04, NNZs: 1, Bias: -0.033558, T: 56892, Avg. loss: 0.033900\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 29.06, NNZs: 1, Bias: 0.127946, T: 113784, Avg. loss: 0.005255\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 29.07, NNZs: 1, Bias: -0.022889, T: 170676, Avg. loss: 0.002519\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 29.08, NNZs: 1, Bias: -0.053710, T: 227568, Avg. loss: 0.001810\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 29.09, NNZs: 1, Bias: -0.005400, T: 284460, Avg. loss: 0.001539\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 29.09, NNZs: 1, Bias: 0.010319, T: 341352, Avg. loss: 0.001416\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 29.10, NNZs: 1, Bias: 0.000794, T: 398244, Avg. loss: 0.001332\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 29.10, NNZs: 1, Bias: -0.007612, T: 455136, Avg. loss: 0.001273\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 8 epochs took 0.04 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 28.08, NNZs: 1, Bias: -0.010880, T: 56892, Avg. loss: 0.033880\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 28.10, NNZs: 1, Bias: 0.080518, T: 113784, Avg. loss: 0.005292\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 28.11, NNZs: 1, Bias: -0.048544, T: 170676, Avg. loss: 0.002555\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 28.13, NNZs: 1, Bias: -0.006784, T: 227568, Avg. loss: 0.001833\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 28.13, NNZs: 1, Bias: 0.011028, T: 284460, Avg. loss: 0.001564\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 28.14, NNZs: 1, Bias: -0.020271, T: 341352, Avg. loss: 0.001432\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 28.15, NNZs: 1, Bias: -0.027868, T: 398244, Avg. loss: 0.001355\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 28.15, NNZs: 1, Bias: -0.001230, T: 455136, Avg. loss: 0.001303\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 8 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 28.99, NNZs: 1, Bias: 0.128763, T: 56892, Avg. loss: 0.033896\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 29.01, NNZs: 1, Bias: -0.071758, T: 113784, Avg. loss: 0.005131\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 29.02, NNZs: 1, Bias: -0.013226, T: 170676, Avg. loss: 0.002404\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 29.03, NNZs: 1, Bias: -0.003486, T: 227568, Avg. loss: 0.001714\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 29.04, NNZs: 1, Bias: 0.012014, T: 284460, Avg. loss: 0.001453\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 29.05, NNZs: 1, Bias: 0.007129, T: 341352, Avg. loss: 0.001322\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 29.05, NNZs: 1, Bias: -0.024360, T: 398244, Avg. loss: 0.001249\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 29.06, NNZs: 1, Bias: -0.001117, T: 455136, Avg. loss: 0.001197\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 8 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.62, NNZs: 1, Bias: 0.132370, T: 56892, Avg. loss: 0.034317\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 2.30, NNZs: 1, Bias: 0.038403, T: 113784, Avg. loss: 0.005252\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.80, NNZs: 1, Bias: -0.027940, T: 170676, Avg. loss: 0.002483\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.57, NNZs: 1, Bias: -0.002476, T: 227568, Avg. loss: 0.001801\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.43, NNZs: 1, Bias: -0.006481, T: 284460, Avg. loss: 0.001531\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.38, NNZs: 1, Bias: 0.005179, T: 341352, Avg. loss: 0.001402\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.30, NNZs: 1, Bias: 0.022996, T: 398244, Avg. loss: 0.001312\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.26, NNZs: 1, Bias: -0.004363, T: 455136, Avg. loss: 0.001261\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 8 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.48, NNZs: 1, Bias: 0.169946, T: 56892, Avg. loss: 0.034413\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 2.21, NNZs: 1, Bias: -0.030886, T: 113784, Avg. loss: 0.005309\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.76, NNZs: 1, Bias: -0.027601, T: 170676, Avg. loss: 0.002528\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.52, NNZs: 1, Bias: -0.020701, T: 227568, Avg. loss: 0.001835\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.41, NNZs: 1, Bias: -0.028365, T: 284460, Avg. loss: 0.001571\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.33, NNZs: 1, Bias: 0.002191, T: 341352, Avg. loss: 0.001439\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.28, NNZs: 1, Bias: -0.010005, T: 398244, Avg. loss: 0.001366\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.24, NNZs: 1, Bias: 0.004086, T: 455136, Avg. loss: 0.001308\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 8 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.57, NNZs: 1, Bias: 0.200072, T: 56892, Avg. loss: 0.034383\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 2.26, NNZs: 1, Bias: -0.028210, T: 113784, Avg. loss: 0.005269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.78, NNZs: 1, Bias: -0.044415, T: 170676, Avg. loss: 0.002491\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.53, NNZs: 1, Bias: 0.013219, T: 227568, Avg. loss: 0.001819\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.42, NNZs: 1, Bias: -0.013546, T: 284460, Avg. loss: 0.001531\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.32, NNZs: 1, Bias: -0.010826, T: 341352, Avg. loss: 0.001403\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.31, NNZs: 1, Bias: 0.026943, T: 398244, Avg. loss: 0.001331\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.24, NNZs: 1, Bias: 0.006356, T: 455136, Avg. loss: 0.001279\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 8 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.60, NNZs: 1, Bias: 0.025115, T: 56892, Avg. loss: 0.034204\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 2.21, NNZs: 1, Bias: -0.015725, T: 113784, Avg. loss: 0.005271\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.79, NNZs: 1, Bias: 0.060347, T: 170676, Avg. loss: 0.002525\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.54, NNZs: 1, Bias: -0.021295, T: 227568, Avg. loss: 0.001832\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.43, NNZs: 1, Bias: -0.001827, T: 284460, Avg. loss: 0.001569\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.32, NNZs: 1, Bias: 0.002618, T: 341352, Avg. loss: 0.001432\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.26, NNZs: 1, Bias: -0.029737, T: 398244, Avg. loss: 0.001353\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.27, NNZs: 1, Bias: 0.025660, T: 455136, Avg. loss: 0.001306\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 8 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 3.53, NNZs: 1, Bias: 0.006896, T: 56892, Avg. loss: 0.034292\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 2.21, NNZs: 1, Bias: 0.025753, T: 113784, Avg. loss: 0.005134\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.79, NNZs: 1, Bias: -0.026591, T: 170676, Avg. loss: 0.002401\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.56, NNZs: 1, Bias: 0.016055, T: 227568, Avg. loss: 0.001714\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.42, NNZs: 1, Bias: 0.003951, T: 284460, Avg. loss: 0.001461\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.35, NNZs: 1, Bias: 0.030819, T: 341352, Avg. loss: 0.001326\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.28, NNZs: 1, Bias: -0.007753, T: 398244, Avg. loss: 0.001243\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.24, NNZs: 1, Bias: 0.012932, T: 455136, Avg. loss: 0.001194\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 8 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009537, T: 56892, Avg. loss: 3.832427\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.22, NNZs: 1, Bias: 0.007773, T: 113784, Avg. loss: 0.794852\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.37, NNZs: 1, Bias: -0.558381, T: 170676, Avg. loss: 0.373313\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.31, NNZs: 1, Bias: 0.009192, T: 227568, Avg. loss: 0.226132\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.009164, T: 284460, Avg. loss: 0.145767\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.24, NNZs: 1, Bias: 0.009279, T: 341352, Avg. loss: 0.102067\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009409, T: 398244, Avg. loss: 0.075549\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.009533, T: 455136, Avg. loss: 0.056227\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 0.81, NNZs: 1, Bias: 0.202800, T: 512028, Avg. loss: 0.040855\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.009707, T: 568920, Avg. loss: 0.034022\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.16, NNZs: 1, Bias: 0.168104, T: 625812, Avg. loss: 0.027065\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.009772, T: 682704, Avg. loss: 0.021949\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009823, T: 739596, Avg. loss: 0.018951\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.009806, T: 796488, Avg. loss: 0.016532\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009784, T: 853380, Avg. loss: 0.014273\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009710, T: 910272, Avg. loss: 0.012422\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 0.96, NNZs: 1, Bias: -0.093173, T: 967164, Avg. loss: 0.010893\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009525, T: 1024056, Avg. loss: 0.009919\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.009438, T: 1080948, Avg. loss: 0.009137\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.009354, T: 1137840, Avg. loss: 0.008080\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.009247, T: 1194732, Avg. loss: 0.007732\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009125, T: 1251624, Avg. loss: 0.006858\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 0.92, NNZs: 1, Bias: 0.009032, T: 1308516, Avg. loss: 0.006482\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008923, T: 1365408, Avg. loss: 0.005985\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008818, T: 1422300, Avg. loss: 0.005625\n",
            "Total training time: 0.10 seconds.\n",
            "Convergence after 25 epochs took 0.10 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.69, NNZs: 1, Bias: -1.598520, T: 56892, Avg. loss: 3.875165\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.34, NNZs: 1, Bias: 0.004851, T: 113784, Avg. loss: 0.791978\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.22, NNZs: 1, Bias: 0.006334, T: 170676, Avg. loss: 0.385657\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.38, NNZs: 1, Bias: 0.006526, T: 227568, Avg. loss: 0.232306\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.33, NNZs: 1, Bias: -0.337758, T: 284460, Avg. loss: 0.153334\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007330, T: 341352, Avg. loss: 0.107381\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.78, NNZs: 1, Bias: 0.255128, T: 398244, Avg. loss: 0.078230\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.17, NNZs: 1, Bias: 0.007899, T: 455136, Avg. loss: 0.057726\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008052, T: 512028, Avg. loss: 0.044717\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.008300, T: 568920, Avg. loss: 0.034797\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008353, T: 625812, Avg. loss: 0.028438\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008412, T: 682704, Avg. loss: 0.023932\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008442, T: 739596, Avg. loss: 0.019877\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008412, T: 796488, Avg. loss: 0.017266\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 0.90, NNZs: 1, Bias: 0.124768, T: 853380, Avg. loss: 0.015157\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008300, T: 910272, Avg. loss: 0.012986\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 0.84, NNZs: 1, Bias: -0.094579, T: 967164, Avg. loss: 0.011324\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008122, T: 1024056, Avg. loss: 0.010436\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.100054, T: 1080948, Avg. loss: 0.009657\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.007898, T: 1137840, Avg. loss: 0.008666\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 0.93, NNZs: 1, Bias: 0.007789, T: 1194732, Avg. loss: 0.007892\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.007698, T: 1251624, Avg. loss: 0.007419\n",
            "Total training time: 0.12 seconds.\n",
            "Convergence after 22 epochs took 0.12 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.000427, T: 56892, Avg. loss: 3.854740\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.62, NNZs: 1, Bias: -0.829305, T: 113784, Avg. loss: 0.788278\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.05, NNZs: 1, Bias: 0.576672, T: 170676, Avg. loss: 0.379555\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.419221, T: 227568, Avg. loss: 0.222652\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.56, NNZs: 1, Bias: 0.009689, T: 284460, Avg. loss: 0.145965\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.009914, T: 341352, Avg. loss: 0.098676\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.010194, T: 398244, Avg. loss: 0.074641\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.010556, T: 455136, Avg. loss: 0.055357\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 0.92, NNZs: 1, Bias: 0.010672, T: 512028, Avg. loss: 0.042734\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.184798, T: 568920, Avg. loss: 0.033655\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 0.93, NNZs: 1, Bias: 0.010772, T: 625812, Avg. loss: 0.026504\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.010773, T: 682704, Avg. loss: 0.022305\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.144952, T: 739596, Avg. loss: 0.018564\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010738, T: 796488, Avg. loss: 0.016317\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.010710, T: 853380, Avg. loss: 0.014087\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.010653, T: 910272, Avg. loss: 0.012383\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010564, T: 967164, Avg. loss: 0.010998\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010490, T: 1024056, Avg. loss: 0.009980\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.010375, T: 1080948, Avg. loss: 0.009136\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 1.13, NNZs: 1, Bias: 0.097723, T: 1137840, Avg. loss: 0.007849\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.010131, T: 1194732, Avg. loss: 0.007583\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010019, T: 1251624, Avg. loss: 0.006838\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.009925, T: 1308516, Avg. loss: 0.006406\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.082753, T: 1365408, Avg. loss: 0.005995\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.060308, T: 1422300, Avg. loss: 0.005718\n",
            "Total training time: 0.11 seconds.\n",
            "Convergence after 25 epochs took 0.11 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.24, NNZs: 1, Bias: -1.597910, T: 56892, Avg. loss: 3.922217\n",
            "Total training time: 0.00 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 2\n",
            "Norm: 0.55, NNZs: 1, Bias: 0.005447, T: 113784, Avg. loss: 0.775440\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.64, NNZs: 1, Bias: 0.573707, T: 170676, Avg. loss: 0.401171\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.53, NNZs: 1, Bias: 0.436399, T: 227568, Avg. loss: 0.230758\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.68, NNZs: 1, Bias: 0.007675, T: 284460, Avg. loss: 0.146858\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.36, NNZs: 1, Bias: 0.008013, T: 341352, Avg. loss: 0.106027\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008202, T: 398244, Avg. loss: 0.076822\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.18, NNZs: 1, Bias: 0.225386, T: 455136, Avg. loss: 0.057694\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008437, T: 512028, Avg. loss: 0.045837\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 0.90, NNZs: 1, Bias: 0.008529, T: 568920, Avg. loss: 0.035687\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008570, T: 625812, Avg. loss: 0.028606\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008618, T: 682704, Avg. loss: 0.023813\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.008616, T: 739596, Avg. loss: 0.019827\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008576, T: 796488, Avg. loss: 0.016853\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.008518, T: 853380, Avg. loss: 0.014687\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008434, T: 910272, Avg. loss: 0.013008\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.008371, T: 967164, Avg. loss: 0.011875\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008294, T: 1024056, Avg. loss: 0.010368\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.008216, T: 1080948, Avg. loss: 0.009581\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008119, T: 1137840, Avg. loss: 0.008556\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 0.92, NNZs: 1, Bias: 0.008025, T: 1194732, Avg. loss: 0.007880\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.007895, T: 1251624, Avg. loss: 0.007319\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.007810, T: 1308516, Avg. loss: 0.006726\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 0.93, NNZs: 1, Bias: 0.007699, T: 1365408, Avg. loss: 0.006207\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007602, T: 1422300, Avg. loss: 0.005921\n",
            "Total training time: 0.12 seconds.\n",
            "Convergence after 25 epochs took 0.12 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.08, NNZs: 1, Bias: 1.602754, T: 56892, Avg. loss: 3.921153\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.52, NNZs: 1, Bias: 0.845309, T: 113784, Avg. loss: 0.781891\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007211, T: 170676, Avg. loss: 0.362986\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.32, NNZs: 1, Bias: 0.436602, T: 227568, Avg. loss: 0.219188\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008130, T: 284460, Avg. loss: 0.145250\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008826, T: 341352, Avg. loss: 0.096653\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.256544, T: 398244, Avg. loss: 0.072668\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009179, T: 455136, Avg. loss: 0.053589\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 0.94, NNZs: 1, Bias: -0.183833, T: 512028, Avg. loss: 0.041157\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.18, NNZs: 1, Bias: 0.009441, T: 568920, Avg. loss: 0.032720\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.009505, T: 625812, Avg. loss: 0.026118\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.009518, T: 682704, Avg. loss: 0.020997\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009575, T: 739596, Avg. loss: 0.018447\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.134252, T: 796488, Avg. loss: 0.015447\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 0.88, NNZs: 1, Bias: 0.009536, T: 853380, Avg. loss: 0.012910\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.099661, T: 910272, Avg. loss: 0.011288\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009451, T: 967164, Avg. loss: 0.010252\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.009376, T: 1024056, Avg. loss: 0.009082\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.009300, T: 1080948, Avg. loss: 0.008406\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.009201, T: 1137840, Avg. loss: 0.007511\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.07, NNZs: 1, Bias: 0.009108, T: 1194732, Avg. loss: 0.006705\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.009024, T: 1251624, Avg. loss: 0.006304\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008923, T: 1308516, Avg. loss: 0.005686\n",
            "Total training time: 0.10 seconds.\n",
            "Convergence after 23 epochs took 0.10 seconds\n",
            "-- Epoch 1\n",
            "Norm: 387.85, NNZs: 1, Bias: 0.005074, T: 56892, Avg. loss: 3.478567\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 400.18, NNZs: 1, Bias: 0.007657, T: 113784, Avg. loss: 0.706289\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 400.84, NNZs: 1, Bias: -0.559189, T: 170676, Avg. loss: 0.374849\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.008438, T: 227568, Avg. loss: 0.223271\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.008754, T: 284460, Avg. loss: 0.142060\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 400.86, NNZs: 1, Bias: -0.279092, T: 341352, Avg. loss: 0.101841\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009336, T: 398244, Avg. loss: 0.074177\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009496, T: 455136, Avg. loss: 0.054978\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009618, T: 512028, Avg. loss: 0.042545\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009739, T: 568920, Avg. loss: 0.032877\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009822, T: 625812, Avg. loss: 0.026590\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009877, T: 682704, Avg. loss: 0.022181\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009916, T: 739596, Avg. loss: 0.019678\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009920, T: 796488, Avg. loss: 0.015870\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009887, T: 853380, Avg. loss: 0.013740\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009807, T: 910272, Avg. loss: 0.012097\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009720, T: 967164, Avg. loss: 0.011081\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009620, T: 1024056, Avg. loss: 0.009689\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 400.86, NNZs: 1, Bias: -0.082486, T: 1080948, Avg. loss: 0.008912\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009441, T: 1137840, Avg. loss: 0.008127\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009319, T: 1194732, Avg. loss: 0.007421\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009213, T: 1251624, Avg. loss: 0.006725\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 400.86, NNZs: 1, Bias: 0.009089, T: 1308516, Avg. loss: 0.006519\n",
            "Total training time: 0.09 seconds.\n",
            "Convergence after 23 epochs took 0.09 seconds\n",
            "-- Epoch 1\n",
            "Norm: 393.38, NNZs: 1, Bias: 0.005715, T: 56892, Avg. loss: 3.501288\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 405.87, NNZs: 1, Bias: 0.005823, T: 113784, Avg. loss: 0.719060\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 406.52, NNZs: 1, Bias: -0.559780, T: 170676, Avg. loss: 0.384448\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 406.53, NNZs: 1, Bias: 0.007566, T: 227568, Avg. loss: 0.228763\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 406.53, NNZs: 1, Bias: 0.007876, T: 284460, Avg. loss: 0.148766\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 406.53, NNZs: 1, Bias: 0.007848, T: 341352, Avg. loss: 0.103058\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 406.53, NNZs: 1, Bias: 0.008012, T: 398244, Avg. loss: 0.080468\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 406.53, NNZs: 1, Bias: -0.208732, T: 455136, Avg. loss: 0.057731\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 406.53, NNZs: 1, Bias: 0.201624, T: 512028, Avg. loss: 0.046017\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 406.53, NNZs: 1, Bias: -0.165510, T: 568920, Avg. loss: 0.036261\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 406.53, NNZs: 1, Bias: 0.166979, T: 625812, Avg. loss: 0.028454\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 406.54, NNZs: 1, Bias: 0.008614, T: 682704, Avg. loss: 0.023385\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 406.54, NNZs: 1, Bias: 0.008630, T: 739596, Avg. loss: 0.020271\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 406.54, NNZs: 1, Bias: 0.008601, T: 796488, Avg. loss: 0.017450\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 406.54, NNZs: 1, Bias: -0.107816, T: 853380, Avg. loss: 0.014858\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 406.54, NNZs: 1, Bias: 0.008498, T: 910272, Avg. loss: 0.013096\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 406.54, NNZs: 1, Bias: 0.008431, T: 967164, Avg. loss: 0.011491\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 406.54, NNZs: 1, Bias: 0.008348, T: 1024056, Avg. loss: 0.010468\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 406.54, NNZs: 1, Bias: 0.008244, T: 1080948, Avg. loss: 0.009621\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 406.54, NNZs: 1, Bias: 0.008145, T: 1137840, Avg. loss: 0.008592\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 406.54, NNZs: 1, Bias: 0.008032, T: 1194732, Avg. loss: 0.007992\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 406.54, NNZs: 1, Bias: 0.007929, T: 1251624, Avg. loss: 0.007344\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 406.54, NNZs: 1, Bias: 0.083937, T: 1308516, Avg. loss: 0.006866\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 406.54, NNZs: 1, Bias: 0.007723, T: 1365408, Avg. loss: 0.006374\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 406.54, NNZs: 1, Bias: -0.062427, T: 1422300, Avg. loss: 0.005924\n",
            "Total training time: 0.12 seconds.\n",
            "Convergence after 25 epochs took 0.12 seconds\n",
            "-- Epoch 1\n",
            "Norm: 389.85, NNZs: 0, Bias: 0.012427, T: 56892, Avg. loss: 3.420662\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 402.18, NNZs: 1, Bias: -0.827835, T: 113784, Avg. loss: 0.708034\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 402.86, NNZs: 1, Bias: 0.009125, T: 170676, Avg. loss: 0.381352\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 402.87, NNZs: 1, Bias: 0.009580, T: 227568, Avg. loss: 0.227075\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.354660, T: 284460, Avg. loss: 0.149549\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 402.87, NNZs: 1, Bias: 0.010112, T: 341352, Avg. loss: 0.102401\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 402.87, NNZs: 1, Bias: 0.010292, T: 398244, Avg. loss: 0.073145\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 402.87, NNZs: 1, Bias: 0.010465, T: 455136, Avg. loss: 0.054813\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 402.87, NNZs: 1, Bias: -0.182600, T: 512028, Avg. loss: 0.043874\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.010683, T: 568920, Avg. loss: 0.033944\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.010734, T: 625812, Avg. loss: 0.027359\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.010724, T: 682704, Avg. loss: 0.022278\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.010705, T: 739596, Avg. loss: 0.018632\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.010674, T: 796488, Avg. loss: 0.016067\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.127028, T: 853380, Avg. loss: 0.014181\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.010538, T: 910272, Avg. loss: 0.012312\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.010455, T: 967164, Avg. loss: 0.011028\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.010359, T: 1024056, Avg. loss: 0.010072\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.010255, T: 1080948, Avg. loss: 0.009003\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.010166, T: 1137840, Avg. loss: 0.008189\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.010076, T: 1194732, Avg. loss: 0.007353\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.009942, T: 1251624, Avg. loss: 0.007001\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 402.88, NNZs: 1, Bias: -0.066256, T: 1308516, Avg. loss: 0.006397\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 402.88, NNZs: 1, Bias: 0.082670, T: 1365408, Avg. loss: 0.006145\n",
            "Total training time: 0.12 seconds.\n",
            "Convergence after 24 epochs took 0.12 seconds\n",
            "-- Epoch 1\n",
            "Norm: 392.85, NNZs: 1, Bias: -1.599428, T: 56892, Avg. loss: 3.497082\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 405.52, NNZs: 0, Bias: 0.003736, T: 113784, Avg. loss: 0.724687\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 406.19, NNZs: 0, Bias: 0.006567, T: 170676, Avg. loss: 0.379363\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 406.20, NNZs: 1, Bias: 0.006964, T: 227568, Avg. loss: 0.228086\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.007513, T: 284460, Avg. loss: 0.153359\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008100, T: 341352, Avg. loss: 0.105656\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008226, T: 398244, Avg. loss: 0.077212\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008353, T: 455136, Avg. loss: 0.058369\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008568, T: 512028, Avg. loss: 0.043793\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 406.21, NNZs: 1, Bias: -0.165372, T: 568920, Avg. loss: 0.034913\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008818, T: 625812, Avg. loss: 0.029048\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008859, T: 682704, Avg. loss: 0.023706\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008833, T: 739596, Avg. loss: 0.020177\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 406.21, NNZs: 1, Bias: 0.008847, T: 796488, Avg. loss: 0.016522\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008789, T: 853380, Avg. loss: 0.014837\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008737, T: 910272, Avg. loss: 0.012892\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008600, T: 967164, Avg. loss: 0.011657\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 406.21, NNZs: 1, Bias: -0.088620, T: 1024056, Avg. loss: 0.010553\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008387, T: 1080948, Avg. loss: 0.009377\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 406.21, NNZs: 1, Bias: -0.079148, T: 1137840, Avg. loss: 0.008732\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008209, T: 1194732, Avg. loss: 0.007898\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.008095, T: 1251624, Avg. loss: 0.007378\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 406.21, NNZs: 1, Bias: 0.084072, T: 1308516, Avg. loss: 0.006854\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 406.21, NNZs: 1, Bias: -0.065056, T: 1365408, Avg. loss: 0.006301\n",
            "Total training time: 0.11 seconds.\n",
            "Convergence after 24 epochs took 0.11 seconds\n",
            "-- Epoch 1\n",
            "Norm: 391.33, NNZs: 0, Bias: -0.010586, T: 56892, Avg. loss: 3.479332\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 404.03, NNZs: 1, Bias: 0.003104, T: 113784, Avg. loss: 0.706254\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 404.70, NNZs: 1, Bias: 0.005885, T: 170676, Avg. loss: 0.361500\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.006397, T: 227568, Avg. loss: 0.225158\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.007008, T: 284460, Avg. loss: 0.148612\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.007455, T: 341352, Avg. loss: 0.100431\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 404.71, NNZs: 1, Bias: -0.239672, T: 398244, Avg. loss: 0.073311\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008280, T: 455136, Avg. loss: 0.055151\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008422, T: 512028, Avg. loss: 0.040475\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008567, T: 568920, Avg. loss: 0.031977\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008694, T: 625812, Avg. loss: 0.026242\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008801, T: 682704, Avg. loss: 0.020862\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008845, T: 739596, Avg. loss: 0.018279\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008861, T: 796488, Avg. loss: 0.015479\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008861, T: 853380, Avg. loss: 0.013314\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008848, T: 910272, Avg. loss: 0.011350\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008805, T: 967164, Avg. loss: 0.010212\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008752, T: 1024056, Avg. loss: 0.009102\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008676, T: 1080948, Avg. loss: 0.008248\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.096053, T: 1137840, Avg. loss: 0.007253\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008506, T: 1194732, Avg. loss: 0.006888\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.008409, T: 1251624, Avg. loss: 0.006161\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 404.71, NNZs: 1, Bias: 0.084414, T: 1308516, Avg. loss: 0.005786\n",
            "Total training time: 0.10 seconds.\n",
            "Convergence after 23 epochs took 0.10 seconds\n",
            "-- Epoch 1\n",
            "Norm: 101.68, NNZs: 1, Bias: -1.588863, T: 56892, Avg. loss: 3.771757\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 84.49, NNZs: 1, Bias: 0.009710, T: 113784, Avg. loss: 0.725038\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 63.34, NNZs: 1, Bias: 0.007152, T: 170676, Avg. loss: 0.373671\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 50.00, NNZs: 1, Bias: 0.007862, T: 227568, Avg. loss: 0.222753\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 41.53, NNZs: 1, Bias: 0.008339, T: 284460, Avg. loss: 0.145070\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 35.67, NNZs: 1, Bias: 0.008869, T: 341352, Avg. loss: 0.100385\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 31.35, NNZs: 1, Bias: -0.238625, T: 398244, Avg. loss: 0.074880\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 28.04, NNZs: 1, Bias: 0.226243, T: 455136, Avg. loss: 0.054126\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 25.40, NNZs: 1, Bias: 0.009357, T: 512028, Avg. loss: 0.042927\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 23.26, NNZs: 1, Bias: 0.009543, T: 568920, Avg. loss: 0.033922\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 21.46, NNZs: 1, Bias: 0.009566, T: 625812, Avg. loss: 0.026893\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 19.95, NNZs: 1, Bias: 0.154852, T: 682704, Avg. loss: 0.022234\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 18.65, NNZs: 1, Bias: 0.009621, T: 739596, Avg. loss: 0.018878\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 17.52, NNZs: 1, Bias: 0.134267, T: 796488, Avg. loss: 0.015677\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 16.54, NNZs: 1, Bias: 0.009612, T: 853380, Avg. loss: 0.014119\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 15.65, NNZs: 1, Bias: 0.009567, T: 910272, Avg. loss: 0.012343\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 14.89, NNZs: 1, Bias: 0.009478, T: 967164, Avg. loss: 0.010897\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 14.19, NNZs: 1, Bias: 0.009387, T: 1024056, Avg. loss: 0.009955\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 13.56, NNZs: 1, Bias: 0.009282, T: 1080948, Avg. loss: 0.009014\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 12.99, NNZs: 1, Bias: 0.009183, T: 1137840, Avg. loss: 0.008097\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 12.46, NNZs: 1, Bias: 0.009087, T: 1194732, Avg. loss: 0.007580\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 11.99, NNZs: 1, Bias: 0.009003, T: 1251624, Avg. loss: 0.006896\n",
            "Total training time: 0.11 seconds.\n",
            "Convergence after 22 epochs took 0.11 seconds\n",
            "-- Epoch 1\n",
            "Norm: 102.79, NNZs: 1, Bias: 1.612614, T: 56892, Avg. loss: 3.778024\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 85.66, NNZs: 1, Bias: 0.005378, T: 113784, Avg. loss: 0.747030\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 64.16, NNZs: 1, Bias: -0.561219, T: 170676, Avg. loss: 0.382125\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 50.65, NNZs: 1, Bias: 0.006589, T: 227568, Avg. loss: 0.236051\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 42.09, NNZs: 1, Bias: 0.007197, T: 284460, Avg. loss: 0.151368\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 36.14, NNZs: 1, Bias: 0.007306, T: 341352, Avg. loss: 0.105506\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 31.77, NNZs: 1, Bias: 0.007642, T: 398244, Avg. loss: 0.077902\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 28.41, NNZs: 1, Bias: 0.007840, T: 455136, Avg. loss: 0.058736\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 25.74, NNZs: 1, Bias: 0.007965, T: 512028, Avg. loss: 0.045546\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 23.55, NNZs: 1, Bias: 0.008108, T: 568920, Avg. loss: 0.035787\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 21.74, NNZs: 1, Bias: 0.008236, T: 625812, Avg. loss: 0.028860\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 20.21, NNZs: 1, Bias: 0.008257, T: 682704, Avg. loss: 0.024207\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 18.90, NNZs: 1, Bias: 0.008294, T: 739596, Avg. loss: 0.020004\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 17.76, NNZs: 1, Bias: 0.008286, T: 796488, Avg. loss: 0.016898\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 16.75, NNZs: 1, Bias: 0.008240, T: 853380, Avg. loss: 0.015210\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 15.87, NNZs: 1, Bias: 0.008149, T: 910272, Avg. loss: 0.013035\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 15.08, NNZs: 1, Bias: 0.008088, T: 967164, Avg. loss: 0.011292\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 14.37, NNZs: 1, Bias: 0.008010, T: 1024056, Avg. loss: 0.010457\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 13.73, NNZs: 1, Bias: 0.007914, T: 1080948, Avg. loss: 0.009579\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 13.16, NNZs: 1, Bias: 0.007809, T: 1137840, Avg. loss: 0.008537\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 12.62, NNZs: 1, Bias: 0.007724, T: 1194732, Avg. loss: 0.007991\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 12.14, NNZs: 1, Bias: 0.007607, T: 1251624, Avg. loss: 0.007393\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 11.70, NNZs: 1, Bias: 0.007514, T: 1308516, Avg. loss: 0.006856\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 11.29, NNZs: 1, Bias: -0.065521, T: 1365408, Avg. loss: 0.006408\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 10.91, NNZs: 1, Bias: 0.007319, T: 1422300, Avg. loss: 0.006040\n",
            "Total training time: 0.13 seconds.\n",
            "Convergence after 25 epochs took 0.13 seconds\n",
            "-- Epoch 1\n",
            "Norm: 100.90, NNZs: 1, Bias: 1.606800, T: 56892, Avg. loss: 3.704842\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 84.19, NNZs: 1, Bias: 0.844152, T: 113784, Avg. loss: 0.724800\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 63.18, NNZs: 1, Bias: 0.008466, T: 170676, Avg. loss: 0.373845\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 49.88, NNZs: 1, Bias: 0.008868, T: 227568, Avg. loss: 0.229328\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 41.44, NNZs: 1, Bias: 0.009632, T: 284460, Avg. loss: 0.143053\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 35.59, NNZs: 1, Bias: 0.009648, T: 341352, Avg. loss: 0.104432\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 31.28, NNZs: 1, Bias: 0.009807, T: 398244, Avg. loss: 0.072038\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 27.98, NNZs: 1, Bias: 0.009980, T: 455136, Avg. loss: 0.055492\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 25.34, NNZs: 1, Bias: 0.010190, T: 512028, Avg. loss: 0.042643\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 23.20, NNZs: 1, Bias: 0.010286, T: 568920, Avg. loss: 0.033842\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 21.42, NNZs: 1, Bias: 0.168715, T: 625812, Avg. loss: 0.027161\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 19.90, NNZs: 1, Bias: 0.010362, T: 682704, Avg. loss: 0.022187\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 18.61, NNZs: 1, Bias: 0.010327, T: 739596, Avg. loss: 0.018759\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 17.48, NNZs: 1, Bias: 0.010330, T: 796488, Avg. loss: 0.016226\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 16.50, NNZs: 1, Bias: 0.010265, T: 853380, Avg. loss: 0.013957\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 15.63, NNZs: 1, Bias: 0.010242, T: 910272, Avg. loss: 0.012421\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 14.85, NNZs: 1, Bias: 0.112971, T: 967164, Avg. loss: 0.010882\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 14.15, NNZs: 1, Bias: 0.010052, T: 1024056, Avg. loss: 0.010137\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 13.54, NNZs: 1, Bias: 0.009938, T: 1080948, Avg. loss: 0.009045\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 12.96, NNZs: 1, Bias: 0.009843, T: 1137840, Avg. loss: 0.008203\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 12.44, NNZs: 1, Bias: 0.009723, T: 1194732, Avg. loss: 0.007533\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 11.96, NNZs: 1, Bias: 0.009609, T: 1251624, Avg. loss: 0.006954\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 11.52, NNZs: 1, Bias: 0.009512, T: 1308516, Avg. loss: 0.006354\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 11.12, NNZs: 1, Bias: 0.009379, T: 1365408, Avg. loss: 0.006070\n",
            "Total training time: 0.11 seconds.\n",
            "Convergence after 24 epochs took 0.11 seconds\n",
            "-- Epoch 1\n",
            "Norm: 104.50, NNZs: 1, Bias: 0.020678, T: 56892, Avg. loss: 3.857697\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 85.80, NNZs: 1, Bias: 0.014755, T: 113784, Avg. loss: 0.740781\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 64.34, NNZs: 1, Bias: 0.010657, T: 170676, Avg. loss: 0.382052\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 50.82, NNZs: 1, Bias: 0.010315, T: 227568, Avg. loss: 0.235027\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 42.21, NNZs: 1, Bias: 0.010265, T: 284460, Avg. loss: 0.153460\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 36.26, NNZs: 1, Bias: 0.010421, T: 341352, Avg. loss: 0.107431\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 31.87, NNZs: 1, Bias: 0.010305, T: 398244, Avg. loss: 0.075160\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 28.50, NNZs: 1, Bias: 0.010350, T: 455136, Avg. loss: 0.058246\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 25.82, NNZs: 1, Bias: 0.010383, T: 512028, Avg. loss: 0.045329\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 23.63, NNZs: 1, Bias: 0.010329, T: 568920, Avg. loss: 0.035016\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 21.81, NNZs: 1, Bias: 0.010284, T: 625812, Avg. loss: 0.028443\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 20.28, NNZs: 1, Bias: 0.155486, T: 682704, Avg. loss: 0.023585\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 18.95, NNZs: 1, Bias: 0.010094, T: 739596, Avg. loss: 0.020303\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 17.82, NNZs: 1, Bias: 0.010016, T: 796488, Avg. loss: 0.017256\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 16.81, NNZs: 1, Bias: 0.009933, T: 853380, Avg. loss: 0.014476\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 15.92, NNZs: 1, Bias: 0.009826, T: 910272, Avg. loss: 0.013381\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 15.14, NNZs: 1, Bias: 0.112489, T: 967164, Avg. loss: 0.011663\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 14.41, NNZs: 1, Bias: 0.106696, T: 1024056, Avg. loss: 0.010430\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 13.78, NNZs: 1, Bias: 0.009429, T: 1080948, Avg. loss: 0.009394\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 13.20, NNZs: 1, Bias: 0.009288, T: 1137840, Avg. loss: 0.008741\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 12.67, NNZs: 1, Bias: 0.009167, T: 1194732, Avg. loss: 0.007886\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 12.19, NNZs: 1, Bias: 0.009008, T: 1251624, Avg. loss: 0.007310\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 11.74, NNZs: 1, Bias: 0.084962, T: 1308516, Avg. loss: 0.006754\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 11.32, NNZs: 1, Bias: 0.008753, T: 1365408, Avg. loss: 0.006284\n",
            "Total training time: 0.12 seconds.\n",
            "Convergence after 24 epochs took 0.12 seconds\n",
            "-- Epoch 1\n",
            "Norm: 101.52, NNZs: 1, Bias: 1.600408, T: 56892, Avg. loss: 3.728087\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 84.01, NNZs: 0, Bias: -0.830037, T: 113784, Avg. loss: 0.728274\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 62.95, NNZs: 1, Bias: 0.574995, T: 170676, Avg. loss: 0.361020\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 49.71, NNZs: 1, Bias: 0.007976, T: 227568, Avg. loss: 0.222733\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 41.30, NNZs: 1, Bias: 0.007877, T: 284460, Avg. loss: 0.147410\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 35.47, NNZs: 1, Bias: 0.296309, T: 341352, Avg. loss: 0.098975\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 31.18, NNZs: 1, Bias: -0.239194, T: 398244, Avg. loss: 0.072490\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 27.88, NNZs: 1, Bias: 0.008546, T: 455136, Avg. loss: 0.053907\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 25.26, NNZs: 1, Bias: 0.008742, T: 512028, Avg. loss: 0.040965\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 23.12, NNZs: 1, Bias: 0.008894, T: 568920, Avg. loss: 0.032029\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 21.34, NNZs: 1, Bias: 0.009049, T: 625812, Avg. loss: 0.025955\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 19.84, NNZs: 1, Bias: 0.009097, T: 682704, Avg. loss: 0.021832\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 18.54, NNZs: 1, Bias: 0.009153, T: 739596, Avg. loss: 0.017868\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 17.42, NNZs: 1, Bias: 0.009160, T: 796488, Avg. loss: 0.015107\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 16.45, NNZs: 1, Bias: 0.125569, T: 853380, Avg. loss: 0.013029\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 15.58, NNZs: 1, Bias: 0.118296, T: 910272, Avg. loss: 0.011570\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 14.80, NNZs: 1, Bias: 0.009055, T: 967164, Avg. loss: 0.010286\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 14.11, NNZs: 1, Bias: 0.008993, T: 1024056, Avg. loss: 0.009119\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 13.48, NNZs: 1, Bias: 0.008890, T: 1080948, Avg. loss: 0.008181\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 12.91, NNZs: 1, Bias: 0.096228, T: 1137840, Avg. loss: 0.007551\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 12.39, NNZs: 1, Bias: 0.008680, T: 1194732, Avg. loss: 0.006951\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 11.91, NNZs: 1, Bias: -0.070962, T: 1251624, Avg. loss: 0.006304\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 11.48, NNZs: 1, Bias: 0.008461, T: 1308516, Avg. loss: 0.005772\n",
            "Total training time: 0.11 seconds.\n",
            "Convergence after 23 epochs took 0.11 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000226, T: 56892, Avg. loss: 0.002547\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000023, T: 113784, Avg. loss: 0.001223\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000173, T: 170676, Avg. loss: 0.001223\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000406, T: 227568, Avg. loss: 0.001223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000692, T: 284460, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000638, T: 341352, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000590, T: 398244, Avg. loss: 0.001223\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000743, T: 56892, Avg. loss: 0.002641\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000573, T: 113784, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000713, T: 170676, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000718, T: 227568, Avg. loss: 0.001252\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000447, T: 284460, Avg. loss: 0.001252\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: 0.000032, T: 341352, Avg. loss: 0.001252\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000671, T: 398244, Avg. loss: 0.001252\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000489, T: 56892, Avg. loss: 0.002605\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001184, T: 113784, Avg. loss: 0.001247\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001099, T: 170676, Avg. loss: 0.001247\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001416, T: 227568, Avg. loss: 0.001247\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000745, T: 284460, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000077, T: 341352, Avg. loss: 0.001247\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000281, T: 398244, Avg. loss: 0.001247\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000488, T: 56892, Avg. loss: 0.002525\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001089, T: 113784, Avg. loss: 0.001255\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001017, T: 170676, Avg. loss: 0.001255\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000338, T: 227568, Avg. loss: 0.001255\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000670, T: 284460, Avg. loss: 0.001255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000761, T: 341352, Avg. loss: 0.001255\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000452, T: 398244, Avg. loss: 0.001255\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001082, T: 56892, Avg. loss: 0.002325\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001056, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000545, T: 170676, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000144, T: 227568, Avg. loss: 0.001045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000503, T: 284460, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000433, T: 341352, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.001310, T: 398244, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000718, T: 56892, Avg. loss: 0.002476\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000314, T: 113784, Avg. loss: 0.001223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000310, T: 170676, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001059, T: 227568, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000304, T: 284460, Avg. loss: 0.001223\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000438, T: 341352, Avg. loss: 0.001223\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000184, T: 398244, Avg. loss: 0.001223\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000543, T: 56892, Avg. loss: 0.002573\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000187, T: 113784, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000817, T: 170676, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001021, T: 227568, Avg. loss: 0.001252\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000485, T: 284460, Avg. loss: 0.001252\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000557, T: 341352, Avg. loss: 0.001252\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000376, T: 398244, Avg. loss: 0.001252\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000288, T: 56892, Avg. loss: 0.002557\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001284, T: 113784, Avg. loss: 0.001247\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000063, T: 170676, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000497, T: 227568, Avg. loss: 0.001247\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000673, T: 284460, Avg. loss: 0.001247\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000995, T: 341352, Avg. loss: 0.001246\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001425, T: 398244, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000553, T: 56892, Avg. loss: 0.002631\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000172, T: 113784, Avg. loss: 0.001255\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000386, T: 170676, Avg. loss: 0.001255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000511, T: 227568, Avg. loss: 0.001255\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000661, T: 284460, Avg. loss: 0.001255\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000884, T: 341352, Avg. loss: 0.001255\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000249, T: 398244, Avg. loss: 0.001255\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000816, T: 56892, Avg. loss: 0.002356\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000126, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001098, T: 170676, Avg. loss: 0.001045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000680, T: 227568, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000692, T: 284460, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000992, T: 341352, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000105, T: 398244, Avg. loss: 0.001045\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001034, T: 56892, Avg. loss: 0.002514\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000341, T: 113784, Avg. loss: 0.001223\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000350, T: 170676, Avg. loss: 0.001223\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000597, T: 227568, Avg. loss: 0.001223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001091, T: 284460, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001158, T: 341352, Avg. loss: 0.001223\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001366, T: 398244, Avg. loss: 0.001223\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000691, T: 56892, Avg. loss: 0.002583\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001221, T: 113784, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001693, T: 170676, Avg. loss: 0.001252\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002079, T: 227568, Avg. loss: 0.001252\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000056, T: 284460, Avg. loss: 0.001252\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000179, T: 341352, Avg. loss: 0.001252\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000140, T: 398244, Avg. loss: 0.001252\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001354, T: 56892, Avg. loss: 0.002616\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000690, T: 113784, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000278, T: 170676, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000782, T: 227568, Avg. loss: 0.001247\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000347, T: 284460, Avg. loss: 0.001247\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000367, T: 341352, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002407, T: 398244, Avg. loss: 0.001246\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000773, T: 56892, Avg. loss: 0.002616\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000346, T: 113784, Avg. loss: 0.001255\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000709, T: 170676, Avg. loss: 0.001255\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000548, T: 227568, Avg. loss: 0.001255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000556, T: 284460, Avg. loss: 0.001255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000942, T: 341352, Avg. loss: 0.001255\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001394, T: 398244, Avg. loss: 0.001255\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.000689, T: 56892, Avg. loss: 0.002423\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000609, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000592, T: 170676, Avg. loss: 0.001045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000139, T: 227568, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000743, T: 284460, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000297, T: 341352, Avg. loss: 0.001045\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000151, T: 398244, Avg. loss: 0.001045\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001150, T: 56892, Avg. loss: 0.005687\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003211, T: 113784, Avg. loss: 0.001002\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001762, T: 170676, Avg. loss: 0.001002\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001522, T: 227568, Avg. loss: 0.001002\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001969, T: 284460, Avg. loss: 0.001002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001834, T: 341352, Avg. loss: 0.001002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001299, T: 398244, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001910, T: 56892, Avg. loss: 0.005755\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001506, T: 113784, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002515, T: 170676, Avg. loss: 0.001034\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001651, T: 227568, Avg. loss: 0.001033\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002714, T: 284460, Avg. loss: 0.001033\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002274, T: 341352, Avg. loss: 0.001033\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003207, T: 398244, Avg. loss: 0.001033\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000129, T: 56892, Avg. loss: 0.005710\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002589, T: 113784, Avg. loss: 0.001010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.001182, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001960, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001070, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002222, T: 341352, Avg. loss: 0.001010\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001851, T: 398244, Avg. loss: 0.001010\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002719, T: 56892, Avg. loss: 0.005691\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002352, T: 113784, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001781, T: 170676, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002108, T: 227568, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001550, T: 284460, Avg. loss: 0.001031\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001721, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002039, T: 398244, Avg. loss: 0.001031\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000287, T: 56892, Avg. loss: 0.005652\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001799, T: 113784, Avg. loss: 0.000932\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000489, T: 170676, Avg. loss: 0.000933\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001286, T: 227568, Avg. loss: 0.000933\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000432, T: 284460, Avg. loss: 0.000932\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001316, T: 341352, Avg. loss: 0.000932\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000803, T: 398244, Avg. loss: 0.000932\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001964, T: 56892, Avg. loss: 0.005697\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001984, T: 113784, Avg. loss: 0.001002\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001400, T: 170676, Avg. loss: 0.001002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001837, T: 227568, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002513, T: 284460, Avg. loss: 0.001002\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001015, T: 341352, Avg. loss: 0.001002\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001722, T: 398244, Avg. loss: 0.001002\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001193, T: 56892, Avg. loss: 0.005752\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001721, T: 113784, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001153, T: 170676, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002273, T: 227568, Avg. loss: 0.001033\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002736, T: 284460, Avg. loss: 0.001034\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002377, T: 341352, Avg. loss: 0.001033\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002247, T: 398244, Avg. loss: 0.001033\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000861, T: 56892, Avg. loss: 0.005713\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001104, T: 113784, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000688, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000405, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001579, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000720, T: 341352, Avg. loss: 0.001010\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000981, T: 398244, Avg. loss: 0.001010\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001772, T: 56892, Avg. loss: 0.005751\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002657, T: 113784, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002039, T: 170676, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002491, T: 227568, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001679, T: 284460, Avg. loss: 0.001031\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.002445, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002702, T: 398244, Avg. loss: 0.001031\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 7 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001651, T: 56892, Avg. loss: 0.005656\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000958, T: 113784, Avg. loss: 0.000933\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001962, T: 170676, Avg. loss: 0.000932\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002165, T: 227568, Avg. loss: 0.000933\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000820, T: 284460, Avg. loss: 0.000932\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001180, T: 341352, Avg. loss: 0.000932\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000297, T: 398244, Avg. loss: 0.000932\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002752, T: 56892, Avg. loss: 0.005701\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000454, T: 113784, Avg. loss: 0.001002\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002895, T: 170676, Avg. loss: 0.001002\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000900, T: 227568, Avg. loss: 0.001002\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001599, T: 284460, Avg. loss: 0.001002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001876, T: 341352, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001929, T: 398244, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003583, T: 56892, Avg. loss: 0.005704\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003015, T: 113784, Avg. loss: 0.001033\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002428, T: 170676, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001670, T: 227568, Avg. loss: 0.001034\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002219, T: 284460, Avg. loss: 0.001033\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001993, T: 341352, Avg. loss: 0.001033\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.002792, T: 398244, Avg. loss: 0.001033\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003388, T: 56892, Avg. loss: 0.005703\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001211, T: 113784, Avg. loss: 0.001010\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001386, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000881, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000945, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001164, T: 341352, Avg. loss: 0.001010\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000483, T: 398244, Avg. loss: 0.001010\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001356, T: 56892, Avg. loss: 0.005707\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002489, T: 113784, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001393, T: 170676, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002848, T: 227568, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000930, T: 284460, Avg. loss: 0.001031\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001747, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001444, T: 398244, Avg. loss: 0.001031\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001683, T: 56892, Avg. loss: 0.005659\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001664, T: 113784, Avg. loss: 0.000933\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000965, T: 170676, Avg. loss: 0.000933\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002326, T: 227568, Avg. loss: 0.000933\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001342, T: 284460, Avg. loss: 0.000933\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000714, T: 341352, Avg. loss: 0.000932\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001628, T: 398244, Avg. loss: 0.000933\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: 0.009363, T: 56892, Avg. loss: 0.003649\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.012161, T: 113784, Avg. loss: 0.001640\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.004256, T: 170676, Avg. loss: 0.001640\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.004430, T: 227568, Avg. loss: 0.001639\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006284, T: 284460, Avg. loss: 0.001637\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008789, T: 341352, Avg. loss: 0.001637\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007909, T: 398244, Avg. loss: 0.001634\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000591, T: 56892, Avg. loss: 0.003767\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000112, T: 113784, Avg. loss: 0.001719\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003566, T: 170676, Avg. loss: 0.001716\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003378, T: 227568, Avg. loss: 0.001717\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002385, T: 284460, Avg. loss: 0.001715\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003525, T: 341352, Avg. loss: 0.001715\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001861, T: 398244, Avg. loss: 0.001715\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.004031, T: 56892, Avg. loss: 0.003796\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008520, T: 113784, Avg. loss: 0.001698\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010967, T: 170676, Avg. loss: 0.001695\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005822, T: 227568, Avg. loss: 0.001694\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005107, T: 284460, Avg. loss: 0.001695\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006903, T: 341352, Avg. loss: 0.001694\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008152, T: 398244, Avg. loss: 0.001695\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001998, T: 56892, Avg. loss: 0.003728\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000324, T: 113784, Avg. loss: 0.001730\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: 0.004378, T: 170676, Avg. loss: 0.001725\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001026, T: 227568, Avg. loss: 0.001729\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003648, T: 284460, Avg. loss: 0.001723\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003959, T: 341352, Avg. loss: 0.001725\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002722, T: 398244, Avg. loss: 0.001725\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.003571, T: 56892, Avg. loss: 0.003146\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000114, T: 113784, Avg. loss: 0.001074\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001942, T: 170676, Avg. loss: 0.001075\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000847, T: 227568, Avg. loss: 0.001075\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000322, T: 284460, Avg. loss: 0.001072\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000146, T: 341352, Avg. loss: 0.001070\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001754, T: 398244, Avg. loss: 0.001072\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005118, T: 56892, Avg. loss: 0.003700\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006941, T: 113784, Avg. loss: 0.001639\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007876, T: 170676, Avg. loss: 0.001637\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006017, T: 227568, Avg. loss: 0.001635\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.004343, T: 284460, Avg. loss: 0.001636\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010208, T: 341352, Avg. loss: 0.001638\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007678, T: 398244, Avg. loss: 0.001636\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000640, T: 56892, Avg. loss: 0.003744\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000383, T: 113784, Avg. loss: 0.001721\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002675, T: 170676, Avg. loss: 0.001717\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.003921, T: 227568, Avg. loss: 0.001719\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.002454, T: 284460, Avg. loss: 0.001716\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000322, T: 341352, Avg. loss: 0.001714\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.003524, T: 398244, Avg. loss: 0.001716\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009109, T: 56892, Avg. loss: 0.003730\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006831, T: 113784, Avg. loss: 0.001696\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007516, T: 170676, Avg. loss: 0.001694\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008460, T: 227568, Avg. loss: 0.001695\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005894, T: 284460, Avg. loss: 0.001693\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007654, T: 341352, Avg. loss: 0.001691\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006900, T: 398244, Avg. loss: 0.001694\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001375, T: 56892, Avg. loss: 0.003702\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000277, T: 113784, Avg. loss: 0.001727\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002868, T: 170676, Avg. loss: 0.001725\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001451, T: 227568, Avg. loss: 0.001724\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002351, T: 284460, Avg. loss: 0.001725\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002338, T: 341352, Avg. loss: 0.001725\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003906, T: 398244, Avg. loss: 0.001725\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002140, T: 56892, Avg. loss: 0.003130\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000751, T: 113784, Avg. loss: 0.001076\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001860, T: 170676, Avg. loss: 0.001075\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000875, T: 227568, Avg. loss: 0.001074\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002616, T: 284460, Avg. loss: 0.001071\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002561, T: 341352, Avg. loss: 0.001073\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001712, T: 398244, Avg. loss: 0.001073\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010216, T: 56892, Avg. loss: 0.003700\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008497, T: 113784, Avg. loss: 0.001641\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007407, T: 170676, Avg. loss: 0.001638\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: 0.010080, T: 227568, Avg. loss: 0.001637\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009016, T: 284460, Avg. loss: 0.001635\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006035, T: 341352, Avg. loss: 0.001636\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006850, T: 398244, Avg. loss: 0.001637\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000746, T: 56892, Avg. loss: 0.003798\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000355, T: 113784, Avg. loss: 0.001718\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000701, T: 170676, Avg. loss: 0.001719\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003933, T: 227568, Avg. loss: 0.001715\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000376, T: 284460, Avg. loss: 0.001714\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.004150, T: 341352, Avg. loss: 0.001717\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000002, T: 398244, Avg. loss: 0.001717\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006846, T: 56892, Avg. loss: 0.003733\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010391, T: 113784, Avg. loss: 0.001698\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007759, T: 170676, Avg. loss: 0.001696\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006032, T: 227568, Avg. loss: 0.001694\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008308, T: 284460, Avg. loss: 0.001693\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009950, T: 341352, Avg. loss: 0.001693\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009130, T: 398244, Avg. loss: 0.001691\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000839, T: 56892, Avg. loss: 0.003776\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001560, T: 113784, Avg. loss: 0.001726\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005050, T: 170676, Avg. loss: 0.001728\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000745, T: 227568, Avg. loss: 0.001728\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.003836, T: 284460, Avg. loss: 0.001724\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002094, T: 341352, Avg. loss: 0.001725\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001688, T: 398244, Avg. loss: 0.001725\n",
            "Total training time: 0.09 seconds.\n",
            "Convergence after 7 epochs took 0.09 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002958, T: 56892, Avg. loss: 0.003091\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000168, T: 113784, Avg. loss: 0.001073\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000399, T: 170676, Avg. loss: 0.001073\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001330, T: 227568, Avg. loss: 0.001070\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000453, T: 284460, Avg. loss: 0.001072\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000467, T: 341352, Avg. loss: 0.001071\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000086, T: 398244, Avg. loss: 0.001073\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000782, T: 56892, Avg. loss: 0.001679\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000114, T: 113784, Avg. loss: 0.001237\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002523, T: 170676, Avg. loss: 0.001237\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000974, T: 227568, Avg. loss: 0.001237\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000037, T: 284460, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000061, T: 341352, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004005, T: 56892, Avg. loss: 0.001708\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001568, T: 113784, Avg. loss: 0.001265\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002122, T: 170676, Avg. loss: 0.001266\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001378, T: 227568, Avg. loss: 0.001267\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007398, T: 284460, Avg. loss: 0.001266\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000962, T: 341352, Avg. loss: 0.001266\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003989, T: 56892, Avg. loss: 0.001703\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005021, T: 113784, Avg. loss: 0.001261\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000524, T: 170676, Avg. loss: 0.001260\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000085, T: 227568, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002555, T: 284460, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002733, T: 341352, Avg. loss: 0.001259\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003083, T: 56892, Avg. loss: 0.001711\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001162, T: 113784, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000511, T: 170676, Avg. loss: 0.001270\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001560, T: 227568, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.000906, T: 284460, Avg. loss: 0.001268\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000980, T: 341352, Avg. loss: 0.001269\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000175, T: 56892, Avg. loss: 0.001501\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001590, T: 113784, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002036, T: 170676, Avg. loss: 0.001057\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004150, T: 227568, Avg. loss: 0.001057\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000112, T: 284460, Avg. loss: 0.001057\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003569, T: 341352, Avg. loss: 0.001057\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002841, T: 56892, Avg. loss: 0.001677\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001284, T: 113784, Avg. loss: 0.001236\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000897, T: 170676, Avg. loss: 0.001235\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001349, T: 227568, Avg. loss: 0.001236\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005019, T: 284460, Avg. loss: 0.001235\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002735, T: 341352, Avg. loss: 0.001235\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.006227, T: 56892, Avg. loss: 0.001710\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000996, T: 113784, Avg. loss: 0.001265\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003016, T: 170676, Avg. loss: 0.001266\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002863, T: 227568, Avg. loss: 0.001267\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002929, T: 284460, Avg. loss: 0.001265\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001361, T: 341352, Avg. loss: 0.001265\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000315, T: 56892, Avg. loss: 0.001704\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.006891, T: 113784, Avg. loss: 0.001261\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002471, T: 170676, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000554, T: 227568, Avg. loss: 0.001259\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000186, T: 284460, Avg. loss: 0.001259\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001820, T: 341352, Avg. loss: 0.001261\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001353, T: 56892, Avg. loss: 0.001715\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002006, T: 113784, Avg. loss: 0.001268\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002691, T: 170676, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003052, T: 227568, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.007129, T: 284460, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003426, T: 341352, Avg. loss: 0.001268\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.005433, T: 56892, Avg. loss: 0.001497\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001196, T: 113784, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000617, T: 170676, Avg. loss: 0.001056\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003315, T: 227568, Avg. loss: 0.001056\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: -0.001305, T: 284460, Avg. loss: 0.001058\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004098, T: 341352, Avg. loss: 0.001056\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.010187, T: 56892, Avg. loss: 0.001677\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000464, T: 113784, Avg. loss: 0.001235\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003048, T: 170676, Avg. loss: 0.001235\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005641, T: 227568, Avg. loss: 0.001236\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000758, T: 284460, Avg. loss: 0.001236\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001942, T: 341352, Avg. loss: 0.001236\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.007506, T: 56892, Avg. loss: 0.001711\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003137, T: 113784, Avg. loss: 0.001266\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001557, T: 170676, Avg. loss: 0.001266\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001487, T: 227568, Avg. loss: 0.001266\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.006456, T: 284460, Avg. loss: 0.001266\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003005, T: 341352, Avg. loss: 0.001266\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004725, T: 56892, Avg. loss: 0.001705\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000259, T: 113784, Avg. loss: 0.001261\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008028, T: 170676, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001362, T: 227568, Avg. loss: 0.001261\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.005348, T: 284460, Avg. loss: 0.001260\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004148, T: 341352, Avg. loss: 0.001261\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000095, T: 56892, Avg. loss: 0.001712\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001416, T: 113784, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.008116, T: 170676, Avg. loss: 0.001269\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.007123, T: 227568, Avg. loss: 0.001269\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002127, T: 284460, Avg. loss: 0.001268\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000631, T: 341352, Avg. loss: 0.001268\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000412, T: 56892, Avg. loss: 0.001497\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002978, T: 113784, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003780, T: 170676, Avg. loss: 0.001057\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000610, T: 227568, Avg. loss: 0.001057\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003229, T: 284460, Avg. loss: 0.001058\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000546, T: 341352, Avg. loss: 0.001056\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001343, T: 56892, Avg. loss: 0.001791\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002188, T: 113784, Avg. loss: 0.001010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.001310, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005867, T: 227568, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.006238, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000660, T: 341352, Avg. loss: 0.001011\n",
            "Total training time: 0.02 seconds."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000754, T: 56892, Avg. loss: 0.001820\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.007915, T: 113784, Avg. loss: 0.001043\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.006481, T: 170676, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000383, T: 227568, Avg. loss: 0.001042\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005585, T: 284460, Avg. loss: 0.001042\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003175, T: 341352, Avg. loss: 0.001042\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001360, T: 56892, Avg. loss: 0.001794\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001524, T: 113784, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.006049, T: 170676, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.002407, T: 227568, Avg. loss: 0.001018\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000327, T: 284460, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001827, T: 341352, Avg. loss: 0.001018\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003419, T: 56892, Avg. loss: 0.001825\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000070, T: 113784, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004634, T: 170676, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.002338, T: 227568, Avg. loss: 0.001039\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.005898, T: 284460, Avg. loss: 0.001040\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004825, T: 341352, Avg. loss: 0.001040\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.005433, T: 56892, Avg. loss: 0.001723\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001784, T: 113784, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.001974, T: 170676, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004631, T: 227568, Avg. loss: 0.000942\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001662, T: 284460, Avg. loss: 0.000942\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003802, T: 341352, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004061, T: 56892, Avg. loss: 0.001786\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000395, T: 113784, Avg. loss: 0.001011\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002816, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001342, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002468, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000968, T: 341352, Avg. loss: 0.001010\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003708, T: 56892, Avg. loss: 0.001821\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002655, T: 113784, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005718, T: 170676, Avg. loss: 0.001043\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000758, T: 227568, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003529, T: 284460, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001192, T: 341352, Avg. loss: 0.001041\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001311, T: 56892, Avg. loss: 0.001798\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003358, T: 113784, Avg. loss: 0.001018\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003416, T: 170676, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.006397, T: 227568, Avg. loss: 0.001020\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000863, T: 284460, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003558, T: 341352, Avg. loss: 0.001019\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000538, T: 56892, Avg. loss: 0.001824\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000816, T: 113784, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.002464, T: 170676, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000317, T: 227568, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004860, T: 284460, Avg. loss: 0.001039\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001811, T: 341352, Avg. loss: 0.001040\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.006005, T: 56892, Avg. loss: 0.001719\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000148, T: 113784, Avg. loss: 0.000942\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002974, T: 170676, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000863, T: 227568, Avg. loss: 0.000940\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.005915, T: 284460, Avg. loss: 0.000940\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004006, T: 341352, Avg. loss: 0.000941\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000497, T: 56892, Avg. loss: 0.001788\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000391, T: 113784, Avg. loss: 0.001010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000975, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.005860, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.005140, T: 284460, Avg. loss: 0.001011\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002061, T: 341352, Avg. loss: 0.001011\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003684, T: 56892, Avg. loss: 0.001820\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002205, T: 113784, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001840, T: 170676, Avg. loss: 0.001042\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004927, T: 227568, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003841, T: 284460, Avg. loss: 0.001042\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.004113, T: 341352, Avg. loss: 0.001042\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001898, T: 56892, Avg. loss: 0.001800\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003394, T: 113784, Avg. loss: 0.001019\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001509, T: 170676, Avg. loss: 0.001018\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004079, T: 227568, Avg. loss: 0.001019\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004383, T: 284460, Avg. loss: 0.001019\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002712, T: 341352, Avg. loss: 0.001019\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.003609, T: 56892, Avg. loss: 0.001814\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003705, T: 113784, Avg. loss: 0.001040\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001453, T: 170676, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: 0.000881, T: 227568, Avg. loss: 0.001040\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.008387, T: 284460, Avg. loss: 0.001040\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000285, T: 341352, Avg. loss: 0.001040\n",
            "Total training time: 0.04 seconds.\n",
            "Convergence after 6 epochs took 0.04 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.003641, T: 56892, Avg. loss: 0.001721\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.004131, T: 113784, Avg. loss: 0.000940\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001168, T: 170676, Avg. loss: 0.000941\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.004723, T: 227568, Avg. loss: 0.000940\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001843, T: 284460, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000618, T: 341352, Avg. loss: 0.000941\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.030000, T: 56892, Avg. loss: 0.002540\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001821\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001830\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.001837\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001817\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001830\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002655\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001963\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.020000, T: 170676, Avg. loss: 0.001938\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.020000, T: 227568, Avg. loss: 0.001932\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.001952\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001934\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002618\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.010000, T: 113784, Avg. loss: 0.001886\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.010000, T: 170676, Avg. loss: 0.001896\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.001900\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001902\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001896\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002681\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010000, T: 113784, Avg. loss: 0.001943\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001948\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.001944\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000000, T: 284460, Avg. loss: 0.001948\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.010000, T: 341352, Avg. loss: 0.001945\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000000, T: 56892, Avg. loss: 0.002014\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.000000, T: 113784, Avg. loss: 0.001263\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001263\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001263\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001270\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010000, T: 341352, Avg. loss: 0.001264\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.002563\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001831\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001827\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001835\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001825\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001843\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002672\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001934\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 170676, Avg. loss: 0.001946\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 227568, Avg. loss: 0.001935\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 284460, Avg. loss: 0.001936\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001950\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002649\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 113784, Avg. loss: 0.001884\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.001886\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001888\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 284460, Avg. loss: 0.001895\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001898\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000000, T: 56892, Avg. loss: 0.002673\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001948\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000000, T: 170676, Avg. loss: 0.001934\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001929\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.030000, T: 284460, Avg. loss: 0.001935\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000000, T: 341352, Avg. loss: 0.001949\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 56892, Avg. loss: 0.001991\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.020000, T: 113784, Avg. loss: 0.001276\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010000, T: 170676, Avg. loss: 0.001280\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.001258\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000000, T: 284460, Avg. loss: 0.001264\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.000000, T: 341352, Avg. loss: 0.001282\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002573\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000000, T: 113784, Avg. loss: 0.001858\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.030000, T: 170676, Avg. loss: 0.001834\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001828\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.020000, T: 284460, Avg. loss: 0.001822\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001812\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000000, T: 56892, Avg. loss: 0.002685\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000000, T: 113784, Avg. loss: 0.001940\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000000, T: 170676, Avg. loss: 0.001925\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 227568, Avg. loss: 0.001937\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010000, T: 284460, Avg. loss: 0.001944\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001954\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.010000, T: 56892, Avg. loss: 0.002647\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.030000, T: 113784, Avg. loss: 0.001895\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000000, T: 170676, Avg. loss: 0.001894\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.020000, T: 227568, Avg. loss: 0.001885\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001893\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.010000, T: 341352, Avg. loss: 0.001891\n",
            "Total training time: 0.03 seconds.\n",
            "Convergence after 6 epochs took 0.03 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000000, T: 56892, Avg. loss: 0.002704\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001953\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.010000, T: 170676, Avg. loss: 0.001945\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000000, T: 227568, Avg. loss: 0.001948\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000000, T: 284460, Avg. loss: 0.001938\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000000, T: 341352, Avg. loss: 0.001929\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.020000, T: 56892, Avg. loss: 0.002005\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.010000, T: 113784, Avg. loss: 0.001268\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.020000, T: 170676, Avg. loss: 0.001267\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000000, T: 227568, Avg. loss: 0.001274\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.010000, T: 284460, Avg. loss: 0.001276\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000000, T: 341352, Avg. loss: 0.001265\n",
            "Total training time: 0.02 seconds.\n",
            "Convergence after 6 epochs took 0.02 seconds\n",
            "-- Epoch 1\n",
            "Norm: 6011165902487.60, NNZs: 1, Bias: -15969567722141.000000, T: 56892, Avg. loss: 267533959955030613751234560.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 6084148987857.21, NNZs: 1, Bias: 3182433243405.570312, T: 113784, Avg. loss: 55405504482078835924271104.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1728167811864.79, NNZs: 1, Bias: 2629685861959.497070, T: 170676, Avg. loss: 23220299077913381267570688.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1818384611091.28, NNZs: 1, Bias: 6625902846936.144531, T: 227568, Avg. loss: 12404055789677386424909824.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4678175096990.34, NNZs: 1, Bias: 855115762684.476807, T: 284460, Avg. loss: 7583632479586611135250432.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2795475241559.02, NNZs: 1, Bias: 532165903468.222656, T: 341352, Avg. loss: 5023393350809515884281856.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 316285247123.09, NNZs: 1, Bias: -840221487468.441528, T: 398244, Avg. loss: 3506003258529431735500800.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1624162087924.48, NNZs: 1, Bias: 1967007492407.142090, T: 455136, Avg. loss: 2561421981419987894534144.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1132128857764.54, NNZs: 1, Bias: 1141888198751.832520, T: 512028, Avg. loss: 1897491379085460214120448.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 179861034796.16, NNZs: 1, Bias: -321228886757.383057, T: 568920, Avg. loss: 1441740488545551677128704.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 2055980515927.97, NNZs: 1, Bias: 232318331581.904541, T: 625812, Avg. loss: 1094014848349744945692672.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1163083790845.58, NNZs: 1, Bias: -2246666476.444336, T: 682704, Avg. loss: 828209162848585079848960.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 64275056220.55, NNZs: 1, Bias: 933825508467.829102, T: 739596, Avg. loss: 614330581349561328992256.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 389740716792.02, NNZs: 1, Bias: 371421592579.053406, T: 796488, Avg. loss: 429018245684783057207296.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 291284860152.21, NNZs: 1, Bias: 269947674920.688110, T: 853380, Avg. loss: 271706238996900636262400.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 130273128467.46, NNZs: 1, Bias: 62645738787.898476, T: 910272, Avg. loss: 105458712643490830876672.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: nan, NNZs: 1, Bias: -0.016476, T: 967164, Avg. loss: 9169400934480199286784.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: nan, NNZs: 1, Bias: -0.145570, T: 1024056, Avg. loss: 604617970.939011\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: nan, NNZs: 1, Bias: 0.223209, T: 1080948, Avg. loss: 415.515932\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: nan, NNZs: 1, Bias: -0.013401, T: 1137840, Avg. loss: 2.740923\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: nan, NNZs: 1, Bias: -0.048072, T: 1194732, Avg. loss: 2.760791\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: nan, NNZs: 1, Bias: -0.037166, T: 1251624, Avg. loss: 0.034339\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 23\n",
            "Norm: nan, NNZs: 1, Bias: -0.041807, T: 1308516, Avg. loss: 0.016539\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 24\n",
            "Norm: nan, NNZs: 1, Bias: 0.025919, T: 1365408, Avg. loss: 0.011300\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 25\n",
            "Norm: nan, NNZs: 1, Bias: -0.028361, T: 1422300, Avg. loss: 0.008646\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: nan, NNZs: 1, Bias: 0.050878, T: 1479192, Avg. loss: 0.006943\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 27\n",
            "Norm: nan, NNZs: 1, Bias: -0.019800, T: 1536084, Avg. loss: 0.005707\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: nan, NNZs: 1, Bias: -0.031922, T: 1592976, Avg. loss: 0.005059\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 29\n",
            "Norm: nan, NNZs: 1, Bias: -0.034222, T: 1649868, Avg. loss: 0.004523\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: nan, NNZs: 1, Bias: 0.036947, T: 1706760, Avg. loss: 0.004222\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 31\n",
            "Norm: nan, NNZs: 1, Bias: -0.002831, T: 1763652, Avg. loss: 0.003806\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 32\n",
            "Norm: nan, NNZs: 1, Bias: 0.051620, T: 1820544, Avg. loss: 0.003545\n",
            "Total training time: 0.17 seconds.\n",
            "Convergence after 32 epochs took 0.17 seconds\n",
            "-- Epoch 1\n",
            "Norm: 8479297744539.68, NNZs: 1, Bias: 11378306805874.769531, T: 56892, Avg. loss: 265062294255854630001967104.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 329208471604.32, NNZs: 1, Bias: -2401632341125.411133, T: 113784, Avg. loss: 55139435576743185480679424.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4456261454903.01, NNZs: 1, Bias: -2499612969019.070312, T: 170676, Avg. loss: 23105034249742358136487936.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4431108643904.10, NNZs: 1, Bias: -2181068675618.600586, T: 227568, Avg. loss: 12375373324961050064322560.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2746880954645.18, NNZs: 1, Bias: -1599931006434.201172, T: 284460, Avg. loss: 7603769285847353858719744.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1459957541464.49, NNZs: 1, Bias: -3395408786217.249512, T: 341352, Avg. loss: 5016110837111203263676416.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1177806677094.00, NNZs: 1, Bias: -1195407513134.935791, T: 398244, Avg. loss: 3500317978579973179441152.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1263247954922.84, NNZs: 1, Bias: -473959126052.541870, T: 455136, Avg. loss: 2540780783561875753271296.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1026207646383.96, NNZs: 1, Bias: -1411640486364.760254, T: 512028, Avg. loss: 1891943688732505217695744.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 513490970968.61, NNZs: 1, Bias: 40911165574.809174, T: 568920, Avg. loss: 1430976723036966857211904.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 594006378218.19, NNZs: 1, Bias: -128093350414.172302, T: 625812, Avg. loss: 1088116926331477399961600.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 2068400552563.89, NNZs: 1, Bias: -291749801688.176758, T: 682704, Avg. loss: 821572340717307819982848.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 201520118364.78, NNZs: 1, Bias: 6275431899.148682, T: 739596, Avg. loss: 611360011332819951288320.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 60721542246.15, NNZs: 1, Bias: -125456641303.542923, T: 796488, Avg. loss: 419591470038155815550976.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 574146365510.86, NNZs: 1, Bias: -1275501246873.115234, T: 853380, Avg. loss: 267709943571460598530048.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 336472.59, NNZs: 1, Bias: -3222.950453, T: 910272, Avg. loss: 104227881400918456926208.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 313924.56, NNZs: 1, Bias: 0.528047, T: 967164, Avg. loss: 4850206182904274354176.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 296962.61, NNZs: 1, Bias: -0.060233, T: 1024056, Avg. loss: 236261828131201941504.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 281777.23, NNZs: 1, Bias: -0.091044, T: 1080948, Avg. loss: 2224.790150\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 268069.33, NNZs: 1, Bias: -0.025682, T: 1137840, Avg. loss: 1.856191\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 255633.28, NNZs: 1, Bias: 0.008268, T: 1194732, Avg. loss: 0.099232\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 244299.91, NNZs: 1, Bias: -0.132173, T: 1251624, Avg. loss: 0.055390\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 233928.81, NNZs: 1, Bias: -0.062885, T: 1308516, Avg. loss: 0.016851\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 224402.40, NNZs: 1, Bias: 0.006691, T: 1365408, Avg. loss: 0.011202\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 215621.53, NNZs: 1, Bias: 0.007706, T: 1422300, Avg. loss: 0.009033\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 207501.97, NNZs: 1, Bias: 0.022886, T: 1479192, Avg. loss: 0.007124\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 199971.73, NNZs: 1, Bias: 0.017756, T: 1536084, Avg. loss: 0.005662\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 192968.89, NNZs: 1, Bias: 0.066686, T: 1592976, Avg. loss: 0.005201\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 186439.93, NNZs: 1, Bias: 0.007319, T: 1649868, Avg. loss: 0.004513\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 180338.31, NNZs: 1, Bias: -0.005067, T: 1706760, Avg. loss: 0.004169\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 174623.41, NNZs: 1, Bias: 0.002407, T: 1763652, Avg. loss: 0.003908\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 169259.60, NNZs: 1, Bias: -0.032995, T: 1820544, Avg. loss: 0.003732\n",
            "Total training time: 0.13 seconds.\n",
            "Convergence after 32 epochs took 0.13 seconds\n",
            "-- Epoch 1\n",
            "Norm: 2483132782359.42, NNZs: 1, Bias: 9922275825633.945312, T: 56892, Avg. loss: 266592126969708574266097664.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 6983918321735.29, NNZs: 1, Bias: -5949460094037.902344, T: 113784, Avg. loss: 55351849314613887955369984.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5120904011173.12, NNZs: 1, Bias: 3807349392902.660156, T: 170676, Avg. loss: 23091888428003295437520896.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1203204124708.79, NNZs: 1, Bias: 2656874972532.577637, T: 227568, Avg. loss: 12417736124152805301682176.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2237948476261.86, NNZs: 1, Bias: 3583985897503.158203, T: 284460, Avg. loss: 7561354347313668626055168.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 722656340714.59, NNZs: 1, Bias: 3141463988746.134277, T: 341352, Avg. loss: 5005385065344182272393216.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1650228619982.06, NNZs: 1, Bias: 831382625452.041504, T: 398244, Avg. loss: 3533018256210340358389760.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 369826381173.43, NNZs: 1, Bias: -784509828370.328369, T: 455136, Avg. loss: 2547773643086418476531712.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1454830598640.14, NNZs: 1, Bias: -950286383201.746094, T: 512028, Avg. loss: 1891334319918743170318336.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 491560516665.61, NNZs: 1, Bias: 7655719625.473877, T: 568920, Avg. loss: 1437402554654084181262336.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1691605095977.69, NNZs: 1, Bias: 1095017320726.310181, T: 625812, Avg. loss: 1091686997012333486669824.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 282752463132.23, NNZs: 1, Bias: 105856914917.035141, T: 682704, Avg. loss: 819320711985956548247552.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 952380710434.15, NNZs: 1, Bias: -171001045231.624084, T: 739596, Avg. loss: 613820957819538086297600.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 547492946360.31, NNZs: 1, Bias: 112163375607.865417, T: 796488, Avg. loss: 427243546846730184032256.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 373712340.01, NNZs: 1, Bias: 42189038.552229, T: 853380, Avg. loss: 262124745281687580049408.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: nan, NNZs: 1, Bias: 672691.180224, T: 910272, Avg. loss: 106851668285563892400128.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: nan, NNZs: 1, Bias: -4.870967, T: 967164, Avg. loss: 5377609403946699325440.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 18\n",
            "Norm: nan, NNZs: 1, Bias: -0.045932, T: 1024056, Avg. loss: 93295389.191923\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: nan, NNZs: 1, Bias: -0.013865, T: 1080948, Avg. loss: 36443.583017\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: nan, NNZs: 1, Bias: 0.107825, T: 1137840, Avg. loss: 0.986048\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: nan, NNZs: 1, Bias: 0.023449, T: 1194732, Avg. loss: 0.218072\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: nan, NNZs: 1, Bias: 0.067059, T: 1251624, Avg. loss: 0.039060\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 23\n",
            "Norm: nan, NNZs: 1, Bias: -0.028667, T: 1308516, Avg. loss: 0.028606\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: nan, NNZs: 1, Bias: 0.014395, T: 1365408, Avg. loss: 0.010855\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 25\n",
            "Norm: nan, NNZs: 1, Bias: -0.016989, T: 1422300, Avg. loss: 0.009010\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 26\n",
            "Norm: nan, NNZs: 1, Bias: -0.052696, T: 1479192, Avg. loss: 0.006643\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 27\n",
            "Norm: nan, NNZs: 1, Bias: 0.013842, T: 1536084, Avg. loss: 0.005733\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 28\n",
            "Norm: nan, NNZs: 1, Bias: -0.012855, T: 1592976, Avg. loss: 0.005154\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 29\n",
            "Norm: nan, NNZs: 1, Bias: -0.010111, T: 1649868, Avg. loss: 0.004549\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 30\n",
            "Norm: nan, NNZs: 1, Bias: 0.014299, T: 1706760, Avg. loss: 0.004167\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 31\n",
            "Norm: nan, NNZs: 1, Bias: -0.007338, T: 1763652, Avg. loss: 0.003799\n",
            "Total training time: 0.14 seconds.\n",
            "Convergence after 31 epochs took 0.14 seconds\n",
            "-- Epoch 1\n",
            "Norm: 19110964800016.92, NNZs: 1, Bias: -8125827359066.187500, T: 56892, Avg. loss: 266000727104448993337278464.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 7161105710468.54, NNZs: 1, Bias: 13831336816611.562500, T: 113784, Avg. loss: 55334382220733643000643584.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5813957950876.72, NNZs: 1, Bias: -301642862715.266602, T: 170676, Avg. loss: 23189661119249466186006528.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 3109888400129.38, NNZs: 1, Bias: -3037437660145.360352, T: 227568, Avg. loss: 12417312935935224808734720.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 3020703259424.40, NNZs: 1, Bias: 1891738964709.778564, T: 284460, Avg. loss: 7573486056465852446801920.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1425226107696.22, NNZs: 1, Bias: -872817677256.655762, T: 341352, Avg. loss: 5033817886567456099532800.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 3122140736438.20, NNZs: 1, Bias: 962638938319.789551, T: 398244, Avg. loss: 3491964821041960135426048.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 2207526529224.58, NNZs: 1, Bias: 275887305608.044922, T: 455136, Avg. loss: 2540741607818533481218048.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 2289025527613.92, NNZs: 1, Bias: 2109951763378.475342, T: 512028, Avg. loss: 1900273537616046997897216.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 2269253701240.72, NNZs: 1, Bias: -173628826851.720215, T: 568920, Avg. loss: 1429924726261815653171200.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 13536194545.59, NNZs: 1, Bias: -874519361985.291382, T: 625812, Avg. loss: 1087221687686475974443008.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 630462915037.49, NNZs: 1, Bias: -256286144768.990967, T: 682704, Avg. loss: 820461703366861129777152.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 604051380604.55, NNZs: 1, Bias: 76644113064.233093, T: 739596, Avg. loss: 606975578337022782210048.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 48768032472.72, NNZs: 1, Bias: -17105669986.158955, T: 796488, Avg. loss: 431782225909208785616896.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 367872937779.26, NNZs: 1, Bias: 35935405632.534027, T: 853380, Avg. loss: 264214108836502286893056.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 4719333.30, NNZs: 1, Bias: -2445694.454678, T: 910272, Avg. loss: 102075622023713532149760.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 333027.17, NNZs: 1, Bias: -17.650894, T: 967164, Avg. loss: 3228469137923692822528.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 315079.52, NNZs: 1, Bias: 0.065894, T: 1024056, Avg. loss: 1391629230.238437\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 298967.72, NNZs: 1, Bias: -0.031029, T: 1080948, Avg. loss: 122832.309389\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 284423.53, NNZs: 1, Bias: 0.237531, T: 1137840, Avg. loss: 0.576166\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 271228.79, NNZs: 1, Bias: 0.022524, T: 1194732, Avg. loss: 0.127324\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 259204.01, NNZs: 1, Bias: -0.000159, T: 1251624, Avg. loss: 0.035176\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 248200.19, NNZs: 1, Bias: 0.055426, T: 1308516, Avg. loss: 0.019317\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 238092.60, NNZs: 1, Bias: 0.221509, T: 1365408, Avg. loss: 0.010426\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 228776.03, NNZs: 1, Bias: 0.024516, T: 1422300, Avg. loss: 0.009204\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 220161.12, NNZs: 1, Bias: 0.002881, T: 1479192, Avg. loss: 0.006972\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 212171.48, NNZs: 1, Bias: 0.035814, T: 1536084, Avg. loss: 0.005761\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 204741.42, NNZs: 1, Bias: 0.028346, T: 1592976, Avg. loss: 0.005414\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 197814.14, NNZs: 1, Bias: -0.057294, T: 1649868, Avg. loss: 0.004600\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 191340.28, NNZs: 1, Bias: 0.078082, T: 1706760, Avg. loss: 0.004397\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 185276.73, NNZs: 1, Bias: 0.007742, T: 1763652, Avg. loss: 0.003980\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 179585.68, NNZs: 1, Bias: 0.005969, T: 1820544, Avg. loss: 0.003672\n",
            "Total training time: 0.15 seconds.\n",
            "Convergence after 32 epochs took 0.15 seconds\n",
            "-- Epoch 1\n",
            "Norm: 6033457359896.13, NNZs: 1, Bias: -14657054060446.435547, T: 56892, Avg. loss: 265846551039226869832482816.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 414315776674.80, NNZs: 1, Bias: 3081831114532.515137, T: 113784, Avg. loss: 55660452933964685633388544.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 9917149069317.11, NNZs: 1, Bias: 2666599375923.355469, T: 170676, Avg. loss: 23109654429130841829408768.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 3356268425162.45, NNZs: 1, Bias: 799774907010.681641, T: 227568, Avg. loss: 12404941159727013369479168.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 539414812493.14, NNZs: 1, Bias: -1105100234793.484375, T: 284460, Avg. loss: 7597796185228445543825408.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 453447395873.20, NNZs: 1, Bias: 623790523960.348145, T: 341352, Avg. loss: 5012646389018286419345408.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 337402077006.81, NNZs: 1, Bias: 747952142390.237549, T: 398244, Avg. loss: 3507121207464311119675392.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 2892904746950.16, NNZs: 1, Bias: -1857269749869.940918, T: 455136, Avg. loss: 2546606642115090967429120.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1033209928444.01, NNZs: 1, Bias: 970217485936.078491, T: 512028, Avg. loss: 1901883316195587491102720.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 273759918204.97, NNZs: 1, Bias: 753101512857.392334, T: 568920, Avg. loss: 1432596283290848554123264.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 794782417595.68, NNZs: 1, Bias: -1313273362402.271240, T: 625812, Avg. loss: 1091068619605066161061888.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 170787016082.57, NNZs: 1, Bias: -301297219432.483398, T: 682704, Avg. loss: 824443027858999935500288.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 90409500001.89, NNZs: 1, Bias: -255961794392.531189, T: 739596, Avg. loss: 610211250079421956096000.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 894310846088.45, NNZs: 1, Bias: -1052101161816.187134, T: 796488, Avg. loss: 429082338043511537926144.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 105107433922.04, NNZs: 1, Bias: 8294804378.949692, T: 853380, Avg. loss: 272359300722010479394816.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 695073.76, NNZs: 1, Bias: 234979.792516, T: 910272, Avg. loss: 115411628597366157737984.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 648488.44, NNZs: 1, Bias: -2.943049, T: 967164, Avg. loss: 7245934256155283947520.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 613540.46, NNZs: 1, Bias: 0.016967, T: 1024056, Avg. loss: 2937863667.883062\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 582166.66, NNZs: 1, Bias: -1.474166, T: 1080948, Avg. loss: 850.458614\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 553845.40, NNZs: 1, Bias: 0.002223, T: 1137840, Avg. loss: 1.720867\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 528151.86, NNZs: 1, Bias: 0.002780, T: 1194732, Avg. loss: 0.206718\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 504736.53, NNZs: 1, Bias: 0.000812, T: 1251624, Avg. loss: 0.031510\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 483309.28, NNZs: 1, Bias: -0.065868, T: 1308516, Avg. loss: 0.014140\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 463627.22, NNZs: 1, Bias: 0.002589, T: 1365408, Avg. loss: 0.009799\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 445485.47, NNZs: 1, Bias: 0.126402, T: 1422300, Avg. loss: 0.007629\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 428710.03, NNZs: 1, Bias: 0.006275, T: 1479192, Avg. loss: 0.006266\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 413152.16, NNZs: 1, Bias: -0.009045, T: 1536084, Avg. loss: 0.005122\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 398683.93, NNZs: 1, Bias: -0.028822, T: 1592976, Avg. loss: 0.004479\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 385194.75, NNZs: 1, Bias: 0.024115, T: 1649868, Avg. loss: 0.003900\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 372588.48, NNZs: 1, Bias: -0.012983, T: 1706760, Avg. loss: 0.003449\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 360781.20, NNZs: 1, Bias: -0.012432, T: 1763652, Avg. loss: 0.003262\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 349699.27, NNZs: 1, Bias: -0.031733, T: 1820544, Avg. loss: 0.003077\n",
            "Total training time: 0.17 seconds.\n",
            "Convergence after 32 epochs took 0.17 seconds\n",
            "-- Epoch 1\n",
            "Norm: 10004984712223.76, NNZs: 1, Bias: 11115995106809.496094, T: 56892, Avg. loss: 266170832780797570292121600.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 7474102813415.40, NNZs: 1, Bias: 5999051516213.282227, T: 113784, Avg. loss: 55390427190938788618567680.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4490635232994.83, NNZs: 1, Bias: 28300900157.544922, T: 170676, Avg. loss: 23103143661235016336146432.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 687027762913.89, NNZs: 1, Bias: 1251031003672.420898, T: 227568, Avg. loss: 12418042686840576378142720.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 38268600694.80, NNZs: 1, Bias: 277500689605.002441, T: 284460, Avg. loss: 7573646463140880892035072.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 785808316347.95, NNZs: 1, Bias: 1323225164502.195557, T: 341352, Avg. loss: 5014056690151740948873216.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2675225132735.78, NNZs: 1, Bias: -1381782996413.961182, T: 398244, Avg. loss: 3501775502510517276114944.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 2108709791754.54, NNZs: 1, Bias: -1323027271782.030029, T: 455136, Avg. loss: 2551286810665108264452096.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 865966675796.17, NNZs: 1, Bias: 1298539307123.433350, T: 512028, Avg. loss: 1894905159550338393440256.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1799772640809.91, NNZs: 1, Bias: 323990197666.092896, T: 568920, Avg. loss: 1434458869648911392309248.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 945386596886.80, NNZs: 1, Bias: -205145875934.315674, T: 625812, Avg. loss: 1096214419419621333401600.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1983371524442.25, NNZs: 1, Bias: -505612609255.884766, T: 682704, Avg. loss: 823962506690245494308864.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1272058709604.17, NNZs: 1, Bias: 405522496084.483032, T: 739596, Avg. loss: 617676494420364106924032.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 19416983961.09, NNZs: 1, Bias: -13929662695.741821, T: 796488, Avg. loss: 431679330337881495437312.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 2254610098.23, NNZs: 1, Bias: -3790171.110339, T: 853380, Avg. loss: 262715061051745743405056.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: -1.505427, T: 910272, Avg. loss: 72247197893543145242624.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: 0.045665, T: 967164, Avg. loss: 411961.776297\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: -0.051627, T: 1024056, Avg. loss: 0.484783\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: -0.396342, T: 1080948, Avg. loss: 0.178591\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: -0.057302, T: 1137840, Avg. loss: 0.084189\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: -0.015697, T: 1194732, Avg. loss: 0.043475\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: 0.007323, T: 1251624, Avg. loss: 0.025317\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: 0.029011, T: 1308516, Avg. loss: 0.015845\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: 0.015918, T: 1365408, Avg. loss: 0.010908\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: 0.018182, T: 1422300, Avg. loss: 0.008296\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: 0.001412, T: 1479192, Avg. loss: 0.006748\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: -0.021153, T: 1536084, Avg. loss: 0.005848\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: 0.008627, T: 1592976, Avg. loss: 0.005162\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: -0.006395, T: 1649868, Avg. loss: 0.004417\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: -0.062211, T: 1706760, Avg. loss: 0.004129\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 2263180815.80, NNZs: 1, Bias: -0.004933, T: 1763652, Avg. loss: 0.003861\n",
            "Total training time: 0.14 seconds.\n",
            "Convergence after 31 epochs took 0.14 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1943513442153.58, NNZs: 1, Bias: -4622998710146.689453, T: 56892, Avg. loss: 265193646485162662993854464.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 257355745438.72, NNZs: 1, Bias: -6809905325616.160156, T: 113784, Avg. loss: 55136828515459833178095616.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2635501988490.41, NNZs: 1, Bias: -3771532455838.906250, T: 170676, Avg. loss: 23160826083368615031078912.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 3114825793416.07, NNZs: 1, Bias: 3108087380929.609863, T: 227568, Avg. loss: 12411670575836873699098624.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 341155238029.49, NNZs: 1, Bias: -746899484254.635742, T: 284460, Avg. loss: 7583173800852697301123072.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 983858954503.31, NNZs: 1, Bias: -2722550226494.629395, T: 341352, Avg. loss: 4993656835351855761457152.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1957035314681.18, NNZs: 1, Bias: 180258926525.321289, T: 398244, Avg. loss: 3506569047895311283912704.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 2204930487950.03, NNZs: 1, Bias: 587819084073.994629, T: 455136, Avg. loss: 2539530836550701207781376.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 201922079461.80, NNZs: 1, Bias: -313614771118.155273, T: 512028, Avg. loss: 1907828504170565497520128.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1382710871901.00, NNZs: 1, Bias: -398734146858.648193, T: 568920, Avg. loss: 1426561867625643764613120.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 561529597586.62, NNZs: 1, Bias: -523444403416.882202, T: 625812, Avg. loss: 1091156335993040385605632.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 660241686377.63, NNZs: 1, Bias: -381897195551.156616, T: 682704, Avg. loss: 819234071720678091915264.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1435927999696.66, NNZs: 1, Bias: -1271545650763.537598, T: 739596, Avg. loss: 612042334503354465517568.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 58470230612.32, NNZs: 1, Bias: -4843027713.618538, T: 796488, Avg. loss: 430044431723289200558080.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 2284375793.72, NNZs: 1, Bias: -2139535187.988645, T: 853380, Avg. loss: 264524048299872051265536.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.295976, T: 910272, Avg. loss: 99359363455912127758336.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.034258, T: 967164, Avg. loss: 8.171898\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.051352, T: 1024056, Avg. loss: 0.382014\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.134607, T: 1080948, Avg. loss: 0.192284\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.041488, T: 1137840, Avg. loss: 0.088953\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.096467, T: 1194732, Avg. loss: 0.047032\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.064876, T: 1251624, Avg. loss: 0.024617\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.075523, T: 1308516, Avg. loss: 0.018018\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.042064, T: 1365408, Avg. loss: 0.011512\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.010149, T: 1422300, Avg. loss: 0.008561\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.005446, T: 1479192, Avg. loss: 0.007064\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: 0.012490, T: 1536084, Avg. loss: 0.006108\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.026262, T: 1592976, Avg. loss: 0.005075\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: 0.006758, T: 1649868, Avg. loss: 0.004569\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: -0.017751, T: 1706760, Avg. loss: 0.004261\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: 0.055810, T: 1763652, Avg. loss: 0.003939\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: 0.028734, T: 1820544, Avg. loss: 0.003711\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 2267147631.11, NNZs: 1, Bias: 0.058358, T: 1877436, Avg. loss: 0.003393\n",
            "Total training time: 0.16 seconds.\n",
            "Convergence after 33 epochs took 0.16 seconds\n",
            "-- Epoch 1\n",
            "Norm: 16463604102523.81, NNZs: 1, Bias: -4021664107869.064453, T: 56892, Avg. loss: 267441519374394104012079104.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 682008053273.99, NNZs: 1, Bias: -13322579098868.548828, T: 113784, Avg. loss: 55438646914396239995863040.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 7158090314095.10, NNZs: 1, Bias: 1229413355290.971191, T: 170676, Avg. loss: 23113838884643301637488640.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 644426516856.52, NNZs: 1, Bias: 3103048682596.520508, T: 227568, Avg. loss: 12365364324126639198830592.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 514485890251.02, NNZs: 1, Bias: 2209718037760.360840, T: 284460, Avg. loss: 7556128563042004829732864.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 3392028477721.21, NNZs: 1, Bias: -547700721213.155273, T: 341352, Avg. loss: 5011486465645782520299520.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1123532716354.05, NNZs: 1, Bias: -1422529138438.464600, T: 398244, Avg. loss: 3515504235937970694127616.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1118028238529.04, NNZs: 1, Bias: -1398943952663.867920, T: 455136, Avg. loss: 2546913957810384479977472.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 2025335560180.95, NNZs: 1, Bias: 146143260741.457031, T: 512028, Avg. loss: 1894752999749224092401664.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 327001504341.56, NNZs: 1, Bias: 3273344016532.143555, T: 568920, Avg. loss: 1428453501979739738341376.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 809722122732.95, NNZs: 1, Bias: 620029742009.587158, T: 625812, Avg. loss: 1086984987648478112907264.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1398301225604.14, NNZs: 1, Bias: 1029507449214.559692, T: 682704, Avg. loss: 831075177807180166332416.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 87613819598.52, NNZs: 1, Bias: 524297618612.511536, T: 739596, Avg. loss: 603200108391389821140992.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 861548666657.72, NNZs: 1, Bias: -772644982021.968506, T: 796488, Avg. loss: 425714326643432249884672.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 2310139666.59, NNZs: 1, Bias: -126372953.738235, T: 853380, Avg. loss: 258288516536939399086080.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 2265916051.44, NNZs: 1, Bias: 0.070918, T: 910272, Avg. loss: 85010942150895934111744.000000\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: -10.483083, T: 967164, Avg. loss: 646721832787033325568.000000\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: -0.826632, T: 1024056, Avg. loss: 0.417089\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: -0.142321, T: 1080948, Avg. loss: 0.161780\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: -0.011017, T: 1137840, Avg. loss: 0.094755\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: 0.192261, T: 1194732, Avg. loss: 0.039557\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: 0.110227, T: 1251624, Avg. loss: 0.025420\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: -0.042918, T: 1308516, Avg. loss: 0.016395\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: -0.047927, T: 1365408, Avg. loss: 0.010644\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: 0.051357, T: 1422300, Avg. loss: 0.008328\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: -0.003037, T: 1479192, Avg. loss: 0.006660\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: -0.032407, T: 1536084, Avg. loss: 0.005821\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: -0.027729, T: 1592976, Avg. loss: 0.005323\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: 0.006650, T: 1649868, Avg. loss: 0.004461\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: -0.018821, T: 1706760, Avg. loss: 0.004193\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 2266020125.79, NNZs: 1, Bias: -0.022870, T: 1763652, Avg. loss: 0.003927\n",
            "Total training time: 0.16 seconds.\n",
            "Convergence after 31 epochs took 0.16 seconds\n",
            "-- Epoch 1\n",
            "Norm: 10040943947321.37, NNZs: 1, Bias: -3252644641368.683594, T: 56892, Avg. loss: 266469351023252348839395328.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 5137303018327.19, NNZs: 1, Bias: 436929983536.861328, T: 113784, Avg. loss: 55282984921050865133944832.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 8888434770915.24, NNZs: 1, Bias: 1350523195628.966797, T: 170676, Avg. loss: 23116450588222723897425920.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2373428604087.02, NNZs: 1, Bias: -288764179880.941895, T: 227568, Avg. loss: 12401124536828688829775872.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 392234435254.92, NNZs: 1, Bias: -773516547203.190430, T: 284460, Avg. loss: 7534006659232704011173888.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1205096441088.25, NNZs: 1, Bias: 1722103037452.563965, T: 341352, Avg. loss: 5019093535427667794329600.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2864873687699.26, NNZs: 1, Bias: -121787084801.771973, T: 398244, Avg. loss: 3504843564873238630629376.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 218633228761.90, NNZs: 1, Bias: -31055822060.509979, T: 455136, Avg. loss: 2540897102743290664452096.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1263475481445.88, NNZs: 1, Bias: -73997519463.742584, T: 512028, Avg. loss: 1898010447832959804243968.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 441618159899.05, NNZs: 1, Bias: -116967799069.819611, T: 568920, Avg. loss: 1434457329048202403381248.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 743330250421.79, NNZs: 1, Bias: -1761143804401.473389, T: 625812, Avg. loss: 1089599792641254996574208.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 621389913991.33, NNZs: 1, Bias: 994574639806.003296, T: 682704, Avg. loss: 816154978228428800524288.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1383896229051.41, NNZs: 1, Bias: 154655822535.926636, T: 739596, Avg. loss: 605573618659785994928128.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 241610928057.55, NNZs: 1, Bias: 421948392751.870117, T: 796488, Avg. loss: 428061656475363574808576.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 2261145431.31, NNZs: 1, Bias: -15761085032.080702, T: 853380, Avg. loss: 267302883111479105552384.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 2265718510.46, NNZs: 1, Bias: -0.087065, T: 910272, Avg. loss: 96043171995525060755456.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 2265718510.47, NNZs: 0, Bias: -0.654855, T: 967164, Avg. loss: 11100513.830311\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 2265718510.47, NNZs: 0, Bias: -0.599340, T: 1024056, Avg. loss: 0.407576\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: 0.039359, T: 1080948, Avg. loss: 0.194032\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: -0.054397, T: 1137840, Avg. loss: 0.083941\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: -0.041779, T: 1194732, Avg. loss: 0.044165\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: 0.007863, T: 1251624, Avg. loss: 0.026426\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: 0.020505, T: 1308516, Avg. loss: 0.016765\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: 0.068693, T: 1365408, Avg. loss: 0.011456\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: -0.009206, T: 1422300, Avg. loss: 0.009240\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: -0.023405, T: 1479192, Avg. loss: 0.007167\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: -0.032300, T: 1536084, Avg. loss: 0.006227\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: -0.036587, T: 1592976, Avg. loss: 0.005205\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: -0.007092, T: 1649868, Avg. loss: 0.004677\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: 0.038720, T: 1706760, Avg. loss: 0.004309\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: -0.034426, T: 1763652, Avg. loss: 0.003978\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: 0.008849, T: 1820544, Avg. loss: 0.003667\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 2265718510.47, NNZs: 1, Bias: -0.022099, T: 1877436, Avg. loss: 0.003520\n",
            "Total training time: 0.17 seconds.\n",
            "Convergence after 33 epochs took 0.17 seconds\n",
            "-- Epoch 1\n",
            "Norm: 5096645295884.42, NNZs: 1, Bias: -3783359042260.121094, T: 56892, Avg. loss: 265766927377000345355943936.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 2269612323663.85, NNZs: 1, Bias: 9642911925061.447266, T: 113784, Avg. loss: 55349598204350020894851072.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 5694859105509.95, NNZs: 1, Bias: 2589467237288.706543, T: 170676, Avg. loss: 23167950893086012510044160.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2102305474193.68, NNZs: 1, Bias: 5273823944379.853516, T: 227568, Avg. loss: 12415259936178141262774272.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1125533097844.10, NNZs: 1, Bias: 2041007039961.482910, T: 284460, Avg. loss: 7585288214016841891184640.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1106086358052.96, NNZs: 1, Bias: -835301095397.883179, T: 341352, Avg. loss: 5003410229959212283199488.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 491921946211.44, NNZs: 1, Bias: -8989272060.514160, T: 398244, Avg. loss: 3518371180080472449351680.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 750307609548.53, NNZs: 1, Bias: -1485561042850.762695, T: 455136, Avg. loss: 2543126195267957141012480.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1067814281001.77, NNZs: 1, Bias: -1414711413613.659424, T: 512028, Avg. loss: 1905731151424425979543552.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 992300295226.98, NNZs: 1, Bias: 1132881369860.780518, T: 568920, Avg. loss: 1436373943171946240802816.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 939265959174.52, NNZs: 1, Bias: 12844498253.445435, T: 625812, Avg. loss: 1089077636427220986626048.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 257663367448.63, NNZs: 1, Bias: -846568903433.083740, T: 682704, Avg. loss: 826853301631706376175616.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 695470621908.68, NNZs: 1, Bias: 393284333910.280884, T: 739596, Avg. loss: 609628441743053671104512.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 863978159407.53, NNZs: 1, Bias: -408315322791.550781, T: 796488, Avg. loss: 430862707564595401195520.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 105027149526.53, NNZs: 1, Bias: 5796396934.841370, T: 853380, Avg. loss: 267190149050725734285312.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.030773, T: 910272, Avg. loss: 79901742803435277778944.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.032192, T: 967164, Avg. loss: 0.963801\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: 0.001408, T: 1024056, Avg. loss: 0.373272\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: 0.048131, T: 1080948, Avg. loss: 0.177928\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.010359, T: 1137840, Avg. loss: 0.077510\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.047365, T: 1194732, Avg. loss: 0.043179\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.188385, T: 1251624, Avg. loss: 0.022821\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.025878, T: 1308516, Avg. loss: 0.015013\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.105055, T: 1365408, Avg. loss: 0.010404\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: 0.002086, T: 1422300, Avg. loss: 0.007797\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.066888, T: 1479192, Avg. loss: 0.005956\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.052266, T: 1536084, Avg. loss: 0.005068\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.008152, T: 1592976, Avg. loss: 0.004652\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.007734, T: 1649868, Avg. loss: 0.003863\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.041580, T: 1706760, Avg. loss: 0.003606\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 2264317363.74, NNZs: 1, Bias: -0.015255, T: 1763652, Avg. loss: 0.003375\n",
            "Total training time: 0.14 seconds.\n",
            "Convergence after 31 epochs took 0.14 seconds\n",
            "-- Epoch 1\n",
            "Norm: 11002155304430.33, NNZs: 1, Bias: 13607141003079.416016, T: 56892, Avg. loss: 267920165640697409043431424.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 2669541296204.46, NNZs: 1, Bias: -3638842793118.852539, T: 113784, Avg. loss: 55301672599316112611475456.000000\n",
            "Total training time: 0.01 seconds."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch 3\n",
            "Norm: 2747821350953.54, NNZs: 1, Bias: 8128660825593.857422, T: 170676, Avg. loss: 23195963788849733861113856.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2298458667121.16, NNZs: 1, Bias: -5278029021443.210938, T: 227568, Avg. loss: 12437144617504755867975680.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2623013800872.38, NNZs: 1, Bias: -673982538065.641846, T: 284460, Avg. loss: 7597299117276268895141888.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1936797057319.08, NNZs: 1, Bias: 1683258432763.748535, T: 341352, Avg. loss: 5027774772650238204182528.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1163585685341.85, NNZs: 1, Bias: -1042056759952.069092, T: 398244, Avg. loss: 3526495796108391765508096.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1983115588347.58, NNZs: 1, Bias: 488848485587.916016, T: 455136, Avg. loss: 2555012597383319884136448.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 554687296097.68, NNZs: 1, Bias: 242467180460.885742, T: 512028, Avg. loss: 1910102442364904476246016.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 226279365097.94, NNZs: 1, Bias: -221670341992.867920, T: 568920, Avg. loss: 1432609510387865488457728.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 264787887621.67, NNZs: 1, Bias: -416251336073.754395, T: 625812, Avg. loss: 1091225252445160774565888.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 193615088459.44, NNZs: 1, Bias: 163378952040.409851, T: 682704, Avg. loss: 830342187508264293367808.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 112550578187.29, NNZs: 1, Bias: 124278463515.884949, T: 739596, Avg. loss: 607366129777000681832448.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1271757735173.21, NNZs: 1, Bias: 164054405328.562866, T: 796488, Avg. loss: 425531426169353742057472.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 112467058754.37, NNZs: 1, Bias: -149454209498.868896, T: 853380, Avg. loss: 267674779079014812221440.000000\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 3753479745.19, NNZs: 1, Bias: -1733333441.199416, T: 910272, Avg. loss: 116719099910771250823168.000000\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 418656926.99, NNZs: 1, Bias: -0.013600, T: 967164, Avg. loss: 2788195024145496408064.000000\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 399400042.95, NNZs: 1, Bias: -0.194331, T: 1024056, Avg. loss: 1910141.168380\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 381972072.96, NNZs: 1, Bias: 0.090312, T: 1080948, Avg. loss: 0.905849\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 366118483.84, NNZs: 1, Bias: -0.011652, T: 1137840, Avg. loss: 0.150664\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 351630368.89, NNZs: 1, Bias: 0.070261, T: 1194732, Avg. loss: 0.051075\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 338334602.87, NNZs: 1, Bias: 0.077266, T: 1251624, Avg. loss: 0.027178\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 326086450.19, NNZs: 1, Bias: 0.187294, T: 1308516, Avg. loss: 0.016999\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 314763939.74, NNZs: 1, Bias: 0.090084, T: 1365408, Avg. loss: 0.011068\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 304263531.39, NNZs: 1, Bias: 0.013108, T: 1422300, Avg. loss: 0.007886\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 294496739.94, NNZs: 1, Bias: -0.033846, T: 1479192, Avg. loss: 0.006949\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 285387477.81, NNZs: 1, Bias: 0.051554, T: 1536084, Avg. loss: 0.006125\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 276869943.69, NNZs: 1, Bias: -0.025883, T: 1592976, Avg. loss: 0.005023\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 268886930.11, NNZs: 1, Bias: -0.034981, T: 1649868, Avg. loss: 0.004466\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 261388455.92, NNZs: 1, Bias: -0.033468, T: 1706760, Avg. loss: 0.004252\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 254330652.92, NNZs: 1, Bias: -0.004787, T: 1763652, Avg. loss: 0.003789\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 247674852.97, NNZs: 1, Bias: 0.043619, T: 1820544, Avg. loss: 0.003518\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 241386834.67, NNZs: 1, Bias: 0.011539, T: 1877436, Avg. loss: 0.003266\n",
            "Total training time: 0.18 seconds.\n",
            "Convergence after 33 epochs took 0.18 seconds\n",
            "-- Epoch 1\n",
            "Norm: 2572692852767.97, NNZs: 1, Bias: -4111695774119.724609, T: 56892, Avg. loss: 265603076335976820026376192.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 9675405274203.42, NNZs: 1, Bias: -1192720889539.724609, T: 113784, Avg. loss: 55141994843776745891430400.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 542512576604.68, NNZs: 1, Bias: -843166271574.089844, T: 170676, Avg. loss: 23192070926936310481420288.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1287992694848.98, NNZs: 1, Bias: -4898229448482.158203, T: 227568, Avg. loss: 12419931080100172955385856.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4013006652691.69, NNZs: 1, Bias: -794654276118.439453, T: 284460, Avg. loss: 7599286230617689925091328.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1789687690207.88, NNZs: 1, Bias: 1045806474960.215820, T: 341352, Avg. loss: 5020317152741275281129472.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 4357853887827.48, NNZs: 1, Bias: -1072691836901.730469, T: 398244, Avg. loss: 3502326186046603309088768.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 675436304023.83, NNZs: 1, Bias: 1052228392963.777588, T: 455136, Avg. loss: 2552999717948700793765888.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 125332564527.88, NNZs: 1, Bias: -2599298868859.074219, T: 512028, Avg. loss: 1898218060781642844209152.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1490249823251.84, NNZs: 1, Bias: -590676063568.791016, T: 568920, Avg. loss: 1437113966477628275687424.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 319926629881.86, NNZs: 1, Bias: -414785382937.955322, T: 625812, Avg. loss: 1091478418233345494220800.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 120271636652.78, NNZs: 1, Bias: -1070356483995.968018, T: 682704, Avg. loss: 827789905585529941917696.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 240397857497.61, NNZs: 1, Bias: -5096893403.791199, T: 739596, Avg. loss: 610348811628675736797184.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 13091523519.05, NNZs: 1, Bias: -27110811255.669655, T: 796488, Avg. loss: 425459082646481371398144.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 12392966874.95, NNZs: 1, Bias: 15280160966.869049, T: 853380, Avg. loss: 264993961325814590996480.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 439771975.59, NNZs: 1, Bias: 390224.246794, T: 910272, Avg. loss: 115095740853416095645696.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 418762684.12, NNZs: 1, Bias: 0.298872, T: 967164, Avg. loss: 3587538627971138977792.000000\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 399500935.58, NNZs: 1, Bias: 0.130288, T: 1024056, Avg. loss: 833999.285600\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 382068563.10, NNZs: 1, Bias: 0.021827, T: 1080948, Avg. loss: 473.262995\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 366210969.20, NNZs: 1, Bias: 0.162231, T: 1137840, Avg. loss: 0.435316\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 351719194.40, NNZs: 1, Bias: 0.050823, T: 1194732, Avg. loss: 0.046101\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 338420069.73, NNZs: 1, Bias: -0.073902, T: 1251624, Avg. loss: 0.027578\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 326168823.04, NNZs: 1, Bias: 0.070686, T: 1308516, Avg. loss: 0.016684\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 314843452.41, NNZs: 1, Bias: -0.016984, T: 1365408, Avg. loss: 0.010875\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 304340391.55, NNZs: 1, Bias: -0.044938, T: 1422300, Avg. loss: 0.008564\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 294571132.90, NNZs: 1, Bias: -0.024253, T: 1479192, Avg. loss: 0.006805\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 285459569.67, NNZs: 1, Bias: -0.019548, T: 1536084, Avg. loss: 0.005626\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 276939883.93, NNZs: 1, Bias: -0.013072, T: 1592976, Avg. loss: 0.005024\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 268954853.76, NNZs: 1, Bias: 0.068968, T: 1649868, Avg. loss: 0.004654\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 261454485.38, NNZs: 1, Bias: -0.016809, T: 1706760, Avg. loss: 0.004273\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 254394899.51, NNZs: 1, Bias: -0.038640, T: 1763652, Avg. loss: 0.003888\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 247737418.23, NNZs: 1, Bias: -0.001166, T: 1820544, Avg. loss: 0.003618\n",
            "Total training time: 0.16 seconds.\n",
            "Convergence after 32 epochs took 0.16 seconds\n",
            "-- Epoch 1\n",
            "Norm: 11567889683033.04, NNZs: 1, Bias: 711993327845.189453, T: 56892, Avg. loss: 266120105301578373006360576.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 856301831434.57, NNZs: 1, Bias: -1066468518352.540527, T: 113784, Avg. loss: 55360688630833773323223040.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4955061233115.38, NNZs: 1, Bias: -1124577397617.604492, T: 170676, Avg. loss: 23154707202312863922257920.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2811689525655.78, NNZs: 1, Bias: -655948135295.402832, T: 227568, Avg. loss: 12358429438700651739611136.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 505761012393.77, NNZs: 1, Bias: -935734898841.142578, T: 284460, Avg. loss: 7607123398350523588411392.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 273309456798.62, NNZs: 1, Bias: -3155343126745.518555, T: 341352, Avg. loss: 5024016026275145429549056.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2335340320557.08, NNZs: 1, Bias: -145036257047.134033, T: 398244, Avg. loss: 3511898751528519558234112.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 152599998079.28, NNZs: 1, Bias: -65665118110.261963, T: 455136, Avg. loss: 2548532921205873444913152.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 682005325386.29, NNZs: 1, Bias: 315537900434.124756, T: 512028, Avg. loss: 1895870204233903945809920.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 375417137968.25, NNZs: 1, Bias: 1640356915839.509521, T: 568920, Avg. loss: 1437142210945027351248896.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 43084708553.99, NNZs: 1, Bias: 2065553982679.777344, T: 625812, Avg. loss: 1098991591660575153717248.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 39694325207.82, NNZs: 1, Bias: 110172394888.519821, T: 682704, Avg. loss: 817258168215481031327744.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 740790745554.48, NNZs: 1, Bias: 1059919648602.058105, T: 739596, Avg. loss: 608753811411350996385792.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 222070153044.25, NNZs: 1, Bias: -147630577363.389771, T: 796488, Avg. loss: 427196631372601185271808.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 259007289773.46, NNZs: 1, Bias: 234694061939.545776, T: 853380, Avg. loss: 274395038441726615224320.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 625323088265.87, NNZs: 1, Bias: 1269028540.194336, T: 910272, Avg. loss: 107511069366743516315648.000000\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 418797916.20, NNZs: 1, Bias: 0.180352, T: 967164, Avg. loss: 3332931660884533051392.000000\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 399534547.10, NNZs: 1, Bias: -0.169406, T: 1024056, Avg. loss: 582527.309844\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 382100707.97, NNZs: 1, Bias: -0.748002, T: 1080948, Avg. loss: 78.130176\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 366241779.91, NNZs: 1, Bias: -0.057165, T: 1137840, Avg. loss: 0.161590\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 351748785.86, NNZs: 1, Bias: 0.045899, T: 1194732, Avg. loss: 0.048384\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 338448542.29, NNZs: 1, Bias: -0.054431, T: 1251624, Avg. loss: 0.027543\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 326196264.85, NNZs: 1, Bias: 0.358149, T: 1308516, Avg. loss: 0.015973\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 314869941.38, NNZs: 1, Bias: -0.180866, T: 1365408, Avg. loss: 0.010742\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 304365996.85, NNZs: 1, Bias: 0.048748, T: 1422300, Avg. loss: 0.008301\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 294595916.28, NNZs: 1, Bias: -0.095979, T: 1479192, Avg. loss: 0.006851\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 285483586.47, NNZs: 1, Bias: 0.052660, T: 1536084, Avg. loss: 0.005843\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 276963183.93, NNZs: 1, Bias: -0.032971, T: 1592976, Avg. loss: 0.005101\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 268977481.95, NNZs: 1, Bias: -0.020120, T: 1649868, Avg. loss: 0.004527\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 261476482.54, NNZs: 1, Bias: -0.004378, T: 1706760, Avg. loss: 0.004310\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 254416302.71, NNZs: 1, Bias: -0.037235, T: 1763652, Avg. loss: 0.003857\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 247758261.31, NNZs: 1, Bias: -0.021881, T: 1820544, Avg. loss: 0.003765\n",
            "Total training time: 0.18 seconds.\n",
            "Convergence after 32 epochs took 0.18 seconds\n",
            "-- Epoch 1\n",
            "Norm: 870127096077.34, NNZs: 1, Bias: -10597507179279.949219, T: 56892, Avg. loss: 266245426782185064841084928.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 15882420122.83, NNZs: 1, Bias: 10955637820784.308594, T: 113784, Avg. loss: 55097881737114089896804352.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 417569889897.42, NNZs: 1, Bias: -1499237326312.520508, T: 170676, Avg. loss: 23156965280992488197193728.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 3145363270011.43, NNZs: 1, Bias: 687066827634.908203, T: 227568, Avg. loss: 12405900949231315957317632.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2506143543235.10, NNZs: 1, Bias: 5450288325125.632812, T: 284460, Avg. loss: 7563519137316885726494720.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5343637050733.73, NNZs: 1, Bias: -1476134162628.182129, T: 341352, Avg. loss: 5020248919820935905673216.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2717046145239.87, NNZs: 1, Bias: 772250756204.488281, T: 398244, Avg. loss: 3516055879641356300189696.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 207368269023.13, NNZs: 1, Bias: 2375345035748.649414, T: 455136, Avg. loss: 2549957108378415816245248.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 892130029246.01, NNZs: 1, Bias: 2022467124531.049561, T: 512028, Avg. loss: 1900843043345910238019584.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 455500226959.92, NNZs: 1, Bias: -308374309712.936768, T: 568920, Avg. loss: 1439530423573180995076096.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1142831438870.08, NNZs: 1, Bias: -374330083607.194763, T: 625812, Avg. loss: 1086518915686911960940544.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 241584340835.53, NNZs: 1, Bias: 1289136456035.607422, T: 682704, Avg. loss: 816963691537770590765056.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 809196901754.18, NNZs: 1, Bias: 194955576901.610352, T: 739596, Avg. loss: 612462053995234082160640.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 190012860588.49, NNZs: 1, Bias: 170890486252.097015, T: 796488, Avg. loss: 428059038822488569020416.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 56463356224.31, NNZs: 1, Bias: -10718840229.351883, T: 853380, Avg. loss: 256321825175957258895360.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 438430754.77, NNZs: 1, Bias: 53699219.026068, T: 910272, Avg. loss: 103781829028882392547328.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 417243008.55, NNZs: 1, Bias: -0.088944, T: 967164, Avg. loss: 1835283886609502568448.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 398051160.28, NNZs: 1, Bias: 0.052166, T: 1024056, Avg. loss: 257087804.532974\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 380682049.29, NNZs: 1, Bias: -0.030152, T: 1080948, Avg. loss: 1575.403342\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 364882002.06, NNZs: 1, Bias: 0.018304, T: 1137840, Avg. loss: 0.134541\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 350442817.42, NNZs: 1, Bias: -0.043224, T: 1194732, Avg. loss: 0.048356\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 337191954.82, NNZs: 1, Bias: -0.078767, T: 1251624, Avg. loss: 0.025538\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 324985167.48, NNZs: 1, Bias: -0.007297, T: 1308516, Avg. loss: 0.017373\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 313700896.23, NNZs: 1, Bias: -0.049840, T: 1365408, Avg. loss: 0.011984\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 303235950.63, NNZs: 1, Bias: -0.049648, T: 1422300, Avg. loss: 0.008554\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 293502144.28, NNZs: 1, Bias: -0.008617, T: 1479192, Avg. loss: 0.007159\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 284423646.61, NNZs: 1, Bias: -0.053379, T: 1536084, Avg. loss: 0.005826\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 275934878.52, NNZs: 1, Bias: 0.042628, T: 1592976, Avg. loss: 0.005236\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 267978825.75, NNZs: 1, Bias: 0.007927, T: 1649868, Avg. loss: 0.004723\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 260505675.96, NNZs: 1, Bias: 0.031406, T: 1706760, Avg. loss: 0.004256\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 253471709.08, NNZs: 1, Bias: 0.015143, T: 1763652, Avg. loss: 0.003942\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 246838387.57, NNZs: 1, Bias: 0.002603, T: 1820544, Avg. loss: 0.003658\n",
            "Total training time: 0.16 seconds.\n",
            "Convergence after 32 epochs took 0.16 seconds\n",
            "-- Epoch 1\n",
            "Norm: 667097926141.24, NNZs: 1, Bias: -22774348294697.625000, T: 56892, Avg. loss: 266012347501815442113036288.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1053802541966.40, NNZs: 1, Bias: 3619912192475.403320, T: 113784, Avg. loss: 55381023938107590198689792.000000\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1281500103397.92, NNZs: 1, Bias: -4661031697169.892578, T: 170676, Avg. loss: 23147093047809251888594944.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1975587977731.08, NNZs: 1, Bias: -2831739290760.070801, T: 227568, Avg. loss: 12416181581202715473608704.000000\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2821737607125.69, NNZs: 1, Bias: -401096491467.857910, T: 284460, Avg. loss: 7557572668361373137240064.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 2408187341952.76, NNZs: 1, Bias: -2830337811886.709961, T: 341352, Avg. loss: 5000994700956874051682304.000000\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2689151197632.06, NNZs: 1, Bias: 642708293969.450195, T: 398244, Avg. loss: 3516490448246772743536640.000000\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1099363534669.70, NNZs: 1, Bias: 460808025830.763550, T: 455136, Avg. loss: 2550944893667213658030080.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 118068994944.28, NNZs: 1, Bias: 1306529715515.904297, T: 512028, Avg. loss: 1906396495924782463713280.000000\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 652277648897.23, NNZs: 1, Bias: 491597009986.460205, T: 568920, Avg. loss: 1432232281789246151327744.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 969586630678.36, NNZs: 1, Bias: -118114455301.453369, T: 625812, Avg. loss: 1081800867161743663562752.000000\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 379793803729.84, NNZs: 1, Bias: 125594030288.965912, T: 682704, Avg. loss: 825773709768807394836480.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 299454966638.48, NNZs: 1, Bias: -148445803189.620850, T: 739596, Avg. loss: 615560805622485291630592.000000\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 915818684985.42, NNZs: 1, Bias: 577358399337.438477, T: 796488, Avg. loss: 425467912927943149486080.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 32441178952.56, NNZs: 1, Bias: -5675550189.476967, T: 853380, Avg. loss: 272878113232620720488448.000000\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 492481603975.29, NNZs: 1, Bias: -529497873786.919861, T: 910272, Avg. loss: 110841612525003199217664.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 418638960.87, NNZs: 1, Bias: -0.104338, T: 967164, Avg. loss: 5963660420669003268096.000000\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 399382903.20, NNZs: 1, Bias: -0.047709, T: 1024056, Avg. loss: 78689.249219\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 381955681.12, NNZs: 1, Bias: 0.035564, T: 1080948, Avg. loss: 88.861527\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 366102772.33, NNZs: 1, Bias: -0.070535, T: 1137840, Avg. loss: 0.103438\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 351615279.12, NNZs: 1, Bias: 0.374204, T: 1194732, Avg. loss: 0.060517\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 338320083.67, NNZs: 1, Bias: 0.011722, T: 1251624, Avg. loss: 0.031314\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 326072456.60, NNZs: 1, Bias: -0.032960, T: 1308516, Avg. loss: 0.015946\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 314750432.05, NNZs: 1, Bias: -0.022990, T: 1365408, Avg. loss: 0.010161\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 304250474.31, NNZs: 1, Bias: -0.094895, T: 1422300, Avg. loss: 0.007055\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 294484101.99, NNZs: 1, Bias: -0.026542, T: 1479192, Avg. loss: 0.005931\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 285375230.77, NNZs: 1, Bias: 0.118570, T: 1536084, Avg. loss: 0.004928\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 276858062.17, NNZs: 1, Bias: -0.038407, T: 1592976, Avg. loss: 0.004335\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 268875391.17, NNZs: 1, Bias: 0.041597, T: 1649868, Avg. loss: 0.003887\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 261377238.77, NNZs: 1, Bias: -0.007302, T: 1706760, Avg. loss: 0.003590\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 254319738.65, NNZs: 1, Bias: 0.155964, T: 1763652, Avg. loss: 0.003396\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 247664224.32, NNZs: 1, Bias: -0.032513, T: 1820544, Avg. loss: 0.003036\n",
            "Total training time: 0.16 seconds.\n",
            "Convergence after 32 epochs took 0.16 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.31, NNZs: 1, Bias: -0.678719, T: 56892, Avg. loss: 0.172716\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.35, NNZs: 1, Bias: -0.936279, T: 113784, Avg. loss: 0.079013\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.66, NNZs: 1, Bias: 0.697009, T: 170676, Avg. loss: 0.049828\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.99, NNZs: 1, Bias: -0.025663, T: 227568, Avg. loss: 0.035671\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.78, NNZs: 1, Bias: 0.157100, T: 284460, Avg. loss: 0.026944\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.18, NNZs: 1, Bias: -0.074519, T: 341352, Avg. loss: 0.021349\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.205324, T: 398244, Avg. loss: 0.017319\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.179118, T: 455136, Avg. loss: 0.014365\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.114557, T: 512028, Avg. loss: 0.012108\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.29, NNZs: 1, Bias: 0.167412, T: 568920, Avg. loss: 0.010269\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 0.85, NNZs: 1, Bias: 0.030429, T: 625812, Avg. loss: 0.008806\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 0.89, NNZs: 1, Bias: -0.212161, T: 682704, Avg. loss: 0.007679\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.023472, T: 739596, Avg. loss: 0.006731\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 0.86, NNZs: 1, Bias: -0.047382, T: 796488, Avg. loss: 0.005992\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.030817, T: 853380, Avg. loss: 0.005372\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 0.97, NNZs: 1, Bias: -0.030325, T: 910272, Avg. loss: 0.004834\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 1.05, NNZs: 1, Bias: -0.005435, T: 967164, Avg. loss: 0.004406\n",
            "Total training time: 0.09 seconds.\n",
            "Convergence after 17 epochs took 0.09 seconds\n",
            "-- Epoch 1\n",
            "Norm: 2.25, NNZs: 1, Bias: 0.875286, T: 56892, Avg. loss: 0.172403\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 2.08, NNZs: 1, Bias: 0.435544, T: 113784, Avg. loss: 0.078738\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.70, NNZs: 1, Bias: 0.734350, T: 170676, Avg. loss: 0.049892\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.204720, T: 227568, Avg. loss: 0.035532\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.15, NNZs: 1, Bias: -0.011916, T: 284460, Avg. loss: 0.026856\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.95, NNZs: 1, Bias: -0.171673, T: 341352, Avg. loss: 0.021350\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.82, NNZs: 1, Bias: -0.116726, T: 398244, Avg. loss: 0.017356\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 0.78, NNZs: 1, Bias: -0.084730, T: 455136, Avg. loss: 0.014302\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 0.93, NNZs: 1, Bias: -0.036211, T: 512028, Avg. loss: 0.012082\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.13, NNZs: 1, Bias: 0.046783, T: 568920, Avg. loss: 0.010289\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.072030, T: 625812, Avg. loss: 0.008863\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 0.83, NNZs: 1, Bias: 0.063688, T: 682704, Avg. loss: 0.007718\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.006665, T: 739596, Avg. loss: 0.006813\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 0.93, NNZs: 1, Bias: 0.082404, T: 796488, Avg. loss: 0.006055\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.074344, T: 853380, Avg. loss: 0.005438\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.176439, T: 910272, Avg. loss: 0.004849\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.082373, T: 967164, Avg. loss: 0.004443\n",
            "Total training time: 0.09 seconds.\n",
            "Convergence after 17 epochs took 0.09 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.98, NNZs: 1, Bias: 0.188022, T: 56892, Avg. loss: 0.172202\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.11, NNZs: 1, Bias: 0.109560, T: 113784, Avg. loss: 0.079010\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.13, NNZs: 1, Bias: 0.500567, T: 170676, Avg. loss: 0.049902\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.14, NNZs: 1, Bias: 0.353226, T: 227568, Avg. loss: 0.035557\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.85, NNZs: 1, Bias: -0.381350, T: 284460, Avg. loss: 0.026979\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.11, NNZs: 1, Bias: 0.042009, T: 341352, Avg. loss: 0.021373\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.378071, T: 398244, Avg. loss: 0.017265\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.41, NNZs: 1, Bias: 0.390345, T: 455136, Avg. loss: 0.014336\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.13, NNZs: 1, Bias: 0.034676, T: 512028, Avg. loss: 0.012065\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.063748, T: 568920, Avg. loss: 0.010347\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.18, NNZs: 1, Bias: 0.113966, T: 625812, Avg. loss: 0.008855\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 0.92, NNZs: 1, Bias: -0.170617, T: 682704, Avg. loss: 0.007720\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.047041, T: 739596, Avg. loss: 0.006770\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.176031, T: 796488, Avg. loss: 0.006009\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.017387, T: 853380, Avg. loss: 0.005388\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.065052, T: 910272, Avg. loss: 0.004824\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.111995, T: 967164, Avg. loss: 0.004384\n",
            "Total training time: 0.10 seconds.\n",
            "Convergence after 17 epochs took 0.10 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.15, NNZs: 1, Bias: -0.935325, T: 56892, Avg. loss: 0.172554\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.53, NNZs: 1, Bias: -0.240796, T: 113784, Avg. loss: 0.079006\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.047276, T: 170676, Avg. loss: 0.049830\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.23, NNZs: 1, Bias: -0.340896, T: 227568, Avg. loss: 0.035607\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.055286, T: 284460, Avg. loss: 0.026980\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.195447, T: 341352, Avg. loss: 0.021213\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.24, NNZs: 1, Bias: 0.139819, T: 398244, Avg. loss: 0.017272\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.014314, T: 455136, Avg. loss: 0.014328\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 0.75, NNZs: 1, Bias: 0.076825, T: 512028, Avg. loss: 0.012080\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.047107, T: 568920, Avg. loss: 0.010323\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.09, NNZs: 1, Bias: -0.092093, T: 625812, Avg. loss: 0.008848\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.061438, T: 682704, Avg. loss: 0.007748\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1.13, NNZs: 1, Bias: -0.018604, T: 739596, Avg. loss: 0.006799\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 0.89, NNZs: 1, Bias: 0.056183, T: 796488, Avg. loss: 0.006077\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 0.92, NNZs: 1, Bias: 0.001575, T: 853380, Avg. loss: 0.005394\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.020252, T: 910272, Avg. loss: 0.004834\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 0.94, NNZs: 1, Bias: -0.009553, T: 967164, Avg. loss: 0.004390\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 17 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 0.73, NNZs: 1, Bias: -0.598614, T: 56892, Avg. loss: 0.172351\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.68, NNZs: 1, Bias: 1.213693, T: 113784, Avg. loss: 0.078877\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.31, NNZs: 1, Bias: 0.383738, T: 170676, Avg. loss: 0.049694\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.256089, T: 227568, Avg. loss: 0.035401\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.60, NNZs: 1, Bias: 0.000700, T: 284460, Avg. loss: 0.026915\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.29, NNZs: 1, Bias: 0.108499, T: 341352, Avg. loss: 0.021270\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.26, NNZs: 1, Bias: 0.107541, T: 398244, Avg. loss: 0.017206\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.026951, T: 455136, Avg. loss: 0.014227\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.08, NNZs: 1, Bias: -0.125020, T: 512028, Avg. loss: 0.011941\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.053245, T: 568920, Avg. loss: 0.010134\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.19, NNZs: 1, Bias: 0.001437, T: 625812, Avg. loss: 0.008713\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1.11, NNZs: 1, Bias: -0.137186, T: 682704, Avg. loss: 0.007606\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.052738, T: 739596, Avg. loss: 0.006683\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.051646, T: 796488, Avg. loss: 0.005892\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.043152, T: 853380, Avg. loss: 0.005252\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.96, NNZs: 1, Bias: -0.042592, T: 910272, Avg. loss: 0.004758\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 0.92, NNZs: 1, Bias: 0.040334, T: 967164, Avg. loss: 0.004279\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 17 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 152.28, NNZs: 1, Bias: -0.474334, T: 56892, Avg. loss: 0.160629\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 163.13, NNZs: 1, Bias: -0.534342, T: 113784, Avg. loss: 0.075763\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 163.68, NNZs: 1, Bias: 0.567888, T: 170676, Avg. loss: 0.049797\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 163.69, NNZs: 1, Bias: -0.312611, T: 227568, Avg. loss: 0.035553\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 163.69, NNZs: 1, Bias: 0.285525, T: 284460, Avg. loss: 0.027039\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 163.69, NNZs: 1, Bias: 0.508680, T: 341352, Avg. loss: 0.021318\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 163.69, NNZs: 1, Bias: -0.085808, T: 398244, Avg. loss: 0.017316\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 163.69, NNZs: 1, Bias: -0.098719, T: 455136, Avg. loss: 0.014380\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 163.69, NNZs: 1, Bias: 0.017609, T: 512028, Avg. loss: 0.012033\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 163.69, NNZs: 1, Bias: -0.016556, T: 568920, Avg. loss: 0.010291\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 163.70, NNZs: 1, Bias: -0.089065, T: 625812, Avg. loss: 0.008863\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 163.69, NNZs: 1, Bias: -0.149157, T: 682704, Avg. loss: 0.007705\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 163.70, NNZs: 1, Bias: 0.037919, T: 739596, Avg. loss: 0.006777\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 163.70, NNZs: 1, Bias: -0.068715, T: 796488, Avg. loss: 0.006006\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 163.70, NNZs: 1, Bias: -0.059955, T: 853380, Avg. loss: 0.005352\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 163.70, NNZs: 1, Bias: -0.054503, T: 910272, Avg. loss: 0.004838\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 163.70, NNZs: 1, Bias: -0.017537, T: 967164, Avg. loss: 0.004420\n",
            "Total training time: 0.10 seconds.\n",
            "Convergence after 17 epochs took 0.10 seconds\n",
            "-- Epoch 1\n",
            "Norm: 152.56, NNZs: 1, Bias: 0.962988, T: 56892, Avg. loss: 0.160554\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 163.24, NNZs: 1, Bias: -0.477065, T: 113784, Avg. loss: 0.075784\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 163.82, NNZs: 1, Bias: 0.267374, T: 170676, Avg. loss: 0.049603\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 163.83, NNZs: 1, Bias: 0.017647, T: 227568, Avg. loss: 0.035619\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 163.84, NNZs: 1, Bias: 0.017088, T: 284460, Avg. loss: 0.026930\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 163.84, NNZs: 1, Bias: 0.150174, T: 341352, Avg. loss: 0.021349\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 163.84, NNZs: 1, Bias: 0.313680, T: 398244, Avg. loss: 0.017332\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 163.84, NNZs: 1, Bias: -0.025757, T: 455136, Avg. loss: 0.014349\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 163.84, NNZs: 1, Bias: -0.095589, T: 512028, Avg. loss: 0.012043\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 163.84, NNZs: 1, Bias: -0.018710, T: 568920, Avg. loss: 0.010258\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 163.84, NNZs: 1, Bias: -0.060987, T: 625812, Avg. loss: 0.008865\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 163.84, NNZs: 1, Bias: -0.090883, T: 682704, Avg. loss: 0.007719\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 163.84, NNZs: 1, Bias: 0.071562, T: 739596, Avg. loss: 0.006821\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 163.84, NNZs: 1, Bias: -0.075543, T: 796488, Avg. loss: 0.005992\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 163.84, NNZs: 1, Bias: -0.072374, T: 853380, Avg. loss: 0.005391\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 163.84, NNZs: 1, Bias: 0.089236, T: 910272, Avg. loss: 0.004880\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 163.84, NNZs: 1, Bias: 0.027775, T: 967164, Avg. loss: 0.004418\n",
            "Total training time: 0.09 seconds.\n",
            "Convergence after 17 epochs took 0.09 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 152.10, NNZs: 1, Bias: -0.597152, T: 56892, Avg. loss: 0.160166\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 162.78, NNZs: 1, Bias: -0.926593, T: 113784, Avg. loss: 0.075771\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 163.33, NNZs: 1, Bias: 0.154635, T: 170676, Avg. loss: 0.049596\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 163.35, NNZs: 1, Bias: -0.067556, T: 227568, Avg. loss: 0.035626\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 163.35, NNZs: 1, Bias: -0.054897, T: 284460, Avg. loss: 0.026999\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 163.35, NNZs: 1, Bias: 0.162550, T: 341352, Avg. loss: 0.021269\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 163.35, NNZs: 1, Bias: 0.054601, T: 398244, Avg. loss: 0.017366\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 163.35, NNZs: 1, Bias: -0.124528, T: 455136, Avg. loss: 0.014341\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 163.35, NNZs: 1, Bias: -0.085148, T: 512028, Avg. loss: 0.012013\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 163.35, NNZs: 1, Bias: 0.013679, T: 568920, Avg. loss: 0.010280\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 163.35, NNZs: 1, Bias: 0.013722, T: 625812, Avg. loss: 0.008868\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 163.36, NNZs: 1, Bias: -0.214639, T: 682704, Avg. loss: 0.007731\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 163.36, NNZs: 1, Bias: 0.179708, T: 739596, Avg. loss: 0.006773\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 163.36, NNZs: 1, Bias: -0.018263, T: 796488, Avg. loss: 0.006016\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 163.36, NNZs: 1, Bias: 0.018155, T: 853380, Avg. loss: 0.005380\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 163.36, NNZs: 1, Bias: 0.005112, T: 910272, Avg. loss: 0.004834\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 163.36, NNZs: 1, Bias: 0.030408, T: 967164, Avg. loss: 0.004415\n",
            "Total training time: 0.10 seconds.\n",
            "Convergence after 17 epochs took 0.10 seconds\n",
            "-- Epoch 1\n",
            "Norm: 151.42, NNZs: 0, Bias: 0.134097, T: 56892, Avg. loss: 0.160494\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 161.98, NNZs: 1, Bias: -0.013941, T: 113784, Avg. loss: 0.075809\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 162.62, NNZs: 1, Bias: 0.115765, T: 170676, Avg. loss: 0.049703\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 162.63, NNZs: 1, Bias: -0.355114, T: 227568, Avg. loss: 0.035500\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 162.63, NNZs: 1, Bias: 0.104947, T: 284460, Avg. loss: 0.026975\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 162.63, NNZs: 1, Bias: -0.007940, T: 341352, Avg. loss: 0.021328\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 162.63, NNZs: 1, Bias: -0.149855, T: 398244, Avg. loss: 0.017293\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 162.63, NNZs: 1, Bias: 0.011882, T: 455136, Avg. loss: 0.014346\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 162.63, NNZs: 1, Bias: -0.063007, T: 512028, Avg. loss: 0.012050\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 162.63, NNZs: 1, Bias: 0.158114, T: 568920, Avg. loss: 0.010254\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 162.63, NNZs: 1, Bias: -0.024439, T: 625812, Avg. loss: 0.008892\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 162.63, NNZs: 1, Bias: -0.049384, T: 682704, Avg. loss: 0.007769\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 162.63, NNZs: 1, Bias: -0.027559, T: 739596, Avg. loss: 0.006726\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 162.63, NNZs: 1, Bias: -0.028529, T: 796488, Avg. loss: 0.006011\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 162.63, NNZs: 1, Bias: 0.039880, T: 853380, Avg. loss: 0.005452\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 162.63, NNZs: 1, Bias: -0.001870, T: 910272, Avg. loss: 0.004886\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 162.63, NNZs: 1, Bias: 0.085437, T: 967164, Avg. loss: 0.004380\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 162.63, NNZs: 1, Bias: 0.025583, T: 1024056, Avg. loss: 0.004056\n",
            "Total training time: 0.09 seconds.\n",
            "Convergence after 18 epochs took 0.09 seconds\n",
            "-- Epoch 1\n",
            "Norm: 152.95, NNZs: 1, Bias: -0.640209, T: 56892, Avg. loss: 0.160236\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 163.15, NNZs: 1, Bias: 0.315400, T: 113784, Avg. loss: 0.075876\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 163.68, NNZs: 1, Bias: 0.879702, T: 170676, Avg. loss: 0.049508\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 163.69, NNZs: 1, Bias: 0.321076, T: 227568, Avg. loss: 0.035423\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 163.69, NNZs: 1, Bias: 0.038231, T: 284460, Avg. loss: 0.026831\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 163.69, NNZs: 1, Bias: -0.057089, T: 341352, Avg. loss: 0.021257\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 163.69, NNZs: 1, Bias: -0.047024, T: 398244, Avg. loss: 0.017192\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 163.69, NNZs: 1, Bias: 0.039989, T: 455136, Avg. loss: 0.014265\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 163.69, NNZs: 1, Bias: -0.063056, T: 512028, Avg. loss: 0.011980\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 163.69, NNZs: 1, Bias: 0.012031, T: 568920, Avg. loss: 0.010175\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 163.69, NNZs: 1, Bias: -0.054139, T: 625812, Avg. loss: 0.008825\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 163.69, NNZs: 1, Bias: 0.005041, T: 682704, Avg. loss: 0.007583\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 163.69, NNZs: 1, Bias: -0.038665, T: 739596, Avg. loss: 0.006698\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 163.69, NNZs: 1, Bias: -0.054619, T: 796488, Avg. loss: 0.005900\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 163.70, NNZs: 1, Bias: -0.009068, T: 853380, Avg. loss: 0.005300\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 163.70, NNZs: 1, Bias: -0.062870, T: 910272, Avg. loss: 0.004733\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 163.70, NNZs: 1, Bias: -0.023009, T: 967164, Avg. loss: 0.004313\n",
            "Total training time: 0.09 seconds.\n",
            "Convergence after 17 epochs took 0.09 seconds\n",
            "-- Epoch 1\n",
            "Norm: 54.28, NNZs: 1, Bias: -0.577110, T: 56892, Avg. loss: 0.169660\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 50.94, NNZs: 1, Bias: -0.155251, T: 113784, Avg. loss: 0.076928\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 40.05, NNZs: 1, Bias: 0.176515, T: 170676, Avg. loss: 0.049689\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 32.45, NNZs: 1, Bias: 0.030875, T: 227568, Avg. loss: 0.035511\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 27.41, NNZs: 1, Bias: -0.159910, T: 284460, Avg. loss: 0.027021\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 23.83, NNZs: 1, Bias: -0.128174, T: 341352, Avg. loss: 0.021340\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 21.13, NNZs: 1, Bias: -0.140842, T: 398244, Avg. loss: 0.017361\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 19.01, NNZs: 1, Bias: 0.035505, T: 455136, Avg. loss: 0.014299\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 17.32, NNZs: 1, Bias: -0.137261, T: 512028, Avg. loss: 0.012116\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 15.92, NNZs: 1, Bias: 0.020035, T: 568920, Avg. loss: 0.010294\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 14.75, NNZs: 1, Bias: -0.118103, T: 625812, Avg. loss: 0.008854\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 13.76, NNZs: 1, Bias: -0.120678, T: 682704, Avg. loss: 0.007670\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 12.90, NNZs: 1, Bias: 0.034330, T: 739596, Avg. loss: 0.006810\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 12.13, NNZs: 1, Bias: -0.082375, T: 796488, Avg. loss: 0.006026\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 11.47, NNZs: 1, Bias: -0.019705, T: 853380, Avg. loss: 0.005324\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 10.90, NNZs: 1, Bias: 0.021027, T: 910272, Avg. loss: 0.004830\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 10.36, NNZs: 1, Bias: -0.085296, T: 967164, Avg. loss: 0.004410\n",
            "Total training time: 0.09 seconds.\n",
            "Convergence after 17 epochs took 0.10 seconds\n",
            "-- Epoch 1\n",
            "Norm: 54.60, NNZs: 1, Bias: -0.166027, T: 56892, Avg. loss: 0.169143\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 50.98, NNZs: 1, Bias: -0.188997, T: 113784, Avg. loss: 0.076693\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 40.02, NNZs: 1, Bias: -0.229787, T: 170676, Avg. loss: 0.049528\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 32.44, NNZs: 1, Bias: -0.020429, T: 227568, Avg. loss: 0.035556\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 27.40, NNZs: 1, Bias: 0.223311, T: 284460, Avg. loss: 0.026934\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 23.83, NNZs: 1, Bias: 0.071724, T: 341352, Avg. loss: 0.021278\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 21.12, NNZs: 1, Bias: 0.305273, T: 398244, Avg. loss: 0.017272\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 19.01, NNZs: 1, Bias: 0.021995, T: 455136, Avg. loss: 0.014372\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 17.31, NNZs: 1, Bias: -0.060872, T: 512028, Avg. loss: 0.012077\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 15.91, NNZs: 1, Bias: -0.039002, T: 568920, Avg. loss: 0.010267\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 14.74, NNZs: 1, Bias: 0.227470, T: 625812, Avg. loss: 0.008856\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 13.74, NNZs: 1, Bias: 0.050609, T: 682704, Avg. loss: 0.007742\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 12.87, NNZs: 1, Bias: -0.028521, T: 739596, Avg. loss: 0.006763\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 12.14, NNZs: 1, Bias: -0.006596, T: 796488, Avg. loss: 0.006048\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 11.46, NNZs: 1, Bias: -0.093922, T: 853380, Avg. loss: 0.005399\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 10.88, NNZs: 1, Bias: 0.038714, T: 910272, Avg. loss: 0.004874\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 10.35, NNZs: 1, Bias: 0.041407, T: 967164, Avg. loss: 0.004454\n",
            "Total training time: 0.10 seconds.\n",
            "Convergence after 17 epochs took 0.10 seconds\n",
            "-- Epoch 1\n",
            "Norm: 54.25, NNZs: 0, Bias: -0.079981, T: 56892, Avg. loss: 0.169586\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 50.85, NNZs: 1, Bias: 0.227355, T: 113784, Avg. loss: 0.076822\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 39.95, NNZs: 1, Bias: 0.271925, T: 170676, Avg. loss: 0.049663\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 32.39, NNZs: 1, Bias: -0.332645, T: 227568, Avg. loss: 0.035550\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 27.40, NNZs: 1, Bias: 0.027191, T: 284460, Avg. loss: 0.027045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 23.78, NNZs: 1, Bias: 0.133560, T: 341352, Avg. loss: 0.021315\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 21.10, NNZs: 1, Bias: 0.157533, T: 398244, Avg. loss: 0.017310\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 18.97, NNZs: 1, Bias: 0.056192, T: 455136, Avg. loss: 0.014346\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 17.28, NNZs: 1, Bias: -0.027698, T: 512028, Avg. loss: 0.012096\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 15.89, NNZs: 1, Bias: 0.062326, T: 568920, Avg. loss: 0.010323\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 14.72, NNZs: 1, Bias: 0.091706, T: 625812, Avg. loss: 0.008866\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 13.73, NNZs: 1, Bias: 0.031809, T: 682704, Avg. loss: 0.007717\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 12.87, NNZs: 1, Bias: 0.126512, T: 739596, Avg. loss: 0.006793\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 12.12, NNZs: 1, Bias: 0.231825, T: 796488, Avg. loss: 0.005987\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 11.45, NNZs: 1, Bias: -0.086114, T: 853380, Avg. loss: 0.005356\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 10.88, NNZs: 1, Bias: -0.000835, T: 910272, Avg. loss: 0.004836\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 10.35, NNZs: 1, Bias: -0.055094, T: 967164, Avg. loss: 0.004408\n",
            "Total training time: 0.11 seconds.\n",
            "Convergence after 17 epochs took 0.11 seconds\n",
            "-- Epoch 1\n",
            "Norm: 54.02, NNZs: 1, Bias: -0.788327, T: 56892, Avg. loss: 0.169766\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 51.26, NNZs: 1, Bias: -0.743129, T: 113784, Avg. loss: 0.076819\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 40.24, NNZs: 1, Bias: -0.179393, T: 170676, Avg. loss: 0.049650\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 32.63, NNZs: 1, Bias: -0.154319, T: 227568, Avg. loss: 0.035511\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 27.57, NNZs: 1, Bias: 0.169829, T: 284460, Avg. loss: 0.026994\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 23.98, NNZs: 1, Bias: -0.043998, T: 341352, Avg. loss: 0.021417\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 21.24, NNZs: 1, Bias: 0.056603, T: 398244, Avg. loss: 0.017290\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 19.14, NNZs: 1, Bias: 0.009550, T: 455136, Avg. loss: 0.014378\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 17.42, NNZs: 1, Bias: -0.064950, T: 512028, Avg. loss: 0.012101\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 16.00, NNZs: 1, Bias: 0.242648, T: 568920, Avg. loss: 0.010284\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 14.82, NNZs: 1, Bias: -0.059430, T: 625812, Avg. loss: 0.008951\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 13.82, NNZs: 1, Bias: -0.078478, T: 682704, Avg. loss: 0.007734\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 12.96, NNZs: 1, Bias: 0.054923, T: 739596, Avg. loss: 0.006829\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 12.20, NNZs: 1, Bias: -0.013343, T: 796488, Avg. loss: 0.006055\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 11.54, NNZs: 1, Bias: -0.067563, T: 853380, Avg. loss: 0.005376\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 10.96, NNZs: 1, Bias: 0.001819, T: 910272, Avg. loss: 0.004862\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 10.41, NNZs: 1, Bias: -0.040841, T: 967164, Avg. loss: 0.004446\n",
            "Total training time: 0.11 seconds.\n",
            "Convergence after 17 epochs took 0.11 seconds\n",
            "-- Epoch 1\n",
            "Norm: 53.87, NNZs: 1, Bias: -1.043382, T: 56892, Avg. loss: 0.169500\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 50.68, NNZs: 1, Bias: 1.078491, T: 113784, Avg. loss: 0.076867\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 39.77, NNZs: 1, Bias: -0.282445, T: 170676, Avg. loss: 0.049590\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 32.26, NNZs: 1, Bias: -0.370065, T: 227568, Avg. loss: 0.035467\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 27.28, NNZs: 1, Bias: -0.028548, T: 284460, Avg. loss: 0.026837\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 23.68, NNZs: 1, Bias: -0.161812, T: 341352, Avg. loss: 0.021172\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 21.01, NNZs: 1, Bias: 0.152140, T: 398244, Avg. loss: 0.017277\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 18.89, NNZs: 1, Bias: -0.016870, T: 455136, Avg. loss: 0.014245\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 17.21, NNZs: 1, Bias: -0.118465, T: 512028, Avg. loss: 0.011992\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 15.81, NNZs: 1, Bias: -0.041906, T: 568920, Avg. loss: 0.010147\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 14.66, NNZs: 1, Bias: 0.027036, T: 625812, Avg. loss: 0.008749\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 13.68, NNZs: 1, Bias: -0.103248, T: 682704, Avg. loss: 0.007598\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 12.81, NNZs: 1, Bias: -0.031942, T: 739596, Avg. loss: 0.006694\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 12.06, NNZs: 1, Bias: -0.031177, T: 796488, Avg. loss: 0.005924\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 11.40, NNZs: 1, Bias: 0.034645, T: 853380, Avg. loss: 0.005233\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 10.82, NNZs: 1, Bias: -0.060708, T: 910272, Avg. loss: 0.004741\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 10.30, NNZs: 1, Bias: 0.072231, T: 967164, Avg. loss: 0.004295\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 17 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 6.78, NNZs: 1, Bias: 11.279136, T: 56892, Avg. loss: 17.672216\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 11.50, NNZs: 1, Bias: -6.887880, T: 113784, Avg. loss: 8.362249\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 7.18, NNZs: 1, Bias: -0.000601, T: 170676, Avg. loss: 5.378590\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.50, NNZs: 1, Bias: -3.858923, T: 227568, Avg. loss: 3.929034\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 4.87, NNZs: 1, Bias: -0.002299, T: 284460, Avg. loss: 3.067532\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.23, NNZs: 1, Bias: -0.000492, T: 341352, Avg. loss: 2.482678\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.67, NNZs: 1, Bias: -2.324078, T: 398244, Avg. loss: 2.061110\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 2.99, NNZs: 1, Bias: 0.002561, T: 455136, Avg. loss: 1.770255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 0.87, NNZs: 1, Bias: -3.675726, T: 512028, Avg. loss: 1.505459\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 3.48, NNZs: 1, Bias: 0.003197, T: 568920, Avg. loss: 1.346514\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 0.52, NNZs: 1, Bias: 1.524179, T: 625812, Avg. loss: 1.198154\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 2.22, NNZs: 1, Bias: -1.396816, T: 682704, Avg. loss: 1.056976\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.003865, T: 739596, Avg. loss: 0.953350\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.004515, T: 796488, Avg. loss: 0.885348\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 1.93, NNZs: 1, Bias: -1.124669, T: 853380, Avg. loss: 0.776470\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.005389, T: 910272, Avg. loss: 0.734311\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 0.03, NNZs: 1, Bias: 0.005816, T: 967164, Avg. loss: 0.673069\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 0.29, NNZs: 1, Bias: -0.940984, T: 1024056, Avg. loss: 0.627474\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.006277, T: 1080948, Avg. loss: 0.581921\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 0.10, NNZs: 1, Bias: 0.006461, T: 1137840, Avg. loss: 0.542833\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 1.81, NNZs: 1, Bias: 0.006736, T: 1194732, Avg. loss: 0.509084\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 0.36, NNZs: 1, Bias: 0.786224, T: 1251624, Avg. loss: 0.471853\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.753192, T: 1308516, Avg. loss: 0.440769\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.006792, T: 1365408, Avg. loss: 0.405112\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 0.67, NNZs: 1, Bias: -0.680816, T: 1422300, Avg. loss: 0.390401\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.007071, T: 1479192, Avg. loss: 0.370563\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 0.35, NNZs: 1, Bias: 0.645050, T: 1536084, Avg. loss: 0.347832\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 1.43, NNZs: 1, Bias: -0.608232, T: 1592976, Avg. loss: 0.322673\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007369, T: 1649868, Avg. loss: 0.309104\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 2.01, NNZs: 1, Bias: 0.582678, T: 1706760, Avg. loss: 0.305555\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 0.87, NNZs: 1, Bias: 0.007580, T: 1763652, Avg. loss: 0.281401\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.007640, T: 1820544, Avg. loss: 0.263293\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.007716, T: 1877436, Avg. loss: 0.246188\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 0.55, NNZs: 1, Bias: 0.007764, T: 1934328, Avg. loss: 0.241454\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 0.24, NNZs: 1, Bias: 0.502168, T: 1991220, Avg. loss: 0.229452\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.007888, T: 2048112, Avg. loss: 0.223695\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007883, T: 2105004, Avg. loss: 0.213844\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 1.24, NNZs: 1, Bias: 0.007881, T: 2161896, Avg. loss: 0.203834\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.007952, T: 2218788, Avg. loss: 0.187155\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 0.84, NNZs: 1, Bias: 0.008018, T: 2275680, Avg. loss: 0.186262\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 0.54, NNZs: 1, Bias: -0.414967, T: 2332572, Avg. loss: 0.180216\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.008113, T: 2389464, Avg. loss: 0.168191\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 1.72, NNZs: 1, Bias: 0.008172, T: 2446356, Avg. loss: 0.166636\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008192, T: 2503248, Avg. loss: 0.159404\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008277, T: 2560140, Avg. loss: 0.149380\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 1.49, NNZs: 1, Bias: 0.008307, T: 2617032, Avg. loss: 0.143520\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 0.48, NNZs: 1, Bias: 0.008371, T: 2673924, Avg. loss: 0.140980\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 0.61, NNZs: 1, Bias: 0.008414, T: 2730816, Avg. loss: 0.132736\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.008473, T: 2787708, Avg. loss: 0.129364\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008517, T: 2844600, Avg. loss: 0.121790\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008520, T: 2901492, Avg. loss: 0.120136\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 1.36, NNZs: 1, Bias: 0.343055, T: 2958384, Avg. loss: 0.115883\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.008607, T: 3015276, Avg. loss: 0.110498\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 0.85, NNZs: 1, Bias: 0.330825, T: 3072168, Avg. loss: 0.108808\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 1.10, NNZs: 1, Bias: -0.624106, T: 3129060, Avg. loss: 0.104791\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 0.88, NNZs: 1, Bias: 0.319457, T: 3185952, Avg. loss: 0.100120\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.008701, T: 3242844, Avg. loss: 0.097714\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.008737, T: 3299736, Avg. loss: 0.097888\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 1.22, NNZs: 1, Bias: -0.286417, T: 3356628, Avg. loss: 0.091838\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.008745, T: 3413520, Avg. loss: 0.090003\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008778, T: 3470412, Avg. loss: 0.088670\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 1.09, NNZs: 1, Bias: -0.272174, T: 3527304, Avg. loss: 0.083234\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 1.17, NNZs: 1, Bias: 0.008834, T: 3584196, Avg. loss: 0.078428\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008856, T: 3641088, Avg. loss: 0.077666\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 0.60, NNZs: 1, Bias: 0.008887, T: 3697980, Avg. loss: 0.075459\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008913, T: 3754872, Avg. loss: 0.075328\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008945, T: 3811764, Avg. loss: 0.070106\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.008967, T: 3868656, Avg. loss: 0.067893\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.009001, T: 3925548, Avg. loss: 0.068193\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.009017, T: 3982440, Avg. loss: 0.064926\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 1.25, NNZs: 1, Bias: -0.236598, T: 4039332, Avg. loss: 0.061744\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.233196, T: 4096224, Avg. loss: 0.061366\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 0.77, NNZs: 1, Bias: 0.248039, T: 4153116, Avg. loss: 0.061003\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009098, T: 4210008, Avg. loss: 0.056068\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 0.82, NNZs: 1, Bias: 0.009114, T: 4266900, Avg. loss: 0.054680\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.009138, T: 4323792, Avg. loss: 0.054466\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 0.80, NNZs: 1, Bias: -0.217474, T: 4380684, Avg. loss: 0.051865\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.009187, T: 4437576, Avg. loss: 0.051934\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009215, T: 4494468, Avg. loss: 0.051551\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 1.32, NNZs: 1, Bias: 0.009226, T: 4551360, Avg. loss: 0.048466\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.009231, T: 4608252, Avg. loss: 0.048046\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 0.71, NNZs: 1, Bias: 0.009259, T: 4665144, Avg. loss: 0.047654\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.009269, T: 4722036, Avg. loss: 0.046260\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.009284, T: 4778928, Avg. loss: 0.044670\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.009291, T: 4835820, Avg. loss: 0.041876\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 0.97, NNZs: 1, Bias: -0.193767, T: 4892712, Avg. loss: 0.042262\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 0.90, NNZs: 1, Bias: 0.210073, T: 4949604, Avg. loss: 0.041242\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 0.83, NNZs: 1, Bias: 0.009334, T: 5006496, Avg. loss: 0.040777\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.009347, T: 5063388, Avg. loss: 0.039261\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.009365, T: 5120280, Avg. loss: 0.038713\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 0.81, NNZs: 1, Bias: 0.009380, T: 5177172, Avg. loss: 0.037009\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.009401, T: 5234064, Avg. loss: 0.035268\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.009414, T: 5290956, Avg. loss: 0.037357\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 1.06, NNZs: 1, Bias: -0.176471, T: 5347848, Avg. loss: 0.034739\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.009435, T: 5404740, Avg. loss: 0.033551\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 1.18, NNZs: 1, Bias: -0.172592, T: 5461632, Avg. loss: 0.033912\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.009462, T: 5518524, Avg. loss: 0.032084\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009461, T: 5575416, Avg. loss: 0.031556\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.009470, T: 5632308, Avg. loss: 0.031259\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009480, T: 5689200, Avg. loss: 0.030851\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009493, T: 5746092, Avg. loss: 0.030050\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.009502, T: 5802984, Avg. loss: 0.029552\n",
            "Total training time: 0.47 seconds.\n",
            "Convergence after 102 epochs took 0.47 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 4.49, NNZs: 1, Bias: 0.021401, T: 56892, Avg. loss: 17.685170\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 4.09, NNZs: 1, Bias: -6.873276, T: 113784, Avg. loss: 8.287692\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.54, NNZs: 1, Bias: -4.935620, T: 170676, Avg. loss: 5.336105\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.59, NNZs: 1, Bias: 0.004218, T: 227568, Avg. loss: 3.916764\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001492, T: 284460, Avg. loss: 3.062649\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.62, NNZs: 1, Bias: -2.681654, T: 341352, Avg. loss: 2.499087\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.00, NNZs: 1, Bias: 2.328938, T: 398244, Avg. loss: 2.099546\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.30, NNZs: 1, Bias: 2.058805, T: 455136, Avg. loss: 1.770248\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 3.69, NNZs: 1, Bias: 1.843682, T: 512028, Avg. loss: 1.553646\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.14, NNZs: 1, Bias: 1.670345, T: 568920, Avg. loss: 1.372743\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 0.10, NNZs: 1, Bias: 1.525924, T: 625812, Avg. loss: 1.208915\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 2.73, NNZs: 1, Bias: 0.004799, T: 682704, Avg. loss: 1.089891\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 0.50, NNZs: 1, Bias: 0.004639, T: 739596, Avg. loss: 0.979283\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1.08, NNZs: 1, Bias: -2.411359, T: 796488, Avg. loss: 0.882817\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 1.21, NNZs: 1, Bias: 0.003798, T: 853380, Avg. loss: 0.817603\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 1.66, NNZs: 1, Bias: 0.004000, T: 910272, Avg. loss: 0.745233\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 1.46, NNZs: 1, Bias: 1.005399, T: 967164, Avg. loss: 0.693038\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 0.04, NNZs: 1, Bias: 0.951624, T: 1024056, Avg. loss: 0.629146\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 2.09, NNZs: 1, Bias: 0.004592, T: 1080948, Avg. loss: 0.579099\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 1.41, NNZs: 1, Bias: 0.004985, T: 1137840, Avg. loss: 0.554216\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 1.42, NNZs: 1, Bias: -0.810447, T: 1194732, Avg. loss: 0.508034\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.005280, T: 1251624, Avg. loss: 0.478651\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 0.87, NNZs: 1, Bias: 0.005396, T: 1308516, Avg. loss: 0.443942\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 0.71, NNZs: 1, Bias: -0.710135, T: 1365408, Avg. loss: 0.425651\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 0.68, NNZs: 1, Bias: 1.381119, T: 1422300, Avg. loss: 0.405694\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 0.88, NNZs: 1, Bias: -0.656184, T: 1479192, Avg. loss: 0.369059\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 0.60, NNZs: 1, Bias: 0.643656, T: 1536084, Avg. loss: 0.357708\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005824, T: 1592976, Avg. loss: 0.331972\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006049, T: 1649868, Avg. loss: 0.322573\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.006249, T: 1706760, Avg. loss: 0.305174\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 1.59, NNZs: 1, Bias: -0.550701, T: 1763652, Avg. loss: 0.283652\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.006466, T: 1820544, Avg. loss: 0.274116\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.006517, T: 1877436, Avg. loss: 0.257483\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.006566, T: 1934328, Avg. loss: 0.248455\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.006660, T: 1991220, Avg. loss: 0.238670\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 0.40, NNZs: 1, Bias: -0.474096, T: 2048112, Avg. loss: 0.228560\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 1.31, NNZs: 1, Bias: 0.006688, T: 2105004, Avg. loss: 0.219295\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006767, T: 2161896, Avg. loss: 0.207409\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.006849, T: 2218788, Avg. loss: 0.199893\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 1.25, NNZs: 1, Bias: 0.006960, T: 2275680, Avg. loss: 0.193415\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.006976, T: 2332572, Avg. loss: 0.188558\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 1.24, NNZs: 1, Bias: 0.833126, T: 2389464, Avg. loss: 0.176212\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.007092, T: 2446356, Avg. loss: 0.166769\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 0.53, NNZs: 1, Bias: 0.007172, T: 2503248, Avg. loss: 0.160919\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007205, T: 2560140, Avg. loss: 0.159321\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.007238, T: 2617032, Avg. loss: 0.145408\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.007353, T: 2673924, Avg. loss: 0.145551\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.007401, T: 2730816, Avg. loss: 0.134700\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.007450, T: 2787708, Avg. loss: 0.133218\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 1.31, NNZs: 1, Bias: -0.340226, T: 2844600, Avg. loss: 0.129615\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.007422, T: 2901492, Avg. loss: 0.125477\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 1.26, NNZs: 1, Bias: 0.341915, T: 2958384, Avg. loss: 0.122846\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.007523, T: 3015276, Avg. loss: 0.118077\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.314625, T: 3072168, Avg. loss: 0.111834\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 0.87, NNZs: 1, Bias: 0.007561, T: 3129060, Avg. loss: 0.110558\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.007597, T: 3185952, Avg. loss: 0.101740\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 1.13, NNZs: 1, Bias: 0.312998, T: 3242844, Avg. loss: 0.101062\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.007671, T: 3299736, Avg. loss: 0.098022\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 0.95, NNZs: 1, Bias: -0.287430, T: 3356628, Avg. loss: 0.094198\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.007710, T: 3413520, Avg. loss: 0.093683\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.293303, T: 3470412, Avg. loss: 0.089441\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 1.27, NNZs: 1, Bias: 0.288744, T: 3527304, Avg. loss: 0.087168\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.007791, T: 3584196, Avg. loss: 0.084431\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.007815, T: 3641088, Avg. loss: 0.083749\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 0.93, NNZs: 1, Bias: 0.007851, T: 3697980, Avg. loss: 0.079323\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 0.68, NNZs: 1, Bias: 0.007853, T: 3754872, Avg. loss: 0.079050\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007873, T: 3811764, Avg. loss: 0.075305\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 0.93, NNZs: 1, Bias: -0.248508, T: 3868656, Avg. loss: 0.074504\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 0.58, NNZs: 1, Bias: -0.244786, T: 3925548, Avg. loss: 0.070071\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.007942, T: 3982440, Avg. loss: 0.069584\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 0.78, NNZs: 1, Bias: 0.007966, T: 4039332, Avg. loss: 0.066422\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 1.31, NNZs: 1, Bias: 0.007973, T: 4096224, Avg. loss: 0.061158\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008003, T: 4153116, Avg. loss: 0.062720\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.007997, T: 4210008, Avg. loss: 0.062019\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 0.91, NNZs: 1, Bias: 0.008022, T: 4266900, Avg. loss: 0.057824\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008032, T: 4323792, Avg. loss: 0.058615\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.008047, T: 4380684, Avg. loss: 0.055798\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 1.22, NNZs: 1, Bias: 0.231828, T: 4437576, Avg. loss: 0.056134\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008093, T: 4494468, Avg. loss: 0.054277\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008103, T: 4551360, Avg. loss: 0.052584\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.008111, T: 4608252, Avg. loss: 0.051303\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.008139, T: 4665144, Avg. loss: 0.049134\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 1.34, NNZs: 1, Bias: 0.008153, T: 4722036, Avg. loss: 0.048232\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008168, T: 4778928, Avg. loss: 0.046980\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.008203, T: 4835820, Avg. loss: 0.047073\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.008212, T: 4892712, Avg. loss: 0.044311\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008223, T: 4949604, Avg. loss: 0.044442\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008228, T: 5006496, Avg. loss: 0.041245\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008222, T: 5063388, Avg. loss: 0.041608\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.008237, T: 5120280, Avg. loss: 0.041348\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.008247, T: 5177172, Avg. loss: 0.040673\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 1.17, NNZs: 1, Bias: 0.198169, T: 5234064, Avg. loss: 0.038707\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008278, T: 5290956, Avg. loss: 0.037670\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.008282, T: 5347848, Avg. loss: 0.037208\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008294, T: 5404740, Avg. loss: 0.035630\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.008304, T: 5461632, Avg. loss: 0.034470\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008307, T: 5518524, Avg. loss: 0.035104\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008321, T: 5575416, Avg. loss: 0.034121\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008323, T: 5632308, Avg. loss: 0.033195\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.008341, T: 5689200, Avg. loss: 0.032073\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008355, T: 5746092, Avg. loss: 0.031051\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008362, T: 5802984, Avg. loss: 0.030890\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 103\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.008375, T: 5859876, Avg. loss: 0.030453\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 104\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008387, T: 5916768, Avg. loss: 0.029784\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 105\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.008392, T: 5973660, Avg. loss: 0.029573\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 106\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.008402, T: 6030552, Avg. loss: 0.028093\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 107\n",
            "Norm: 0.89, NNZs: 1, Bias: 0.008402, T: 6087444, Avg. loss: 0.027935\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 108\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008412, T: 6144336, Avg. loss: 0.027436\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 109\n",
            "Norm: 0.89, NNZs: 1, Bias: 0.008413, T: 6201228, Avg. loss: 0.027362\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 110\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.008417, T: 6258120, Avg. loss: 0.026324\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 111\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.008412, T: 6315012, Avg. loss: 0.025974\n",
            "Total training time: 0.54 seconds.\n",
            "-- Epoch 112\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.164580, T: 6371904, Avg. loss: 0.024959\n",
            "Total training time: 0.54 seconds.\n",
            "-- Epoch 113\n",
            "Norm: 1.04, NNZs: 1, Bias: -0.146370, T: 6428796, Avg. loss: 0.024488\n",
            "Total training time: 0.54 seconds.\n",
            "-- Epoch 114\n",
            "Norm: 1.03, NNZs: 1, Bias: -0.145012, T: 6485688, Avg. loss: 0.024362\n",
            "Total training time: 0.55 seconds.\n",
            "-- Epoch 115\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008428, T: 6542580, Avg. loss: 0.024032\n",
            "Total training time: 0.55 seconds.\n",
            "-- Epoch 116\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008428, T: 6599472, Avg. loss: 0.023718\n",
            "Total training time: 0.56 seconds.\n",
            "-- Epoch 117\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.008429, T: 6656364, Avg. loss: 0.023208\n",
            "Total training time: 0.56 seconds.\n",
            "Convergence after 117 epochs took 0.57 seconds\n",
            "-- Epoch 1\n",
            "Norm: 6.76, NNZs: 1, Bias: -0.092818, T: 56892, Avg. loss: 17.682236\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.47, NNZs: 1, Bias: 6.851743, T: 113784, Avg. loss: 8.433413\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.73, NNZs: 1, Bias: -0.005218, T: 170676, Avg. loss: 5.398687\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 3.71, NNZs: 1, Bias: -3.857450, T: 227568, Avg. loss: 3.921372\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 2.02, NNZs: 1, Bias: -0.001553, T: 284460, Avg. loss: 3.074428\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.44, NNZs: 1, Bias: 0.003879, T: 341352, Avg. loss: 2.478765\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.83, NNZs: 1, Bias: 0.002759, T: 398244, Avg. loss: 2.088771\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 2.48, NNZs: 1, Bias: 0.001602, T: 455136, Avg. loss: 1.764173\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.74, NNZs: 1, Bias: -1.836801, T: 512028, Avg. loss: 1.526525\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 0.81, NNZs: 1, Bias: 0.003383, T: 568920, Avg. loss: 1.366812\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.80, NNZs: 1, Bias: 0.004485, T: 625812, Avg. loss: 1.190133\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.004344, T: 682704, Avg. loss: 1.075588\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 2.60, NNZs: 1, Bias: 0.003950, T: 739596, Avg. loss: 0.991796\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.004666, T: 796488, Avg. loss: 0.877196\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 0.21, NNZs: 1, Bias: -1.125152, T: 853380, Avg. loss: 0.787163\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 1.86, NNZs: 1, Bias: 0.005177, T: 910272, Avg. loss: 0.727613\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 2.50, NNZs: 1, Bias: 1.006446, T: 967164, Avg. loss: 0.665862\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 2.31, NNZs: 1, Bias: -0.941786, T: 1024056, Avg. loss: 0.616931\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.99, NNZs: 1, Bias: 0.005739, T: 1080948, Avg. loss: 0.572292\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.005665, T: 1137840, Avg. loss: 0.542843\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 0.29, NNZs: 1, Bias: 0.005758, T: 1194732, Avg. loss: 0.495303\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 0.28, NNZs: 1, Bias: 0.006106, T: 1251624, Avg. loss: 0.462216\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.752369, T: 1308516, Avg. loss: 0.439809\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 0.79, NNZs: 1, Bias: 1.437847, T: 1365408, Avg. loss: 0.411242\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.006242, T: 1422300, Avg. loss: 0.385977\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.006200, T: 1479192, Avg. loss: 0.374846\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 1.26, NNZs: 1, Bias: 0.006516, T: 1536084, Avg. loss: 0.334927\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 0.26, NNZs: 1, Bias: 0.006641, T: 1592976, Avg. loss: 0.330014\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.006766, T: 1649868, Avg. loss: 0.304580\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 0.35, NNZs: 1, Bias: 0.006811, T: 1706760, Avg. loss: 0.294142\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 1.65, NNZs: 1, Bias: 0.006964, T: 1763652, Avg. loss: 0.273500\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.007201, T: 1820544, Avg. loss: 0.268558\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 0.19, NNZs: 1, Bias: 0.531059, T: 1877436, Avg. loss: 0.249958\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 1.31, NNZs: 1, Bias: -0.501233, T: 1934328, Avg. loss: 0.241079\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 0.19, NNZs: 1, Bias: 0.007503, T: 1991220, Avg. loss: 0.235501\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 1.85, NNZs: 1, Bias: 0.007632, T: 2048112, Avg. loss: 0.221302\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.007745, T: 2105004, Avg. loss: 0.204856\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.007797, T: 2161896, Avg. loss: 0.199992\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.007899, T: 2218788, Avg. loss: 0.188414\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 0.93, NNZs: 1, Bias: -0.858806, T: 2275680, Avg. loss: 0.182453\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.008058, T: 2332572, Avg. loss: 0.175296\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008094, T: 2389464, Avg. loss: 0.165003\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 0.48, NNZs: 1, Bias: -0.395386, T: 2446356, Avg. loss: 0.164291\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 0.46, NNZs: 1, Bias: -0.386197, T: 2503248, Avg. loss: 0.156901\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 0.76, NNZs: 1, Bias: 0.008400, T: 2560140, Avg. loss: 0.154186\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.008436, T: 2617032, Avg. loss: 0.144238\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008444, T: 2673924, Avg. loss: 0.139454\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 1.51, NNZs: 1, Bias: 0.008530, T: 2730816, Avg. loss: 0.132623\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 1.44, NNZs: 1, Bias: 0.008606, T: 2787708, Avg. loss: 0.131577\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 0.87, NNZs: 1, Bias: 0.008603, T: 2844600, Avg. loss: 0.126700\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008649, T: 2901492, Avg. loss: 0.120376\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.008645, T: 2958384, Avg. loss: 0.116582\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 0.92, NNZs: 1, Bias: -0.319544, T: 3015276, Avg. loss: 0.114588\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 1.55, NNZs: 1, Bias: 0.008683, T: 3072168, Avg. loss: 0.108434\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.325124, T: 3129060, Avg. loss: 0.106610\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 1.13, NNZs: 1, Bias: 0.319569, T: 3185952, Avg. loss: 0.099770\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008834, T: 3242844, Avg. loss: 0.097342\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.008890, T: 3299736, Avg. loss: 0.093360\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 1.23, NNZs: 1, Bias: 0.008928, T: 3356628, Avg. loss: 0.092040\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 0.98, NNZs: 1, Bias: -0.281298, T: 3413520, Avg. loss: 0.087095\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.008985, T: 3470412, Avg. loss: 0.086655\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.290013, T: 3527304, Avg. loss: 0.085781\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.009063, T: 3584196, Avg. loss: 0.078488\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 1.22, NNZs: 1, Bias: 0.281368, T: 3641088, Avg. loss: 0.078791\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009120, T: 3697980, Avg. loss: 0.074884\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.009153, T: 3754872, Avg. loss: 0.071634\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.269390, T: 3811764, Avg. loss: 0.069454\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.009220, T: 3868656, Avg. loss: 0.069525\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 0.95, NNZs: 1, Bias: -0.496174, T: 3925548, Avg. loss: 0.068453\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.009259, T: 3982440, Avg. loss: 0.065317\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.009289, T: 4039332, Avg. loss: 0.063188\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 1.23, NNZs: 1, Bias: 0.251568, T: 4096224, Avg. loss: 0.062939\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 0.76, NNZs: 1, Bias: -0.229636, T: 4153116, Avg. loss: 0.059808\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009348, T: 4210008, Avg. loss: 0.058722\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009379, T: 4266900, Avg. loss: 0.057957\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.009409, T: 4323792, Avg. loss: 0.055514\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.236063, T: 4380684, Avg. loss: 0.050124\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 1.23, NNZs: 1, Bias: 0.233198, T: 4437576, Avg. loss: 0.051339\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 1.05, NNZs: 1, Bias: 0.009461, T: 4494468, Avg. loss: 0.052186\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009480, T: 4551360, Avg. loss: 0.050388\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 0.89, NNZs: 1, Bias: 0.009501, T: 4608252, Avg. loss: 0.049646\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 1.15, NNZs: 1, Bias: -0.203393, T: 4665144, Avg. loss: 0.047023\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 1.06, NNZs: 1, Bias: 0.009542, T: 4722036, Avg. loss: 0.045193\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.009571, T: 4778928, Avg. loss: 0.045631\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009602, T: 4835820, Avg. loss: 0.043894\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009633, T: 4892712, Avg. loss: 0.044027\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 0.81, NNZs: 1, Bias: 0.009657, T: 4949604, Avg. loss: 0.042409\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.009675, T: 5006496, Avg. loss: 0.040396\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 0.83, NNZs: 1, Bias: 0.009695, T: 5063388, Avg. loss: 0.038882\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 1.35, NNZs: 1, Bias: 0.009708, T: 5120280, Avg. loss: 0.038471\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 1.31, NNZs: 1, Bias: 0.009719, T: 5177172, Avg. loss: 0.038503\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 0.70, NNZs: 1, Bias: -0.180176, T: 5234064, Avg. loss: 0.036982\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.009752, T: 5290956, Avg. loss: 0.035542\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.009772, T: 5347848, Avg. loss: 0.035790\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 0.83, NNZs: 1, Bias: 0.009788, T: 5404740, Avg. loss: 0.033838\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 0.90, NNZs: 1, Bias: 0.009804, T: 5461632, Avg. loss: 0.033742\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.009816, T: 5518524, Avg. loss: 0.033235\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009824, T: 5575416, Avg. loss: 0.032349\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.009836, T: 5632308, Avg. loss: 0.031454\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009847, T: 5689200, Avg. loss: 0.031143\n",
            "Total training time: 0.46 seconds.\n",
            "Convergence after 100 epochs took 0.46 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.36, NNZs: 1, Bias: -11.277726, T: 56892, Avg. loss: 17.725316\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 2.90, NNZs: 1, Bias: 0.002722, T: 113784, Avg. loss: 8.251896\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 4.82, NNZs: 1, Bias: 0.000938, T: 170676, Avg. loss: 5.370683\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.56, NNZs: 1, Bias: -3.853030, T: 227568, Avg. loss: 3.912433\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.25, NNZs: 1, Bias: 3.168042, T: 284460, Avg. loss: 3.071912\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.006122, T: 341352, Avg. loss: 2.485628\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 2.59, NNZs: 1, Bias: 0.003905, T: 398244, Avg. loss: 2.098525\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: 2.059250, T: 455136, Avg. loss: 1.740673\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 3.15, NNZs: 1, Bias: 0.005737, T: 512028, Avg. loss: 1.548051\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 0.40, NNZs: 1, Bias: 0.005510, T: 568920, Avg. loss: 1.368086\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.73, NNZs: 1, Bias: 1.526169, T: 625812, Avg. loss: 1.214922\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 2.36, NNZs: 1, Bias: 0.006212, T: 682704, Avg. loss: 1.080969\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006238, T: 739596, Avg. loss: 0.993052\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1.67, NNZs: 1, Bias: -1.201365, T: 796488, Avg. loss: 0.905671\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006793, T: 853380, Avg. loss: 0.829846\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 2.71, NNZs: 1, Bias: -1.055167, T: 910272, Avg. loss: 0.750534\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.006539, T: 967164, Avg. loss: 0.697968\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.953953, T: 1024056, Avg. loss: 0.634665\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 2.21, NNZs: 1, Bias: -0.892353, T: 1080948, Avg. loss: 0.604326\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006492, T: 1137840, Avg. loss: 0.553475\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.006577, T: 1194732, Avg. loss: 0.506648\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 1.31, NNZs: 1, Bias: 0.785865, T: 1251624, Avg. loss: 0.481627\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 0.84, NNZs: 1, Bias: -0.739647, T: 1308516, Avg. loss: 0.450088\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 0.06, NNZs: 1, Bias: 0.006760, T: 1365408, Avg. loss: 0.429898\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.006644, T: 1422300, Avg. loss: 0.413268\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.006650, T: 1479192, Avg. loss: 0.378164\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006778, T: 1536084, Avg. loss: 0.361423\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 1.36, NNZs: 1, Bias: 0.622384, T: 1592976, Avg. loss: 0.338200\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 1.78, NNZs: 1, Bias: 0.006824, T: 1649868, Avg. loss: 0.327877\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.006815, T: 1706760, Avg. loss: 0.298902\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 2.12, NNZs: 1, Bias: 0.006931, T: 1763652, Avg. loss: 0.289649\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.006965, T: 1820544, Avg. loss: 0.266238\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 1.71, NNZs: 1, Bias: 0.530775, T: 1877436, Avg. loss: 0.257805\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.006955, T: 1934328, Avg. loss: 0.252429\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.006983, T: 1991220, Avg. loss: 0.236860\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 1.07, NNZs: 1, Bias: -0.473910, T: 2048112, Avg. loss: 0.225541\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 1.14, NNZs: 1, Bias: -0.461094, T: 2105004, Avg. loss: 0.214748\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.007010, T: 2161896, Avg. loss: 0.202832\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.451431, T: 2218788, Avg. loss: 0.197365\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.007154, T: 2275680, Avg. loss: 0.186263\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 1.24, NNZs: 1, Bias: 0.007237, T: 2332572, Avg. loss: 0.178351\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.007245, T: 2389464, Avg. loss: 0.171485\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.410777, T: 2446356, Avg. loss: 0.176889\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.007262, T: 2503248, Avg. loss: 0.161609\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.007263, T: 2560140, Avg. loss: 0.154475\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.007303, T: 2617032, Avg. loss: 0.152750\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 0.89, NNZs: 1, Bias: 0.007332, T: 2673924, Avg. loss: 0.146581\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 1.15, NNZs: 1, Bias: 0.007403, T: 2730816, Avg. loss: 0.140802\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.007451, T: 2787708, Avg. loss: 0.133015\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 1.16, NNZs: 1, Bias: -0.340209, T: 2844600, Avg. loss: 0.130139\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.007474, T: 2901492, Avg. loss: 0.125939\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.007520, T: 2958384, Avg. loss: 0.118445\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.007534, T: 3015276, Avg. loss: 0.115632\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.007549, T: 3072168, Avg. loss: 0.114689\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.007574, T: 3129060, Avg. loss: 0.109000\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.007593, T: 3185952, Avg. loss: 0.104342\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.007625, T: 3242844, Avg. loss: 0.101197\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007654, T: 3299736, Avg. loss: 0.098800\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.007685, T: 3356628, Avg. loss: 0.096218\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.297970, T: 3413520, Avg. loss: 0.094518\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.007757, T: 3470412, Avg. loss: 0.088680\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 0.87, NNZs: 1, Bias: 0.007773, T: 3527304, Avg. loss: 0.088378\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.007807, T: 3584196, Avg. loss: 0.084083\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.007835, T: 3641088, Avg. loss: 0.085054\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.007869, T: 3697980, Avg. loss: 0.077991\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 1.16, NNZs: 1, Bias: 0.007901, T: 3754872, Avg. loss: 0.074627\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 1.39, NNZs: 1, Bias: 0.007908, T: 3811764, Avg. loss: 0.073758\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 0.84, NNZs: 1, Bias: 0.007909, T: 3868656, Avg. loss: 0.072474\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.007948, T: 3925548, Avg. loss: 0.069732\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.007977, T: 3982440, Avg. loss: 0.068766\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.008004, T: 4039332, Avg. loss: 0.067244\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 1.26, NNZs: 1, Bias: 0.008010, T: 4096224, Avg. loss: 0.062309\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008047, T: 4153116, Avg. loss: 0.062062\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008078, T: 4210008, Avg. loss: 0.061794\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 0.84, NNZs: 1, Bias: 0.008102, T: 4266900, Avg. loss: 0.060003\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.008121, T: 4323792, Avg. loss: 0.058593\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008148, T: 4380684, Avg. loss: 0.056857\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008167, T: 4437576, Avg. loss: 0.056260\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.008187, T: 4494468, Avg. loss: 0.052787\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.008196, T: 4551360, Avg. loss: 0.051414\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 1.09, NNZs: 1, Bias: 0.223734, T: 4608252, Avg. loss: 0.050489\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 0.89, NNZs: 1, Bias: 0.008221, T: 4665144, Avg. loss: 0.049225\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.008229, T: 4722036, Avg. loss: 0.047919\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008254, T: 4778928, Avg. loss: 0.048320\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.402622, T: 4835820, Avg. loss: 0.047265\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.008288, T: 4892712, Avg. loss: 0.045256\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008309, T: 4949604, Avg. loss: 0.043842\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.008333, T: 5006496, Avg. loss: 0.042467\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008353, T: 5063388, Avg. loss: 0.041253\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008366, T: 5120280, Avg. loss: 0.040885\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.008383, T: 5177172, Avg. loss: 0.039093\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008400, T: 5234064, Avg. loss: 0.038749\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008418, T: 5290956, Avg. loss: 0.037949\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 0.85, NNZs: 1, Bias: -0.177468, T: 5347848, Avg. loss: 0.037433\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.008441, T: 5404740, Avg. loss: 0.036580\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008450, T: 5461632, Avg. loss: 0.035062\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 0.87, NNZs: 1, Bias: 0.008460, T: 5518524, Avg. loss: 0.034156\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 0.66, NNZs: 1, Bias: 0.008470, T: 5575416, Avg. loss: 0.033237\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008483, T: 5632308, Avg. loss: 0.032937\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 0.96, NNZs: 1, Bias: -0.341112, T: 5689200, Avg. loss: 0.031928\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008506, T: 5746092, Avg. loss: 0.031179\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.008512, T: 5802984, Avg. loss: 0.029616\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 103\n",
            "Norm: 1.19, NNZs: 1, Bias: 0.178256, T: 5859876, Avg. loss: 0.029666\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 104\n",
            "Norm: 1.14, NNZs: 1, Bias: 0.008530, T: 5916768, Avg. loss: 0.029001\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 105\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008538, T: 5973660, Avg. loss: 0.028482\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 106\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.008548, T: 6030552, Avg. loss: 0.028202\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 107\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008559, T: 6087444, Avg. loss: 0.027689\n",
            "Total training time: 0.51 seconds.\n",
            "Convergence after 107 epochs took 0.51 seconds\n",
            "-- Epoch 1\n",
            "Norm: 22.79, NNZs: 1, Bias: -0.028415, T: 56892, Avg. loss: 17.785446\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.013004, T: 113784, Avg. loss: 8.282711\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 8.56, NNZs: 1, Bias: 0.010811, T: 170676, Avg. loss: 5.331674\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.47, NNZs: 1, Bias: 0.005078, T: 227568, Avg. loss: 3.880806\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.33, NNZs: 1, Bias: 3.171337, T: 284460, Avg. loss: 3.029085\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 4.00, NNZs: 1, Bias: 0.008073, T: 341352, Avg. loss: 2.459625\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 3.20, NNZs: 1, Bias: 0.006350, T: 398244, Avg. loss: 2.089827\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 0.95, NNZs: 1, Bias: 0.007321, T: 455136, Avg. loss: 1.738464\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 2.62, NNZs: 1, Bias: 1.846011, T: 512028, Avg. loss: 1.501731\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 0.89, NNZs: 1, Bias: 0.006320, T: 568920, Avg. loss: 1.333174\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 2.66, NNZs: 1, Bias: 0.005986, T: 625812, Avg. loss: 1.186923\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 0.01, NNZs: 1, Bias: 1.406433, T: 682704, Avg. loss: 1.052741\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 2.49, NNZs: 1, Bias: 1.302176, T: 739596, Avg. loss: 0.960558\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 0.79, NNZs: 1, Bias: 0.005760, T: 796488, Avg. loss: 0.869209\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 1.63, NNZs: 1, Bias: 1.136093, T: 853380, Avg. loss: 0.795655\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 0.48, NNZs: 1, Bias: 0.006098, T: 910272, Avg. loss: 0.705311\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.006079, T: 967164, Avg. loss: 0.670955\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 1.58, NNZs: 1, Bias: -0.941417, T: 1024056, Avg. loss: 0.631695\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.006250, T: 1080948, Avg. loss: 0.568179\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006368, T: 1137840, Avg. loss: 0.535201\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.006219, T: 1194732, Avg. loss: 0.506159\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.006235, T: 1251624, Avg. loss: 0.464413\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 2.01, NNZs: 1, Bias: 0.006428, T: 1308516, Avg. loss: 0.442458\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 2.35, NNZs: 1, Bias: 0.006509, T: 1365408, Avg. loss: 0.413551\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.006567, T: 1422300, Avg. loss: 0.385383\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.006570, T: 1479192, Avg. loss: 0.362774\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 1.37, NNZs: 1, Bias: -0.631136, T: 1536084, Avg. loss: 0.344189\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.006969, T: 1592976, Avg. loss: 0.328431\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 1.68, NNZs: 1, Bias: 0.601564, T: 1649868, Avg. loss: 0.304620\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 1.80, NNZs: 1, Bias: 0.007033, T: 1706760, Avg. loss: 0.296545\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.007053, T: 1763652, Avg. loss: 0.279140\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 0.95, NNZs: 1, Bias: -0.532706, T: 1820544, Avg. loss: 0.261946\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 1.50, NNZs: 1, Bias: -0.516604, T: 1877436, Avg. loss: 0.252095\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 0.96, NNZs: 1, Bias: 0.007253, T: 1934328, Avg. loss: 0.231220\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.007294, T: 1991220, Avg. loss: 0.223633\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 1.42, NNZs: 1, Bias: 0.007418, T: 2048112, Avg. loss: 0.218678\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007535, T: 2105004, Avg. loss: 0.204728\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 1.29, NNZs: 1, Bias: 0.007572, T: 2161896, Avg. loss: 0.190885\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.007675, T: 2218788, Avg. loss: 0.192083\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 0.85, NNZs: 1, Bias: 0.007647, T: 2275680, Avg. loss: 0.180070\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.007689, T: 2332572, Avg. loss: 0.172384\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 1.21, NNZs: 1, Bias: 0.007755, T: 2389464, Avg. loss: 0.168490\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 1.12, NNZs: 1, Bias: 0.007855, T: 2446356, Avg. loss: 0.161315\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 0.65, NNZs: 1, Bias: -0.386572, T: 2503248, Avg. loss: 0.153864\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.007983, T: 2560140, Avg. loss: 0.147919\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 1.11, NNZs: 1, Bias: 0.385530, T: 2617032, Avg. loss: 0.147179\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.008040, T: 2673924, Avg. loss: 0.137990\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008054, T: 2730816, Avg. loss: 0.133072\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 1.17, NNZs: 1, Bias: 0.008063, T: 2787708, Avg. loss: 0.127986\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008056, T: 2844600, Avg. loss: 0.121984\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 0.40, NNZs: 1, Bias: 0.008080, T: 2901492, Avg. loss: 0.116177\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 0.64, NNZs: 1, Bias: 0.342550, T: 2958384, Avg. loss: 0.114800\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 0.49, NNZs: 1, Bias: 0.008129, T: 3015276, Avg. loss: 0.105086\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 0.93, NNZs: 1, Bias: 0.008169, T: 3072168, Avg. loss: 0.104785\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.324602, T: 3129060, Avg. loss: 0.100448\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 0.88, NNZs: 1, Bias: 0.008261, T: 3185952, Avg. loss: 0.094698\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 1.23, NNZs: 1, Bias: 0.008299, T: 3242844, Avg. loss: 0.098855\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 1.50, NNZs: 1, Bias: 0.008304, T: 3299736, Avg. loss: 0.093958\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.008335, T: 3356628, Avg. loss: 0.087379\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 0.92, NNZs: 1, Bias: 0.008376, T: 3413520, Avg. loss: 0.086472\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 1.21, NNZs: 1, Bias: -0.277130, T: 3470412, Avg. loss: 0.087487\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.008446, T: 3527304, Avg. loss: 0.083253\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 1.15, NNZs: 1, Bias: 0.285049, T: 3584196, Avg. loss: 0.077591\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008497, T: 3641088, Avg. loss: 0.076506\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.008503, T: 3697980, Avg. loss: 0.072347\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.008516, T: 3754872, Avg. loss: 0.072573\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008551, T: 3811764, Avg. loss: 0.069471\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 0.80, NNZs: 1, Bias: -0.247828, T: 3868656, Avg. loss: 0.066287\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 1.17, NNZs: 1, Bias: 0.261285, T: 3925548, Avg. loss: 0.065086\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 1.11, NNZs: 1, Bias: 0.008614, T: 3982440, Avg. loss: 0.064400\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008637, T: 4039332, Avg. loss: 0.059480\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 0.93, NNZs: 1, Bias: 0.008651, T: 4096224, Avg. loss: 0.061245\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.008668, T: 4153116, Avg. loss: 0.060352\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008680, T: 4210008, Avg. loss: 0.056585\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.008701, T: 4266900, Avg. loss: 0.056091\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 1.17, NNZs: 1, Bias: -0.220873, T: 4323792, Avg. loss: 0.053710\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.008751, T: 4380684, Avg. loss: 0.051463\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008779, T: 4437576, Avg. loss: 0.051383\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.008798, T: 4494468, Avg. loss: 0.050908\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.227023, T: 4551360, Avg. loss: 0.045739\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 0.87, NNZs: 1, Bias: -0.206693, T: 4608252, Avg. loss: 0.048223\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 1.08, NNZs: 1, Bias: 0.221756, T: 4665144, Avg. loss: 0.045651\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 0.89, NNZs: 1, Bias: 0.008870, T: 4722036, Avg. loss: 0.044726\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 0.81, NNZs: 1, Bias: 0.008900, T: 4778928, Avg. loss: 0.044817\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.008916, T: 4835820, Avg. loss: 0.041993\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 0.94, NNZs: 1, Bias: 0.008932, T: 4892712, Avg. loss: 0.041017\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 0.78, NNZs: 1, Bias: 0.008962, T: 4949604, Avg. loss: 0.040226\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.008982, T: 5006496, Avg. loss: 0.039883\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 0.92, NNZs: 1, Bias: -0.187281, T: 5063388, Avg. loss: 0.038380\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.008998, T: 5120280, Avg. loss: 0.036897\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.009022, T: 5177172, Avg. loss: 0.035675\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 0.99, NNZs: 1, Bias: 0.009037, T: 5234064, Avg. loss: 0.034473\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 0.93, NNZs: 1, Bias: 0.009049, T: 5290956, Avg. loss: 0.034888\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.009067, T: 5347848, Avg. loss: 0.033571\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 1.03, NNZs: 1, Bias: 0.009083, T: 5404740, Avg. loss: 0.033414\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 0.98, NNZs: 1, Bias: 0.009095, T: 5461632, Avg. loss: 0.031621\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 1.04, NNZs: 1, Bias: 0.009106, T: 5518524, Avg. loss: 0.031506\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 1.07, NNZs: 1, Bias: 0.365809, T: 5575416, Avg. loss: 0.030827\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 0.97, NNZs: 1, Bias: 0.009127, T: 5632308, Avg. loss: 0.029597\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.009148, T: 5689200, Avg. loss: 0.029555\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.009160, T: 5746092, Avg. loss: 0.028603\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 1.15, NNZs: 1, Bias: 0.009163, T: 5802984, Avg. loss: 0.027812\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 103\n",
            "Norm: 0.93, NNZs: 1, Bias: 0.009170, T: 5859876, Avg. loss: 0.027913\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 104\n",
            "Norm: 1.10, NNZs: 1, Bias: 0.009184, T: 5916768, Avg. loss: 0.027175\n",
            "Total training time: 0.47 seconds.\n",
            "Convergence after 104 epochs took 0.47 seconds\n",
            "-- Epoch 1\n",
            "Norm: 712.91, NNZs: 1, Bias: 22.606290, T: 56892, Avg. loss: 17.413234\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1019.98, NNZs: 1, Bias: 6.893003, T: 113784, Avg. loss: 7.730614\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1198.01, NNZs: 1, Bias: 4.956538, T: 170676, Avg. loss: 4.682152\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1314.46, NNZs: 0, Bias: -7.710651, T: 227568, Avg. loss: 3.314069\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1391.97, NNZs: 0, Bias: 0.006538, T: 284460, Avg. loss: 2.518380\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1446.57, NNZs: 0, Bias: 0.002934, T: 341352, Avg. loss: 1.982441\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1485.54, NNZs: 0, Bias: 0.002709, T: 398244, Avg. loss: 1.706012\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1513.53, NNZs: 1, Bias: 2.057506, T: 455136, Avg. loss: 1.465663\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1534.40, NNZs: 0, Bias: 0.003029, T: 512028, Avg. loss: 1.275071\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1549.44, NNZs: 1, Bias: -1.661735, T: 568920, Avg. loss: 1.112998\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1559.89, NNZs: 0, Bias: 0.004284, T: 625812, Avg. loss: 1.023073\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1566.97, NNZs: 0, Bias: 0.004525, T: 682704, Avg. loss: 0.923865\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1572.10, NNZs: 1, Bias: 1.301670, T: 739596, Avg. loss: 0.846135\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1575.89, NNZs: 0, Bias: -1.202597, T: 796488, Avg. loss: 0.797102\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 1578.73, NNZs: 1, Bias: 1.135034, T: 853380, Avg. loss: 0.722513\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 1580.89, NNZs: 1, Bias: 0.005435, T: 910272, Avg. loss: 0.684242\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 1582.50, NNZs: 1, Bias: 0.005851, T: 967164, Avg. loss: 0.633569\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 1583.69, NNZs: 1, Bias: 0.005732, T: 1024056, Avg. loss: 0.586676\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 1584.63, NNZs: 1, Bias: 0.005944, T: 1080948, Avg. loss: 0.549104\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 1585.36, NNZs: 1, Bias: -0.849185, T: 1137840, Avg. loss: 0.530492\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1585.90, NNZs: 1, Bias: 0.006099, T: 1194732, Avg. loss: 0.486255\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 1586.31, NNZs: 1, Bias: 0.006140, T: 1251624, Avg. loss: 0.453707\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 1586.61, NNZs: 1, Bias: 0.006392, T: 1308516, Avg. loss: 0.430315\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 1586.84, NNZs: 1, Bias: 0.006265, T: 1365408, Avg. loss: 0.409278\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 1586.99, NNZs: 1, Bias: -0.681464, T: 1422300, Avg. loss: 0.376994\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 1587.10, NNZs: 1, Bias: -0.655460, T: 1479192, Avg. loss: 0.371152\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 1587.18, NNZs: 1, Bias: -0.631259, T: 1536084, Avg. loss: 0.344249\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 1587.23, NNZs: 1, Bias: 0.006773, T: 1592976, Avg. loss: 0.319683\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 1587.27, NNZs: 1, Bias: 0.006731, T: 1649868, Avg. loss: 0.312489\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 1587.30, NNZs: 1, Bias: 0.006904, T: 1706760, Avg. loss: 0.297800\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 1587.31, NNZs: 1, Bias: 0.006997, T: 1763652, Avg. loss: 0.279829\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 1587.32, NNZs: 1, Bias: 0.007055, T: 1820544, Avg. loss: 0.264460\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 1587.33, NNZs: 1, Bias: -0.516644, T: 1877436, Avg. loss: 0.253344\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 1587.33, NNZs: 1, Bias: 0.007232, T: 1934328, Avg. loss: 0.245112\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 1587.33, NNZs: 1, Bias: -0.487125, T: 1991220, Avg. loss: 0.228094\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 1587.33, NNZs: 1, Bias: 0.007303, T: 2048112, Avg. loss: 0.218833\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 1587.33, NNZs: 1, Bias: 0.007392, T: 2105004, Avg. loss: 0.206251\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.463351, T: 2161896, Avg. loss: 0.202878\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.007468, T: 2218788, Avg. loss: 0.193744\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.007487, T: 2275680, Avg. loss: 0.184981\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.007579, T: 2332572, Avg. loss: 0.178999\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.420696, T: 2389464, Avg. loss: 0.168819\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.007739, T: 2446356, Avg. loss: 0.163925\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 1587.34, NNZs: 1, Bias: -0.386677, T: 2503248, Avg. loss: 0.154907\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.007878, T: 2560140, Avg. loss: 0.148186\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.007925, T: 2617032, Avg. loss: 0.143635\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.007998, T: 2673924, Avg. loss: 0.137765\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008067, T: 2730816, Avg. loss: 0.130727\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008127, T: 2787708, Avg. loss: 0.130072\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 1587.34, NNZs: 1, Bias: -0.339518, T: 2844600, Avg. loss: 0.126416\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008226, T: 2901492, Avg. loss: 0.120107\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008262, T: 2958384, Avg. loss: 0.115517\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008300, T: 3015276, Avg. loss: 0.113755\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008352, T: 3072168, Avg. loss: 0.109863\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 1587.34, NNZs: 1, Bias: -0.308034, T: 3129060, Avg. loss: 0.104096\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008401, T: 3185952, Avg. loss: 0.101271\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.313800, T: 3242844, Avg. loss: 0.098455\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008460, T: 3299736, Avg. loss: 0.093596\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008508, T: 3356628, Avg. loss: 0.090143\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008550, T: 3413520, Avg. loss: 0.087273\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008566, T: 3470412, Avg. loss: 0.083635\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008585, T: 3527304, Avg. loss: 0.082058\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008596, T: 3584196, Avg. loss: 0.080614\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008642, T: 3641088, Avg. loss: 0.078677\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008664, T: 3697980, Avg. loss: 0.076043\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 1587.34, NNZs: 1, Bias: -0.255407, T: 3754872, Avg. loss: 0.072634\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008707, T: 3811764, Avg. loss: 0.072758\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 1587.34, NNZs: 1, Bias: -0.247659, T: 3868656, Avg. loss: 0.067657\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008749, T: 3925548, Avg. loss: 0.069912\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008760, T: 3982440, Avg. loss: 0.065393\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 1587.34, NNZs: 1, Bias: -0.236859, T: 4039332, Avg. loss: 0.063283\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008814, T: 4096224, Avg. loss: 0.060990\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.247787, T: 4153116, Avg. loss: 0.060583\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.244609, T: 4210008, Avg. loss: 0.059412\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008871, T: 4266900, Avg. loss: 0.056358\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008900, T: 4323792, Avg. loss: 0.056424\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.235560, T: 4380684, Avg. loss: 0.052783\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008946, T: 4437576, Avg. loss: 0.050382\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008960, T: 4494468, Avg. loss: 0.050298\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008975, T: 4551360, Avg. loss: 0.049899\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.008991, T: 4608252, Avg. loss: 0.048333\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.221911, T: 4665144, Avg. loss: 0.047276\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.219383, T: 4722036, Avg. loss: 0.045849\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009040, T: 4778928, Avg. loss: 0.043881\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 1587.34, NNZs: 1, Bias: -0.196384, T: 4835820, Avg. loss: 0.043550\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009083, T: 4892712, Avg. loss: 0.042921\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009100, T: 4949604, Avg. loss: 0.041974\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 1587.34, NNZs: 1, Bias: -0.189362, T: 5006496, Avg. loss: 0.039899\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009144, T: 5063388, Avg. loss: 0.039242\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009157, T: 5120280, Avg. loss: 0.039694\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009164, T: 5177172, Avg. loss: 0.038409\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009183, T: 5234064, Avg. loss: 0.036752\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009194, T: 5290956, Avg. loss: 0.035505\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009203, T: 5347848, Avg. loss: 0.035495\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009218, T: 5404740, Avg. loss: 0.034520\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009242, T: 5461632, Avg. loss: 0.034049\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009256, T: 5518524, Avg. loss: 0.032581\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009274, T: 5575416, Avg. loss: 0.031768\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.185840, T: 5632308, Avg. loss: 0.031269\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.358903, T: 5689200, Avg. loss: 0.030675\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009319, T: 5746092, Avg. loss: 0.029272\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009323, T: 5802984, Avg. loss: 0.028736\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 103\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.179068, T: 5859876, Avg. loss: 0.028622\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 104\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009340, T: 5916768, Avg. loss: 0.027902\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 105\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.175873, T: 5973660, Avg. loss: 0.027557\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 106\n",
            "Norm: 1587.34, NNZs: 1, Bias: 0.009357, T: 6030552, Avg. loss: 0.027281\n",
            "Total training time: 0.50 seconds.\n",
            "Convergence after 106 epochs took 0.50 seconds\n",
            "-- Epoch 1\n",
            "Norm: 717.60, NNZs: 1, Bias: -0.088199, T: 56892, Avg. loss: 17.592013\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1028.44, NNZs: 1, Bias: -0.031654, T: 113784, Avg. loss: 7.900567\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1208.97, NNZs: 1, Bias: -0.026119, T: 170676, Avg. loss: 4.851302\n",
            "Total training time: 0.02 seconds."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch 4\n",
            "Norm: 1326.99, NNZs: 1, Bias: -0.017931, T: 227568, Avg. loss: 3.418749\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1404.83, NNZs: 0, Bias: -3.174727, T: 284460, Avg. loss: 2.575667\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1460.61, NNZs: 1, Bias: 2.674253, T: 341352, Avg. loss: 2.070754\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1499.19, NNZs: 0, Bias: -0.005871, T: 398244, Avg. loss: 1.702367\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1527.02, NNZs: 1, Bias: -0.004522, T: 455136, Avg. loss: 1.463025\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1547.66, NNZs: 1, Bias: -3.681371, T: 512028, Avg. loss: 1.268176\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1562.68, NNZs: 1, Bias: -1.665844, T: 568920, Avg. loss: 1.128083\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1572.74, NNZs: 1, Bias: 0.000220, T: 625812, Avg. loss: 1.032162\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1579.91, NNZs: 0, Bias: 1.401016, T: 682704, Avg. loss: 0.946323\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1585.06, NNZs: 1, Bias: 0.001646, T: 739596, Avg. loss: 0.865110\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1588.93, NNZs: 1, Bias: 1.209850, T: 796488, Avg. loss: 0.810366\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 1591.88, NNZs: 1, Bias: 0.002931, T: 853380, Avg. loss: 0.745431\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 1594.02, NNZs: 1, Bias: 0.003285, T: 910272, Avg. loss: 0.686273\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 1595.63, NNZs: 1, Bias: 0.003695, T: 967164, Avg. loss: 0.640485\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 1596.88, NNZs: 1, Bias: 0.003853, T: 1024056, Avg. loss: 0.605207\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 1597.81, NNZs: 1, Bias: 0.902962, T: 1080948, Avg. loss: 0.565944\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 1598.52, NNZs: 1, Bias: 0.859351, T: 1137840, Avg. loss: 0.527428\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 1599.05, NNZs: 1, Bias: 0.004397, T: 1194732, Avg. loss: 0.501909\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 1599.44, NNZs: 1, Bias: 0.004735, T: 1251624, Avg. loss: 0.468718\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 1599.75, NNZs: 1, Bias: 0.004814, T: 1308516, Avg. loss: 0.442694\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 1599.97, NNZs: 1, Bias: 0.720646, T: 1365408, Avg. loss: 0.415465\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 1600.14, NNZs: 1, Bias: 0.005024, T: 1422300, Avg. loss: 0.397057\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 1600.25, NNZs: 1, Bias: 0.005256, T: 1479192, Avg. loss: 0.372733\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 1600.33, NNZs: 1, Bias: 0.005409, T: 1536084, Avg. loss: 0.353533\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 1600.39, NNZs: 1, Bias: 0.005427, T: 1592976, Avg. loss: 0.334517\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 1600.42, NNZs: 1, Bias: 0.005300, T: 1649868, Avg. loss: 0.319760\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 1600.45, NNZs: 1, Bias: 0.005441, T: 1706760, Avg. loss: 0.311264\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 1600.47, NNZs: 1, Bias: 0.005452, T: 1763652, Avg. loss: 0.293382\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 1600.48, NNZs: 1, Bias: -0.534326, T: 1820544, Avg. loss: 0.266170\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 1600.49, NNZs: 1, Bias: 0.005576, T: 1877436, Avg. loss: 0.263814\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 1600.49, NNZs: 1, Bias: 0.514276, T: 1934328, Avg. loss: 0.245685\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 1600.49, NNZs: 1, Bias: -0.488637, T: 1991220, Avg. loss: 0.236456\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 1600.49, NNZs: 1, Bias: 0.005746, T: 2048112, Avg. loss: 0.230993\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 1600.49, NNZs: 1, Bias: 0.005898, T: 2105004, Avg. loss: 0.219460\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 1600.49, NNZs: 1, Bias: 0.005914, T: 2161896, Avg. loss: 0.210380\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.005999, T: 2218788, Avg. loss: 0.197843\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006103, T: 2275680, Avg. loss: 0.191548\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 1600.50, NNZs: 1, Bias: -0.416776, T: 2332572, Avg. loss: 0.182237\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006223, T: 2389464, Avg. loss: 0.176873\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006294, T: 2446356, Avg. loss: 0.169366\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006353, T: 2503248, Avg. loss: 0.163666\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006418, T: 2560140, Avg. loss: 0.157580\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006454, T: 2617032, Avg. loss: 0.150463\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006492, T: 2673924, Avg. loss: 0.145014\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006570, T: 2730816, Avg. loss: 0.137313\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006611, T: 2787708, Avg. loss: 0.135785\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.701998, T: 2844600, Avg. loss: 0.127352\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006703, T: 2901492, Avg. loss: 0.124715\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 1600.50, NNZs: 1, Bias: -0.327677, T: 2958384, Avg. loss: 0.123559\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006804, T: 3015276, Avg. loss: 0.117318\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006865, T: 3072168, Avg. loss: 0.114099\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006880, T: 3129060, Avg. loss: 0.108321\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006911, T: 3185952, Avg. loss: 0.105270\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006933, T: 3242844, Avg. loss: 0.101660\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.006964, T: 3299736, Avg. loss: 0.102245\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007003, T: 3356628, Avg. loss: 0.096004\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007031, T: 3413520, Avg. loss: 0.093010\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 1600.50, NNZs: 1, Bias: -0.278489, T: 3470412, Avg. loss: 0.090208\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 1600.50, NNZs: 1, Bias: -0.273898, T: 3527304, Avg. loss: 0.085573\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 1600.50, NNZs: 1, Bias: -0.269426, T: 3584196, Avg. loss: 0.084585\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.279467, T: 3641088, Avg. loss: 0.080234\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.275352, T: 3697980, Avg. loss: 0.079306\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.271343, T: 3754872, Avg. loss: 0.077687\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.267444, T: 3811764, Avg. loss: 0.075671\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007281, T: 3868656, Avg. loss: 0.071653\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007298, T: 3925548, Avg. loss: 0.071419\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007330, T: 3982440, Avg. loss: 0.068924\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007372, T: 4039332, Avg. loss: 0.067013\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007401, T: 4096224, Avg. loss: 0.064475\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007433, T: 4153116, Avg. loss: 0.063908\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.243209, T: 4210008, Avg. loss: 0.062101\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007468, T: 4266900, Avg. loss: 0.058985\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007502, T: 4323792, Avg. loss: 0.057364\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007537, T: 4380684, Avg. loss: 0.056679\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007569, T: 4437576, Avg. loss: 0.054324\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007603, T: 4494468, Avg. loss: 0.053714\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 1600.50, NNZs: 1, Bias: -0.210569, T: 4551360, Avg. loss: 0.052929\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007659, T: 4608252, Avg. loss: 0.049485\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007682, T: 4665144, Avg. loss: 0.049929\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007704, T: 4722036, Avg. loss: 0.048176\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007722, T: 4778928, Avg. loss: 0.048322\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.213196, T: 4835820, Avg. loss: 0.044361\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.413915, T: 4892712, Avg. loss: 0.043931\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007792, T: 4949604, Avg. loss: 0.042614\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007799, T: 5006496, Avg. loss: 0.043269\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007824, T: 5063388, Avg. loss: 0.041959\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007842, T: 5120280, Avg. loss: 0.040262\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.199838, T: 5177172, Avg. loss: 0.040131\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007872, T: 5234064, Avg. loss: 0.038925\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007883, T: 5290956, Avg. loss: 0.036732\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007895, T: 5347848, Avg. loss: 0.036035\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007907, T: 5404740, Avg. loss: 0.036644\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007924, T: 5461632, Avg. loss: 0.035932\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007945, T: 5518524, Avg. loss: 0.034903\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007954, T: 5575416, Avg. loss: 0.033673\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007971, T: 5632308, Avg. loss: 0.033741\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007978, T: 5689200, Avg. loss: 0.032295\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.007992, T: 5746092, Avg. loss: 0.032207\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.008004, T: 5802984, Avg. loss: 0.030707\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 103\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.008014, T: 5859876, Avg. loss: 0.031205\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 104\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.008021, T: 5916768, Avg. loss: 0.029396\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 105\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.174547, T: 5973660, Avg. loss: 0.029148\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 106\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.008041, T: 6030552, Avg. loss: 0.028210\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 107\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.008057, T: 6087444, Avg. loss: 0.028070\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 108\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.008064, T: 6144336, Avg. loss: 0.027375\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 109\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.008068, T: 6201228, Avg. loss: 0.026359\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 110\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.008074, T: 6258120, Avg. loss: 0.025523\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 111\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.008086, T: 6315012, Avg. loss: 0.026227\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 112\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.008091, T: 6371904, Avg. loss: 0.025448\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 113\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.008094, T: 6428796, Avg. loss: 0.025473\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 114\n",
            "Norm: 1600.50, NNZs: 1, Bias: 0.008103, T: 6485688, Avg. loss: 0.024817\n",
            "Total training time: 0.54 seconds.\n",
            "Convergence after 114 epochs took 0.54 seconds\n",
            "-- Epoch 1\n",
            "Norm: 711.77, NNZs: 1, Bias: 11.269676, T: 56892, Avg. loss: 17.395250\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1018.22, NNZs: 1, Bias: 6.869561, T: 113784, Avg. loss: 7.704655\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1196.52, NNZs: 1, Bias: 0.002243, T: 170676, Avg. loss: 4.738414\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1310.78, NNZs: 1, Bias: 3.862395, T: 227568, Avg. loss: 3.302105\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1387.66, NNZs: 0, Bias: -3.162346, T: 284460, Avg. loss: 2.471213\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1441.99, NNZs: 0, Bias: -5.360109, T: 341352, Avg. loss: 2.009646\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1480.77, NNZs: 0, Bias: -2.325040, T: 398244, Avg. loss: 1.681310\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1509.17, NNZs: 1, Bias: 0.001613, T: 455136, Avg. loss: 1.451848\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1530.02, NNZs: 1, Bias: 0.001961, T: 512028, Avg. loss: 1.288640\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1544.33, NNZs: 1, Bias: 0.002795, T: 568920, Avg. loss: 1.108047\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1554.49, NNZs: 1, Bias: 0.003995, T: 625812, Avg. loss: 1.017593\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1561.91, NNZs: 1, Bias: 0.004755, T: 682704, Avg. loss: 0.935154\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1567.22, NNZs: 1, Bias: 0.005236, T: 739596, Avg. loss: 0.858158\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1570.95, NNZs: 1, Bias: 0.005818, T: 796488, Avg. loss: 0.776438\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 1573.78, NNZs: 1, Bias: 0.005957, T: 853380, Avg. loss: 0.729200\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 1575.93, NNZs: 1, Bias: 0.006199, T: 910272, Avg. loss: 0.687664\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 1577.56, NNZs: 1, Bias: 0.006314, T: 967164, Avg. loss: 0.631273\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 1578.79, NNZs: 1, Bias: 0.006452, T: 1024056, Avg. loss: 0.580382\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 1579.74, NNZs: 1, Bias: 0.006479, T: 1080948, Avg. loss: 0.554345\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 1580.45, NNZs: 1, Bias: 0.006701, T: 1137840, Avg. loss: 0.505582\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 1580.98, NNZs: 1, Bias: -0.808832, T: 1194732, Avg. loss: 0.484632\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 1581.36, NNZs: 1, Bias: 0.006858, T: 1251624, Avg. loss: 0.452702\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 1581.64, NNZs: 1, Bias: 0.007034, T: 1308516, Avg. loss: 0.423396\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 1581.86, NNZs: 1, Bias: 0.007049, T: 1365408, Avg. loss: 0.412827\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 1582.02, NNZs: 1, Bias: 0.694937, T: 1422300, Avg. loss: 0.379126\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 1582.13, NNZs: 1, Bias: 1.331064, T: 1479192, Avg. loss: 0.360368\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 1582.21, NNZs: 1, Bias: 0.007325, T: 1536084, Avg. loss: 0.349895\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 1582.26, NNZs: 1, Bias: 0.622981, T: 1592976, Avg. loss: 0.323005\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 1582.30, NNZs: 1, Bias: 0.007521, T: 1649868, Avg. loss: 0.308349\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1582.33, NNZs: 1, Bias: 0.007845, T: 1706760, Avg. loss: 0.296455\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 1582.35, NNZs: 1, Bias: 0.007948, T: 1763652, Avg. loss: 0.284421\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 1582.36, NNZs: 1, Bias: -0.531940, T: 1820544, Avg. loss: 0.267476\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 1582.36, NNZs: 1, Bias: 0.008047, T: 1877436, Avg. loss: 0.258566\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.500499, T: 1934328, Avg. loss: 0.241448\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008222, T: 1991220, Avg. loss: 0.233899\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008315, T: 2048112, Avg. loss: 0.226412\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008328, T: 2105004, Avg. loss: 0.209776\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008394, T: 2161896, Avg. loss: 0.198645\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.435900, T: 2218788, Avg. loss: 0.194910\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008501, T: 2275680, Avg. loss: 0.189305\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008520, T: 2332572, Avg. loss: 0.181743\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008625, T: 2389464, Avg. loss: 0.172299\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008760, T: 2446356, Avg. loss: 0.167938\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008783, T: 2503248, Avg. loss: 0.160249\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008808, T: 2560140, Avg. loss: 0.147656\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008862, T: 2617032, Avg. loss: 0.146716\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.360714, T: 2673924, Avg. loss: 0.143288\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008931, T: 2730816, Avg. loss: 0.134416\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.008969, T: 2787708, Avg. loss: 0.130562\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009024, T: 2844600, Avg. loss: 0.121404\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009047, T: 2901492, Avg. loss: 0.119757\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.325426, T: 2958384, Avg. loss: 0.117743\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009048, T: 3015276, Avg. loss: 0.115847\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.313104, T: 3072168, Avg. loss: 0.106266\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009084, T: 3129060, Avg. loss: 0.104237\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.301690, T: 3185952, Avg. loss: 0.100872\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.296285, T: 3242844, Avg. loss: 0.099132\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.291039, T: 3299736, Avg. loss: 0.095166\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009146, T: 3356628, Avg. loss: 0.094213\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009209, T: 3413520, Avg. loss: 0.087735\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.294790, T: 3470412, Avg. loss: 0.085731\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.271718, T: 3527304, Avg. loss: 0.082448\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009290, T: 3584196, Avg. loss: 0.080617\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.262969, T: 3641088, Avg. loss: 0.078100\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.277449, T: 3697980, Avg. loss: 0.074237\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.254739, T: 3754872, Avg. loss: 0.072678\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009385, T: 3811764, Avg. loss: 0.073189\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009396, T: 3868656, Avg. loss: 0.068917\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009429, T: 3925548, Avg. loss: 0.067199\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.258578, T: 3982440, Avg. loss: 0.067363\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009487, T: 4039332, Avg. loss: 0.063590\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.232757, T: 4096224, Avg. loss: 0.061946\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009521, T: 4153116, Avg. loss: 0.060722\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009537, T: 4210008, Avg. loss: 0.057218\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009560, T: 4266900, Avg. loss: 0.055152\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009589, T: 4323792, Avg. loss: 0.054657\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.443667, T: 4380684, Avg. loss: 0.054135\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009646, T: 4437576, Avg. loss: 0.053605\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009663, T: 4494468, Avg. loss: 0.051369\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009687, T: 4551360, Avg. loss: 0.051973\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009708, T: 4608252, Avg. loss: 0.048837\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.222641, T: 4665144, Avg. loss: 0.046910\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.220107, T: 4722036, Avg. loss: 0.046039\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.198107, T: 4778928, Avg. loss: 0.045508\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.195666, T: 4835820, Avg. loss: 0.044152\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009807, T: 4892712, Avg. loss: 0.044169\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009825, T: 4949604, Avg. loss: 0.040970\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009846, T: 5006496, Avg. loss: 0.040706\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009874, T: 5063388, Avg. loss: 0.039629\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009889, T: 5120280, Avg. loss: 0.038380\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.201884, T: 5177172, Avg. loss: 0.035950\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009910, T: 5234064, Avg. loss: 0.036714\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009920, T: 5290956, Avg. loss: 0.036746\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.195840, T: 5347848, Avg. loss: 0.033946\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009974, T: 5404740, Avg. loss: 0.034222\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.172052, T: 5461632, Avg. loss: 0.033842\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.009999, T: 5518524, Avg. loss: 0.032181\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.010009, T: 5575416, Avg. loss: 0.032694\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.010028, T: 5632308, Avg. loss: 0.030725\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 1582.37, NNZs: 1, Bias: -0.164763, T: 5689200, Avg. loss: 0.030061\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.010045, T: 5746092, Avg. loss: 0.029547\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.010054, T: 5802984, Avg. loss: 0.029356\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 103\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.179801, T: 5859876, Avg. loss: 0.028189\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 104\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.010078, T: 5916768, Avg. loss: 0.027411\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 105\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.010091, T: 5973660, Avg. loss: 0.027483\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 106\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.010100, T: 6030552, Avg. loss: 0.026638\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 107\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.010112, T: 6087444, Avg. loss: 0.027258\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 108\n",
            "Norm: 1582.37, NNZs: 1, Bias: 0.010119, T: 6144336, Avg. loss: 0.025759\n",
            "Total training time: 0.52 seconds.\n",
            "Convergence after 108 epochs took 0.52 seconds\n",
            "-- Epoch 1\n",
            "Norm: 714.47, NNZs: 1, Bias: -11.371311, T: 56892, Avg. loss: 17.478472\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1022.95, NNZs: 1, Bias: 6.854481, T: 113784, Avg. loss: 7.850146\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1207.23, NNZs: 1, Bias: -0.008215, T: 170676, Avg. loss: 4.838997\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1323.48, NNZs: 1, Bias: 3.849931, T: 227568, Avg. loss: 3.349688\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1401.89, NNZs: 1, Bias: -0.003799, T: 284460, Avg. loss: 2.521720\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1457.69, NNZs: 1, Bias: -0.002901, T: 341352, Avg. loss: 2.044487\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1495.73, NNZs: 1, Bias: -0.004079, T: 398244, Avg. loss: 1.687871\n",
            "Total training time: 0.04 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 8\n",
            "Norm: 1523.71, NNZs: 0, Bias: -0.002803, T: 455136, Avg. loss: 1.449936\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1543.34, NNZs: 1, Bias: 1.837851, T: 512028, Avg. loss: 1.256330\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1558.29, NNZs: 0, Bias: -0.000062, T: 568920, Avg. loss: 1.119132\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1568.43, NNZs: 0, Bias: -1.520231, T: 625812, Avg. loss: 1.031630\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1575.60, NNZs: 1, Bias: 1.400908, T: 682704, Avg. loss: 0.949605\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1580.90, NNZs: 1, Bias: 0.001500, T: 739596, Avg. loss: 0.875999\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1584.76, NNZs: 1, Bias: 0.002006, T: 796488, Avg. loss: 0.805242\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 1587.60, NNZs: 1, Bias: 0.002368, T: 853380, Avg. loss: 0.735970\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 1589.81, NNZs: 1, Bias: 0.002879, T: 910272, Avg. loss: 0.701628\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 1591.49, NNZs: 1, Bias: 1.004459, T: 967164, Avg. loss: 0.643304\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 1592.75, NNZs: 0, Bias: 0.950310, T: 1024056, Avg. loss: 0.614784\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 1593.68, NNZs: 1, Bias: -0.895429, T: 1080948, Avg. loss: 0.563300\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 1594.37, NNZs: 1, Bias: -0.851293, T: 1137840, Avg. loss: 0.521716\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 1594.92, NNZs: 1, Bias: 0.004075, T: 1194732, Avg. loss: 0.504628\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 1595.31, NNZs: 1, Bias: 0.004430, T: 1251624, Avg. loss: 0.468655\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 1595.60, NNZs: 1, Bias: 0.004535, T: 1308516, Avg. loss: 0.436333\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 1595.82, NNZs: 1, Bias: 0.004611, T: 1365408, Avg. loss: 0.414914\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 1595.99, NNZs: 1, Bias: 0.004602, T: 1422300, Avg. loss: 0.398657\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 1596.11, NNZs: 1, Bias: 0.004803, T: 1479192, Avg. loss: 0.380991\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 1596.19, NNZs: 1, Bias: 0.005026, T: 1536084, Avg. loss: 0.351993\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 1596.25, NNZs: 1, Bias: 0.005172, T: 1592976, Avg. loss: 0.335352\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 1596.28, NNZs: 1, Bias: 0.005397, T: 1649868, Avg. loss: 0.319442\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 1596.31, NNZs: 1, Bias: 0.005448, T: 1706760, Avg. loss: 0.295875\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 1596.32, NNZs: 1, Bias: 0.005529, T: 1763652, Avg. loss: 0.287427\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 1596.34, NNZs: 1, Bias: -0.534213, T: 1820544, Avg. loss: 0.271627\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 1596.34, NNZs: 1, Bias: -0.517927, T: 1877436, Avg. loss: 0.263261\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 1596.35, NNZs: 1, Bias: -0.502588, T: 1934328, Avg. loss: 0.249260\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.006242, T: 1991220, Avg. loss: 0.233289\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.006318, T: 2048112, Avg. loss: 0.224456\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.006418, T: 2105004, Avg. loss: 0.214999\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.006547, T: 2161896, Avg. loss: 0.208834\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 1596.35, NNZs: 1, Bias: -0.437719, T: 2218788, Avg. loss: 0.201383\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.440083, T: 2275680, Avg. loss: 0.195567\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.006727, T: 2332572, Avg. loss: 0.178901\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.006727, T: 2389464, Avg. loss: 0.175863\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.006794, T: 2446356, Avg. loss: 0.168429\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.006786, T: 2503248, Avg. loss: 0.159985\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.392719, T: 2560140, Avg. loss: 0.156516\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.006953, T: 2617032, Avg. loss: 0.148651\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.006986, T: 2673924, Avg. loss: 0.146588\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.731061, T: 2730816, Avg. loss: 0.140125\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 1596.35, NNZs: 1, Bias: -0.347599, T: 2787708, Avg. loss: 0.134369\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.354830, T: 2844600, Avg. loss: 0.129047\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007215, T: 2901492, Avg. loss: 0.123605\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007273, T: 2958384, Avg. loss: 0.120155\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007316, T: 3015276, Avg. loss: 0.120127\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007375, T: 3072168, Avg. loss: 0.111329\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007417, T: 3129060, Avg. loss: 0.109152\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007431, T: 3185952, Avg. loss: 0.107046\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007470, T: 3242844, Avg. loss: 0.100915\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007536, T: 3299736, Avg. loss: 0.098829\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007579, T: 3356628, Avg. loss: 0.098805\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007622, T: 3413520, Avg. loss: 0.090512\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007655, T: 3470412, Avg. loss: 0.090203\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007688, T: 3527304, Avg. loss: 0.086582\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 1596.35, NNZs: 1, Bias: -0.268857, T: 3584196, Avg. loss: 0.085489\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007722, T: 3641088, Avg. loss: 0.082419\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 1596.35, NNZs: 1, Bias: -0.260368, T: 3697980, Avg. loss: 0.078245\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.271858, T: 3754872, Avg. loss: 0.074558\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007796, T: 3811764, Avg. loss: 0.074467\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007832, T: 3868656, Avg. loss: 0.070712\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007859, T: 3925548, Avg. loss: 0.070110\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.257018, T: 3982440, Avg. loss: 0.067069\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007911, T: 4039332, Avg. loss: 0.065074\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007943, T: 4096224, Avg. loss: 0.064016\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007974, T: 4153116, Avg. loss: 0.062834\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.007985, T: 4210008, Avg. loss: 0.061377\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.240640, T: 4266900, Avg. loss: 0.058053\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008024, T: 4323792, Avg. loss: 0.056912\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008035, T: 4380684, Avg. loss: 0.056670\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008051, T: 4437576, Avg. loss: 0.056013\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008065, T: 4494468, Avg. loss: 0.051761\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008083, T: 4551360, Avg. loss: 0.052609\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008104, T: 4608252, Avg. loss: 0.050303\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008113, T: 4665144, Avg. loss: 0.049345\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008130, T: 4722036, Avg. loss: 0.048119\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008140, T: 4778928, Avg. loss: 0.046390\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008165, T: 4835820, Avg. loss: 0.044829\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008179, T: 4892712, Avg. loss: 0.043441\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008190, T: 4949604, Avg. loss: 0.042891\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008205, T: 5006496, Avg. loss: 0.042760\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008229, T: 5063388, Avg. loss: 0.042119\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008248, T: 5120280, Avg. loss: 0.040668\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008257, T: 5177172, Avg. loss: 0.038767\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008273, T: 5234064, Avg. loss: 0.039318\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008289, T: 5290956, Avg. loss: 0.038341\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008299, T: 5347848, Avg. loss: 0.036703\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008302, T: 5404740, Avg. loss: 0.035744\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008322, T: 5461632, Avg. loss: 0.035505\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 1596.35, NNZs: 1, Bias: -0.171842, T: 5518524, Avg. loss: 0.035019\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008346, T: 5575416, Avg. loss: 0.033190\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008349, T: 5632308, Avg. loss: 0.034009\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 1596.35, NNZs: 1, Bias: -0.166443, T: 5689200, Avg. loss: 0.032494\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008376, T: 5746092, Avg. loss: 0.031543\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008382, T: 5802984, Avg. loss: 0.031499\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 103\n",
            "Norm: 1596.35, NNZs: 1, Bias: 0.008389, T: 5859876, Avg. loss: 0.031012\n",
            "Total training time: 0.52 seconds.\n",
            "Convergence after 103 epochs took 0.52 seconds\n",
            "-- Epoch 1\n",
            "Norm: 705.95, NNZs: 1, Bias: -0.004795, T: 56892, Avg. loss: 17.265800\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1008.81, NNZs: 1, Bias: -0.002858, T: 113784, Avg. loss: 7.678772\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1187.26, NNZs: 1, Bias: 0.012369, T: 170676, Avg. loss: 4.709068\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1304.08, NNZs: 0, Bias: -3.848905, T: 227568, Avg. loss: 3.289009\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1383.13, NNZs: 1, Bias: 3.169423, T: 284460, Avg. loss: 2.478544\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1438.75, NNZs: 1, Bias: 2.686031, T: 341352, Avg. loss: 1.996554\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1477.72, NNZs: 1, Bias: 2.332033, T: 398244, Avg. loss: 1.679868\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1505.98, NNZs: 1, Bias: 0.005665, T: 455136, Avg. loss: 1.419860\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1525.95, NNZs: 0, Bias: -1.833786, T: 512028, Avg. loss: 1.267854\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1540.58, NNZs: 1, Bias: -1.658901, T: 568920, Avg. loss: 1.127133\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1550.51, NNZs: 1, Bias: 0.006234, T: 625812, Avg. loss: 1.000726\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1557.64, NNZs: 1, Bias: 0.006229, T: 682704, Avg. loss: 0.917692\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 1562.74, NNZs: 1, Bias: 2.599761, T: 739596, Avg. loss: 0.839782\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 1566.68, NNZs: 1, Bias: 1.214060, T: 796488, Avg. loss: 0.806390\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 1569.55, NNZs: 1, Bias: -1.123932, T: 853380, Avg. loss: 0.726342\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 1571.80, NNZs: 1, Bias: 1.067268, T: 910272, Avg. loss: 0.680646\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 1573.42, NNZs: 1, Bias: -1.997095, T: 967164, Avg. loss: 0.615636\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 1574.69, NNZs: 0, Bias: -0.941917, T: 1024056, Avg. loss: 0.591931\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 1575.64, NNZs: 1, Bias: -0.893306, T: 1080948, Avg. loss: 0.546266\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 1576.35, NNZs: 1, Bias: -0.849524, T: 1137840, Avg. loss: 0.510815\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 1576.89, NNZs: 1, Bias: 0.005663, T: 1194732, Avg. loss: 0.486849\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 1577.27, NNZs: 0, Bias: 0.005819, T: 1251624, Avg. loss: 0.445156\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 1577.58, NNZs: 1, Bias: 0.006077, T: 1308516, Avg. loss: 0.428005\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 1577.80, NNZs: 1, Bias: 0.006199, T: 1365408, Avg. loss: 0.408006\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 1577.95, NNZs: 1, Bias: -0.681359, T: 1422300, Avg. loss: 0.373479\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 1578.07, NNZs: 1, Bias: 0.006468, T: 1479192, Avg. loss: 0.361708\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 1578.15, NNZs: 1, Bias: 0.006570, T: 1536084, Avg. loss: 0.351646\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 1578.20, NNZs: 1, Bias: 0.006677, T: 1592976, Avg. loss: 0.317705\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 1578.23, NNZs: 1, Bias: 0.006930, T: 1649868, Avg. loss: 0.303636\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 1578.26, NNZs: 1, Bias: 0.007077, T: 1706760, Avg. loss: 0.278537\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1578.27, NNZs: 1, Bias: 1.121157, T: 1763652, Avg. loss: 0.277485\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 1578.28, NNZs: 1, Bias: -0.532712, T: 1820544, Avg. loss: 0.261208\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 1578.29, NNZs: 1, Bias: 0.007254, T: 1877436, Avg. loss: 0.252450\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.501307, T: 1934328, Avg. loss: 0.234527\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.007406, T: 1991220, Avg. loss: 0.227475\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.007462, T: 2048112, Avg. loss: 0.215262\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.007539, T: 2105004, Avg. loss: 0.206087\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.007535, T: 2161896, Avg. loss: 0.198829\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.007597, T: 2218788, Avg. loss: 0.192888\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.007677, T: 2275680, Avg. loss: 0.180855\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.007622, T: 2332572, Avg. loss: 0.174807\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.007656, T: 2389464, Avg. loss: 0.169380\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.007763, T: 2446356, Avg. loss: 0.161064\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.386690, T: 2503248, Avg. loss: 0.151446\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.007880, T: 2560140, Avg. loss: 0.149613\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.007951, T: 2617032, Avg. loss: 0.144129\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.731218, T: 2673924, Avg. loss: 0.133418\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.353939, T: 2730816, Avg. loss: 0.132321\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008143, T: 2787708, Avg. loss: 0.124931\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008187, T: 2844600, Avg. loss: 0.122328\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.349207, T: 2901492, Avg. loss: 0.116819\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008295, T: 2958384, Avg. loss: 0.116245\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008305, T: 3015276, Avg. loss: 0.109697\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008329, T: 3072168, Avg. loss: 0.106185\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008415, T: 3129060, Avg. loss: 0.102606\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.302340, T: 3185952, Avg. loss: 0.099105\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008475, T: 3242844, Avg. loss: 0.093318\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008516, T: 3299736, Avg. loss: 0.093099\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008547, T: 3356628, Avg. loss: 0.088278\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008584, T: 3413520, Avg. loss: 0.087711\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.294181, T: 3470412, Avg. loss: 0.082419\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008678, T: 3527304, Avg. loss: 0.082360\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.285274, T: 3584196, Avg. loss: 0.079316\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008762, T: 3641088, Avg. loss: 0.077903\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008783, T: 3697980, Avg. loss: 0.073030\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.272899, T: 3754872, Avg. loss: 0.071753\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008833, T: 3811764, Avg. loss: 0.068744\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008872, T: 3868656, Avg. loss: 0.065282\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008886, T: 3925548, Avg. loss: 0.066229\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008917, T: 3982440, Avg. loss: 0.066524\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008938, T: 4039332, Avg. loss: 0.060954\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.008954, T: 4096224, Avg. loss: 0.060581\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.229970, T: 4153116, Avg. loss: 0.058282\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.226731, T: 4210008, Avg. loss: 0.055842\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.223583, T: 4266900, Avg. loss: 0.054883\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009058, T: 4323792, Avg. loss: 0.052432\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009081, T: 4380684, Avg. loss: 0.052902\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009106, T: 4437576, Avg. loss: 0.051636\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009132, T: 4494468, Avg. loss: 0.049927\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009151, T: 4551360, Avg. loss: 0.049018\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009155, T: 4608252, Avg. loss: 0.046588\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009173, T: 4665144, Avg. loss: 0.045026\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.201182, T: 4722036, Avg. loss: 0.045288\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009197, T: 4778928, Avg. loss: 0.043775\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009216, T: 4835820, Avg. loss: 0.041702\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.212308, T: 4892712, Avg. loss: 0.041665\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.191502, T: 4949604, Avg. loss: 0.039698\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009253, T: 5006496, Avg. loss: 0.040748\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.205550, T: 5063388, Avg. loss: 0.039635\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009294, T: 5120280, Avg. loss: 0.039088\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.182682, T: 5177172, Avg. loss: 0.035465\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.199228, T: 5234064, Avg. loss: 0.035585\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.178547, T: 5290956, Avg. loss: 0.034854\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009334, T: 5347848, Avg. loss: 0.034544\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009354, T: 5404740, Avg. loss: 0.034196\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009364, T: 5461632, Avg. loss: 0.031953\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009371, T: 5518524, Avg. loss: 0.033144\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009379, T: 5575416, Avg. loss: 0.030634\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.185948, T: 5632308, Avg. loss: 0.030434\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009396, T: 5689200, Avg. loss: 0.029980\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009409, T: 5746092, Avg. loss: 0.028596\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009416, T: 5802984, Avg. loss: 0.027899\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 103\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009424, T: 5859876, Avg. loss: 0.028127\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 104\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009437, T: 5916768, Avg. loss: 0.027075\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 105\n",
            "Norm: 1578.30, NNZs: 1, Bias: -0.157075, T: 5973660, Avg. loss: 0.026463\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 106\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009447, T: 6030552, Avg. loss: 0.024967\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 107\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009452, T: 6087444, Avg. loss: 0.025151\n",
            "Total training time: 0.54 seconds.\n",
            "-- Epoch 108\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009453, T: 6144336, Avg. loss: 0.024824\n",
            "Total training time: 0.54 seconds.\n",
            "-- Epoch 109\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009457, T: 6201228, Avg. loss: 0.024480\n",
            "Total training time: 0.55 seconds.\n",
            "-- Epoch 110\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009469, T: 6258120, Avg. loss: 0.024720\n",
            "Total training time: 0.55 seconds.\n",
            "-- Epoch 111\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009479, T: 6315012, Avg. loss: 0.023255\n",
            "Total training time: 0.56 seconds.\n",
            "-- Epoch 112\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009487, T: 6371904, Avg. loss: 0.022982\n",
            "Total training time: 0.56 seconds.\n",
            "-- Epoch 113\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009487, T: 6428796, Avg. loss: 0.022802\n",
            "Total training time: 0.56 seconds.\n",
            "-- Epoch 114\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009492, T: 6485688, Avg. loss: 0.021897\n",
            "Total training time: 0.57 seconds.\n",
            "-- Epoch 115\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009492, T: 6542580, Avg. loss: 0.021088\n",
            "Total training time: 0.57 seconds.\n",
            "-- Epoch 116\n",
            "Norm: 1578.30, NNZs: 1, Bias: 0.009502, T: 6599472, Avg. loss: 0.021013\n",
            "Total training time: 0.58 seconds.\n",
            "Convergence after 116 epochs took 0.58 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 218.14, NNZs: 1, Bias: -0.006260, T: 56892, Avg. loss: 17.701745\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 286.92, NNZs: 1, Bias: -0.016741, T: 113784, Avg. loss: 8.260915\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 321.42, NNZs: 1, Bias: -4.957369, T: 170676, Avg. loss: 5.321248\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 341.83, NNZs: 1, Bias: 0.000067, T: 227568, Avg. loss: 3.799241\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 354.26, NNZs: 1, Bias: 0.004896, T: 284460, Avg. loss: 2.920451\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 361.83, NNZs: 1, Bias: 2.686085, T: 341352, Avg. loss: 2.354629\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 364.76, NNZs: 1, Bias: 0.005083, T: 398244, Avg. loss: 1.920457\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 367.01, NNZs: 1, Bias: 0.004773, T: 455136, Avg. loss: 1.660255\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 367.43, NNZs: 1, Bias: 0.004337, T: 512028, Avg. loss: 1.441478\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 365.72, NNZs: 1, Bias: -1.660549, T: 568920, Avg. loss: 1.237462\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 361.89, NNZs: 1, Bias: -1.516328, T: 625812, Avg. loss: 1.093321\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 356.77, NNZs: 1, Bias: 0.004930, T: 682704, Avg. loss: 0.963534\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 350.56, NNZs: 1, Bias: -1.291476, T: 739596, Avg. loss: 0.866554\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 344.20, NNZs: 1, Bias: 0.005762, T: 796488, Avg. loss: 0.807961\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 336.69, NNZs: 1, Bias: -1.123807, T: 853380, Avg. loss: 0.743713\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 328.30, NNZs: 1, Bias: -2.117295, T: 910272, Avg. loss: 0.667235\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 319.73, NNZs: 1, Bias: 0.006495, T: 967164, Avg. loss: 0.629238\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 311.00, NNZs: 1, Bias: 0.006592, T: 1024056, Avg. loss: 0.605420\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 301.97, NNZs: 0, Bias: 0.006640, T: 1080948, Avg. loss: 0.538183\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 293.04, NNZs: 1, Bias: 0.006748, T: 1137840, Avg. loss: 0.514802\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 284.19, NNZs: 1, Bias: 0.006764, T: 1194732, Avg. loss: 0.482941\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 275.61, NNZs: 1, Bias: 0.785972, T: 1251624, Avg. loss: 0.452233\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 267.38, NNZs: 1, Bias: 0.006524, T: 1308516, Avg. loss: 0.437713\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 259.38, NNZs: 1, Bias: 0.006560, T: 1365408, Avg. loss: 0.403465\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 251.60, NNZs: 1, Bias: 0.006620, T: 1422300, Avg. loss: 0.374529\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 244.21, NNZs: 1, Bias: 0.006692, T: 1479192, Avg. loss: 0.361243\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 237.19, NNZs: 1, Bias: 0.006734, T: 1536084, Avg. loss: 0.346554\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 230.46, NNZs: 1, Bias: 0.622338, T: 1592976, Avg. loss: 0.324397\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 224.06, NNZs: 1, Bias: 0.006773, T: 1649868, Avg. loss: 0.305461\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 217.99, NNZs: 1, Bias: -0.568533, T: 1706760, Avg. loss: 0.283458\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 212.21, NNZs: 1, Bias: 0.006712, T: 1763652, Avg. loss: 0.276798\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 206.73, NNZs: 1, Bias: -0.533280, T: 1820544, Avg. loss: 0.264931\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 201.54, NNZs: 1, Bias: 0.006712, T: 1877436, Avg. loss: 0.253249\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 196.60, NNZs: 1, Bias: -0.501875, T: 1934328, Avg. loss: 0.243039\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 191.92, NNZs: 1, Bias: 0.006814, T: 1991220, Avg. loss: 0.230679\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 187.46, NNZs: 1, Bias: 0.006850, T: 2048112, Avg. loss: 0.222982\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 183.22, NNZs: 1, Bias: 0.006970, T: 2105004, Avg. loss: 0.201999\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 179.17, NNZs: 1, Bias: 0.007034, T: 2161896, Avg. loss: 0.197481\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 175.31, NNZs: 1, Bias: 0.007140, T: 2218788, Avg. loss: 0.192371\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 171.64, NNZs: 1, Bias: 0.007261, T: 2275680, Avg. loss: 0.181290\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 168.12, NNZs: 1, Bias: 0.007344, T: 2332572, Avg. loss: 0.179022\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 164.76, NNZs: 1, Bias: 0.007386, T: 2389464, Avg. loss: 0.167380\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 161.54, NNZs: 1, Bias: -0.396065, T: 2446356, Avg. loss: 0.160258\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 158.46, NNZs: 1, Bias: 0.007540, T: 2503248, Avg. loss: 0.151962\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 155.49, NNZs: 1, Bias: 0.007588, T: 2560140, Avg. loss: 0.149878\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 152.65, NNZs: 1, Bias: 0.007614, T: 2617032, Avg. loss: 0.148176\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 149.91, NNZs: 1, Bias: 0.007651, T: 2673924, Avg. loss: 0.136822\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 147.29, NNZs: 1, Bias: 0.007704, T: 2730816, Avg. loss: 0.131333\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 144.76, NNZs: 1, Bias: 0.007764, T: 2787708, Avg. loss: 0.126846\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 142.32, NNZs: 1, Bias: 0.007801, T: 2844600, Avg. loss: 0.129000\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 139.97, NNZs: 1, Bias: 0.007844, T: 2901492, Avg. loss: 0.119613\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 137.70, NNZs: 1, Bias: 0.007915, T: 2958384, Avg. loss: 0.113775\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 135.51, NNZs: 1, Bias: 0.007944, T: 3015276, Avg. loss: 0.108240\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 133.40, NNZs: 1, Bias: 0.007995, T: 3072168, Avg. loss: 0.108626\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 131.36, NNZs: 1, Bias: 0.008066, T: 3129060, Avg. loss: 0.102619\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 129.38, NNZs: 1, Bias: 0.008143, T: 3185952, Avg. loss: 0.100364\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 127.47, NNZs: 1, Bias: 0.008194, T: 3242844, Avg. loss: 0.095984\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 125.61, NNZs: 1, Bias: 0.008234, T: 3299736, Avg. loss: 0.092900\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 123.82, NNZs: 1, Bias: 0.008267, T: 3356628, Avg. loss: 0.093264\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 122.08, NNZs: 1, Bias: -0.281979, T: 3413520, Avg. loss: 0.088369\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 120.39, NNZs: 1, Bias: 0.008320, T: 3470412, Avg. loss: 0.085685\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 118.75, NNZs: 1, Bias: 0.008346, T: 3527304, Avg. loss: 0.079945\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 117.16, NNZs: 1, Bias: 0.008390, T: 3584196, Avg. loss: 0.080788\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 115.62, NNZs: 1, Bias: 0.008424, T: 3641088, Avg. loss: 0.081063\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 114.12, NNZs: 1, Bias: -0.259682, T: 3697980, Avg. loss: 0.076953\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 112.66, NNZs: 1, Bias: 0.008478, T: 3754872, Avg. loss: 0.073091\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 111.24, NNZs: 1, Bias: 0.008495, T: 3811764, Avg. loss: 0.070555\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 109.86, NNZs: 1, Bias: 0.008552, T: 3868656, Avg. loss: 0.070265\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 108.52, NNZs: 1, Bias: 0.008596, T: 3925548, Avg. loss: 0.067768\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 107.21, NNZs: 1, Bias: 0.008619, T: 3982440, Avg. loss: 0.067171\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 105.93, NNZs: 1, Bias: 0.008652, T: 4039332, Avg. loss: 0.063244\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 104.69, NNZs: 1, Bias: -0.233569, T: 4096224, Avg. loss: 0.063326\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 103.48, NNZs: 1, Bias: 0.008699, T: 4153116, Avg. loss: 0.057383\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 102.30, NNZs: 1, Bias: 0.008726, T: 4210008, Avg. loss: 0.059465\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 101.14, NNZs: 1, Bias: -0.223877, T: 4266900, Avg. loss: 0.056682\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 100.02, NNZs: 1, Bias: 0.008790, T: 4323792, Avg. loss: 0.054466\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 98.93, NNZs: 1, Bias: 0.008809, T: 4380684, Avg. loss: 0.052588\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 97.85, NNZs: 1, Bias: 0.008841, T: 4437576, Avg. loss: 0.052846\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 96.81, NNZs: 1, Bias: 0.008860, T: 4494468, Avg. loss: 0.049547\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 95.78, NNZs: 1, Bias: 0.008888, T: 4551360, Avg. loss: 0.048949\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 94.79, NNZs: 1, Bias: 0.008906, T: 4608252, Avg. loss: 0.047258\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 93.81, NNZs: 1, Bias: 0.008910, T: 4665144, Avg. loss: 0.046643\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 92.85, NNZs: 1, Bias: 0.008917, T: 4722036, Avg. loss: 0.046296\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 91.92, NNZs: 1, Bias: 0.008943, T: 4778928, Avg. loss: 0.045149\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 91.01, NNZs: 1, Bias: 0.008976, T: 4835820, Avg. loss: 0.044119\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 90.11, NNZs: 1, Bias: 0.008987, T: 4892712, Avg. loss: 0.041843\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 89.24, NNZs: 1, Bias: 0.008999, T: 4949604, Avg. loss: 0.042305\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 88.38, NNZs: 1, Bias: -0.189466, T: 5006496, Avg. loss: 0.040876\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 87.54, NNZs: 1, Bias: 0.009039, T: 5063388, Avg. loss: 0.039801\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 86.72, NNZs: 1, Bias: -0.185059, T: 5120280, Avg. loss: 0.037601\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 85.91, NNZs: 1, Bias: 0.009064, T: 5177172, Avg. loss: 0.037131\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 85.12, NNZs: 1, Bias: 0.009077, T: 5234064, Avg. loss: 0.036607\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 84.35, NNZs: 1, Bias: 0.009093, T: 5290956, Avg. loss: 0.035819\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 83.59, NNZs: 1, Bias: 0.009099, T: 5347848, Avg. loss: 0.034170\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 82.85, NNZs: 1, Bias: 0.009112, T: 5404740, Avg. loss: 0.033574\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 82.12, NNZs: 1, Bias: 0.009136, T: 5461632, Avg. loss: 0.033744\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 81.40, NNZs: 1, Bias: 0.009143, T: 5518524, Avg. loss: 0.032217\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 80.70, NNZs: 1, Bias: 0.009158, T: 5575416, Avg. loss: 0.031108\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 80.01, NNZs: 1, Bias: 0.009172, T: 5632308, Avg. loss: 0.030970\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 79.33, NNZs: 1, Bias: 0.009190, T: 5689200, Avg. loss: 0.030270\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 78.67, NNZs: 1, Bias: 0.009206, T: 5746092, Avg. loss: 0.030845\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 78.01, NNZs: 1, Bias: 0.009218, T: 5802984, Avg. loss: 0.029352\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 103\n",
            "Norm: 77.37, NNZs: 1, Bias: 0.009226, T: 5859876, Avg. loss: 0.028961\n",
            "Total training time: 0.54 seconds.\n",
            "Convergence after 103 epochs took 0.54 seconds\n",
            "-- Epoch 1\n",
            "Norm: 216.73, NNZs: 1, Bias: -22.585083, T: 56892, Avg. loss: 17.638397\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 283.88, NNZs: 1, Bias: 6.875924, T: 113784, Avg. loss: 8.144323\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 318.73, NNZs: 1, Bias: 0.004968, T: 170676, Avg. loss: 5.224049\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 339.46, NNZs: 1, Bias: -3.851860, T: 227568, Avg. loss: 3.773568\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 352.34, NNZs: 1, Bias: 0.006106, T: 284460, Avg. loss: 2.918359\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 360.43, NNZs: 1, Bias: 0.007536, T: 341352, Avg. loss: 2.381665\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 365.59, NNZs: 1, Bias: 2.331787, T: 398244, Avg. loss: 1.990543\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 367.11, NNZs: 1, Bias: -2.048760, T: 455136, Avg. loss: 1.659658\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 367.70, NNZs: 1, Bias: 0.006138, T: 512028, Avg. loss: 1.428414\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 366.10, NNZs: 1, Bias: 0.006189, T: 568920, Avg. loss: 1.245111\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 363.45, NNZs: 1, Bias: 0.005849, T: 625812, Avg. loss: 1.122143\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 358.82, NNZs: 1, Bias: 0.005698, T: 682704, Avg. loss: 0.986644\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 352.47, NNZs: 1, Bias: 0.005462, T: 739596, Avg. loss: 0.883607\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 345.88, NNZs: 1, Bias: 0.005174, T: 796488, Avg. loss: 0.819089\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 338.35, NNZs: 1, Bias: 0.005421, T: 853380, Avg. loss: 0.749786\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 329.78, NNZs: 1, Bias: 0.005421, T: 910272, Avg. loss: 0.686676\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 321.30, NNZs: 1, Bias: -0.995698, T: 967164, Avg. loss: 0.635707\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 312.47, NNZs: 1, Bias: 0.005513, T: 1024056, Avg. loss: 0.596380\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 303.65, NNZs: 0, Bias: 0.904478, T: 1080948, Avg. loss: 0.556413\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 294.74, NNZs: 1, Bias: 0.005909, T: 1137840, Avg. loss: 0.530552\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 286.05, NNZs: 1, Bias: -0.809692, T: 1194732, Avg. loss: 0.502617\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 277.50, NNZs: 1, Bias: 0.005892, T: 1251624, Avg. loss: 0.460533\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 269.20, NNZs: 1, Bias: 0.006018, T: 1308516, Avg. loss: 0.436434\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 261.20, NNZs: 1, Bias: 0.006015, T: 1365408, Avg. loss: 0.411015\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 253.49, NNZs: 1, Bias: 0.006174, T: 1422300, Avg. loss: 0.400880\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 246.07, NNZs: 1, Bias: 0.006243, T: 1479192, Avg. loss: 0.374269\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 238.96, NNZs: 1, Bias: 0.644096, T: 1536084, Avg. loss: 0.347641\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 232.21, NNZs: 1, Bias: 0.006316, T: 1592976, Avg. loss: 0.343835\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 225.78, NNZs: 1, Bias: 0.006524, T: 1649868, Avg. loss: 0.319729\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 219.67, NNZs: 1, Bias: 0.006727, T: 1706760, Avg. loss: 0.300576\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 213.85, NNZs: 1, Bias: 0.006730, T: 1763652, Avg. loss: 0.294064\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 208.33, NNZs: 1, Bias: 0.006684, T: 1820544, Avg. loss: 0.276210\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 203.09, NNZs: 1, Bias: 0.006767, T: 1877436, Avg. loss: 0.265236\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 198.12, NNZs: 1, Bias: 0.006792, T: 1934328, Avg. loss: 0.249669\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 193.40, NNZs: 1, Bias: 0.006811, T: 1991220, Avg. loss: 0.235925\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 188.90, NNZs: 1, Bias: 0.006814, T: 2048112, Avg. loss: 0.228393\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 184.62, NNZs: 1, Bias: 0.006766, T: 2105004, Avg. loss: 0.214566\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 180.55, NNZs: 1, Bias: 0.006728, T: 2161896, Avg. loss: 0.209319\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 176.67, NNZs: 1, Bias: 0.006839, T: 2218788, Avg. loss: 0.202258\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 172.96, NNZs: 1, Bias: 0.006852, T: 2275680, Avg. loss: 0.195947\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 169.42, NNZs: 1, Bias: 0.006867, T: 2332572, Avg. loss: 0.186736\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 166.03, NNZs: 1, Bias: 0.006933, T: 2389464, Avg. loss: 0.179655\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 162.78, NNZs: 1, Bias: -0.396588, T: 2446356, Avg. loss: 0.170029\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 159.68, NNZs: 1, Bias: 0.401551, T: 2503248, Avg. loss: 0.162595\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 156.69, NNZs: 1, Bias: 0.392990, T: 2560140, Avg. loss: 0.156719\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 153.82, NNZs: 1, Bias: -0.370328, T: 2617032, Avg. loss: 0.153230\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 151.07, NNZs: 1, Bias: 0.376901, T: 2673924, Avg. loss: 0.144229\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 148.42, NNZs: 1, Bias: 0.369337, T: 2730816, Avg. loss: 0.139605\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 145.88, NNZs: 1, Bias: 0.007380, T: 2787708, Avg. loss: 0.131504\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 143.41, NNZs: 1, Bias: 0.007454, T: 2844600, Avg. loss: 0.126246\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 141.05, NNZs: 1, Bias: 0.007506, T: 2901492, Avg. loss: 0.127599\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 138.76, NNZs: 1, Bias: -0.326884, T: 2958384, Avg. loss: 0.124927\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 136.56, NNZs: 1, Bias: 0.007601, T: 3015276, Avg. loss: 0.115943\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 134.43, NNZs: 1, Bias: 0.007637, T: 3072168, Avg. loss: 0.115827\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 132.37, NNZs: 1, Bias: 0.007664, T: 3129060, Avg. loss: 0.110283\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 130.38, NNZs: 1, Bias: 0.007715, T: 3185952, Avg. loss: 0.106470\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 128.45, NNZs: 1, Bias: -0.297655, T: 3242844, Avg. loss: 0.100984\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 126.58, NNZs: 1, Bias: 0.007753, T: 3299736, Avg. loss: 0.098823\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 124.77, NNZs: 1, Bias: -0.287377, T: 3356628, Avg. loss: 0.093229\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 123.02, NNZs: 1, Bias: 0.007776, T: 3413520, Avg. loss: 0.093412\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 121.32, NNZs: 1, Bias: -0.277770, T: 3470412, Avg. loss: 0.087667\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 119.67, NNZs: 1, Bias: 0.007802, T: 3527304, Avg. loss: 0.086994\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 118.07, NNZs: 1, Bias: 0.007832, T: 3584196, Avg. loss: 0.085162\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 116.51, NNZs: 1, Bias: 0.007863, T: 3641088, Avg. loss: 0.082843\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 115.00, NNZs: 1, Bias: 0.007877, T: 3697980, Avg. loss: 0.080918\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 113.53, NNZs: 1, Bias: 0.007888, T: 3754872, Avg. loss: 0.075972\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 112.10, NNZs: 1, Bias: 0.007905, T: 3811764, Avg. loss: 0.076177\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 110.71, NNZs: 1, Bias: 0.007928, T: 3868656, Avg. loss: 0.073245\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 109.35, NNZs: 1, Bias: 0.007958, T: 3925548, Avg. loss: 0.071344\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 108.03, NNZs: 1, Bias: 0.257112, T: 3982440, Avg. loss: 0.068233\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 106.75, NNZs: 1, Bias: 0.008011, T: 4039332, Avg. loss: 0.065453\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 105.50, NNZs: 1, Bias: 0.008022, T: 4096224, Avg. loss: 0.064074\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 104.28, NNZs: 1, Bias: 0.008047, T: 4153116, Avg. loss: 0.061883\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 103.09, NNZs: 1, Bias: 0.008068, T: 4210008, Avg. loss: 0.060854\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 101.93, NNZs: 1, Bias: 0.008072, T: 4266900, Avg. loss: 0.058200\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 100.79, NNZs: 1, Bias: 0.008099, T: 4323792, Avg. loss: 0.058182\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 99.69, NNZs: 1, Bias: 0.008104, T: 4380684, Avg. loss: 0.055942\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 98.61, NNZs: 1, Bias: 0.008123, T: 4437576, Avg. loss: 0.054457\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 97.55, NNZs: 1, Bias: 0.008130, T: 4494468, Avg. loss: 0.053722\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 96.52, NNZs: 1, Bias: 0.226343, T: 4551360, Avg. loss: 0.052622\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 95.52, NNZs: 1, Bias: 0.008161, T: 4608252, Avg. loss: 0.051077\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 94.53, NNZs: 1, Bias: 0.008172, T: 4665144, Avg. loss: 0.049967\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 93.57, NNZs: 1, Bias: 0.008197, T: 4722036, Avg. loss: 0.048403\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 92.63, NNZs: 1, Bias: 0.008205, T: 4778928, Avg. loss: 0.049420\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 91.71, NNZs: 1, Bias: 0.008211, T: 4835820, Avg. loss: 0.047009\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 90.81, NNZs: 1, Bias: 0.008235, T: 4892712, Avg. loss: 0.043439\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 89.93, NNZs: 1, Bias: 0.008261, T: 4949604, Avg. loss: 0.043742\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 89.06, NNZs: 1, Bias: 0.008267, T: 5006496, Avg. loss: 0.043622\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 88.22, NNZs: 1, Bias: 0.008290, T: 5063388, Avg. loss: 0.042788\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 87.38, NNZs: 1, Bias: -0.185801, T: 5120280, Avg. loss: 0.040693\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 86.57, NNZs: 1, Bias: 0.008313, T: 5177172, Avg. loss: 0.039706\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 85.78, NNZs: 1, Bias: 0.008328, T: 5234064, Avg. loss: 0.038332\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 85.00, NNZs: 1, Bias: -0.179540, T: 5290956, Avg. loss: 0.038271\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 84.23, NNZs: 1, Bias: 0.008355, T: 5347848, Avg. loss: 0.037970\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 83.48, NNZs: 1, Bias: 0.008364, T: 5404740, Avg. loss: 0.035389\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 82.75, NNZs: 1, Bias: 0.008377, T: 5461632, Avg. loss: 0.036338\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 82.03, NNZs: 1, Bias: 0.008387, T: 5518524, Avg. loss: 0.034609\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 81.32, NNZs: 1, Bias: 0.008395, T: 5575416, Avg. loss: 0.033683\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 80.62, NNZs: 1, Bias: 0.008404, T: 5632308, Avg. loss: 0.032360\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 79.94, NNZs: 1, Bias: 0.008415, T: 5689200, Avg. loss: 0.032599\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 79.27, NNZs: 1, Bias: 0.181497, T: 5746092, Avg. loss: 0.031625\n",
            "Total training time: 0.54 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 78.62, NNZs: 1, Bias: 0.008429, T: 5802984, Avg. loss: 0.031446\n",
            "Total training time: 0.55 seconds.\n",
            "-- Epoch 103\n",
            "Norm: 77.97, NNZs: 1, Bias: 0.008439, T: 5859876, Avg. loss: 0.031070\n",
            "Total training time: 0.55 seconds.\n",
            "-- Epoch 104\n",
            "Norm: 77.34, NNZs: 1, Bias: 0.008447, T: 5916768, Avg. loss: 0.030762\n",
            "Total training time: 0.56 seconds.\n",
            "Convergence after 104 epochs took 0.56 seconds\n",
            "-- Epoch 1\n",
            "Norm: 217.48, NNZs: 1, Bias: 0.015727, T: 56892, Avg. loss: 17.669047\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 284.93, NNZs: 1, Bias: 0.004401, T: 113784, Avg. loss: 8.143681\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 320.83, NNZs: 1, Bias: 4.954953, T: 170676, Avg. loss: 5.241104\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 340.44, NNZs: 1, Bias: 3.863902, T: 227568, Avg. loss: 3.747801\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 352.37, NNZs: 1, Bias: 0.004131, T: 284460, Avg. loss: 2.920324\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 360.63, NNZs: 1, Bias: 0.003945, T: 341352, Avg. loss: 2.361201\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 364.06, NNZs: 1, Bias: 0.004872, T: 398244, Avg. loss: 1.915074\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 364.70, NNZs: 1, Bias: -2.048994, T: 455136, Avg. loss: 1.613199\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 364.40, NNZs: 1, Bias: 0.006823, T: 512028, Avg. loss: 1.416686\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 363.35, NNZs: 0, Bias: 0.007839, T: 568920, Avg. loss: 1.247497\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 360.61, NNZs: 1, Bias: -1.512965, T: 625812, Avg. loss: 1.107355\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 355.56, NNZs: 1, Bias: 0.007941, T: 682704, Avg. loss: 0.959707\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 350.26, NNZs: 1, Bias: 1.304331, T: 739596, Avg. loss: 0.918639\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 343.07, NNZs: 1, Bias: -1.199958, T: 796488, Avg. loss: 0.775809\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 335.48, NNZs: 1, Bias: 0.007698, T: 853380, Avg. loss: 0.732186\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 327.57, NNZs: 1, Bias: 0.007397, T: 910272, Avg. loss: 0.684686\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 318.96, NNZs: 1, Bias: 0.007494, T: 967164, Avg. loss: 0.624488\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 310.42, NNZs: 0, Bias: 0.007603, T: 1024056, Avg. loss: 0.586570\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 301.40, NNZs: 1, Bias: 0.007718, T: 1080948, Avg. loss: 0.542718\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 292.54, NNZs: 1, Bias: -0.847318, T: 1137840, Avg. loss: 0.522255\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 283.86, NNZs: 1, Bias: -0.807653, T: 1194732, Avg. loss: 0.490384\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 275.47, NNZs: 1, Bias: 0.007635, T: 1251624, Avg. loss: 0.464751\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 267.14, NNZs: 1, Bias: 0.007612, T: 1308516, Avg. loss: 0.433869\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 259.18, NNZs: 1, Bias: 0.007806, T: 1365408, Avg. loss: 0.405043\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 251.43, NNZs: 1, Bias: 0.007876, T: 1422300, Avg. loss: 0.382586\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 244.05, NNZs: 1, Bias: 0.007921, T: 1479192, Avg. loss: 0.368566\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 237.01, NNZs: 1, Bias: 0.008077, T: 1536084, Avg. loss: 0.347788\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 230.32, NNZs: 1, Bias: -0.607412, T: 1592976, Avg. loss: 0.326497\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 223.94, NNZs: 1, Bias: 0.008190, T: 1649868, Avg. loss: 0.311830\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 217.89, NNZs: 1, Bias: 0.008373, T: 1706760, Avg. loss: 0.297886\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 212.12, NNZs: 1, Bias: 0.008469, T: 1763652, Avg. loss: 0.276939\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 206.64, NNZs: 1, Bias: 0.008494, T: 1820544, Avg. loss: 0.265639\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 201.44, NNZs: 1, Bias: 0.008548, T: 1877436, Avg. loss: 0.251347\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 196.51, NNZs: 1, Bias: 0.008564, T: 1934328, Avg. loss: 0.243555\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 191.82, NNZs: 1, Bias: 0.008661, T: 1991220, Avg. loss: 0.227518\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 187.36, NNZs: 1, Bias: 0.008710, T: 2048112, Avg. loss: 0.226410\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 183.12, NNZs: 1, Bias: 0.008726, T: 2105004, Avg. loss: 0.212979\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 179.08, NNZs: 1, Bias: 0.464677, T: 2161896, Avg. loss: 0.196857\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 175.23, NNZs: 1, Bias: 0.008763, T: 2218788, Avg. loss: 0.193503\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 171.55, NNZs: 1, Bias: -0.424545, T: 2275680, Avg. loss: 0.187211\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 168.04, NNZs: 1, Bias: 0.008857, T: 2332572, Avg. loss: 0.173897\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 164.68, NNZs: 1, Bias: 0.008914, T: 2389464, Avg. loss: 0.169623\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 161.46, NNZs: 1, Bias: 0.008986, T: 2446356, Avg. loss: 0.161031\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 158.37, NNZs: 1, Bias: 0.009034, T: 2503248, Avg. loss: 0.158599\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 155.41, NNZs: 1, Bias: 0.009099, T: 2560140, Avg. loss: 0.147290\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 152.57, NNZs: 1, Bias: 0.009090, T: 2617032, Avg. loss: 0.148604\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 149.84, NNZs: 1, Bias: -0.360536, T: 2673924, Avg. loss: 0.143600\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 147.21, NNZs: 1, Bias: 0.009102, T: 2730816, Avg. loss: 0.134279\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 144.68, NNZs: 1, Bias: 0.009117, T: 2787708, Avg. loss: 0.129813\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 142.25, NNZs: 1, Bias: -0.338548, T: 2844600, Avg. loss: 0.127305\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 139.90, NNZs: 1, Bias: 0.350135, T: 2901492, Avg. loss: 0.118550\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 137.63, NNZs: 1, Bias: 0.343698, T: 2958384, Avg. loss: 0.118062\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 135.45, NNZs: 1, Bias: 0.009234, T: 3015276, Avg. loss: 0.114179\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 133.33, NNZs: 1, Bias: 0.009249, T: 3072168, Avg. loss: 0.104991\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 131.29, NNZs: 1, Bias: 0.325661, T: 3129060, Avg. loss: 0.105467\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 129.31, NNZs: 1, Bias: 0.009311, T: 3185952, Avg. loss: 0.103022\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 127.40, NNZs: 1, Bias: 0.009347, T: 3242844, Avg. loss: 0.096854\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 125.55, NNZs: 1, Bias: 0.009370, T: 3299736, Avg. loss: 0.094930\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 123.76, NNZs: 1, Bias: 0.009385, T: 3356628, Avg. loss: 0.088782\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 122.02, NNZs: 1, Bias: 0.009423, T: 3413520, Avg. loss: 0.090452\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 120.33, NNZs: 1, Bias: -0.276096, T: 3470412, Avg. loss: 0.086909\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 118.69, NNZs: 1, Bias: 0.009485, T: 3527304, Avg. loss: 0.083953\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 117.11, NNZs: 1, Bias: -0.267043, T: 3584196, Avg. loss: 0.081713\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 115.56, NNZs: 1, Bias: -0.262739, T: 3641088, Avg. loss: 0.080371\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 114.06, NNZs: 1, Bias: -0.258556, T: 3697980, Avg. loss: 0.074163\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 112.61, NNZs: 1, Bias: 0.009582, T: 3754872, Avg. loss: 0.074177\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 111.19, NNZs: 1, Bias: 0.269779, T: 3811764, Avg. loss: 0.073025\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 109.81, NNZs: 1, Bias: 0.009608, T: 3868656, Avg. loss: 0.068773\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 108.46, NNZs: 1, Bias: 0.009631, T: 3925548, Avg. loss: 0.066692\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 107.15, NNZs: 1, Bias: 0.009655, T: 3982440, Avg. loss: 0.064778\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 105.88, NNZs: 1, Bias: 0.009677, T: 4039332, Avg. loss: 0.062660\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 104.64, NNZs: 1, Bias: 0.009684, T: 4096224, Avg. loss: 0.059956\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 103.43, NNZs: 1, Bias: 0.009706, T: 4153116, Avg. loss: 0.060046\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 102.25, NNZs: 1, Bias: 0.009729, T: 4210008, Avg. loss: 0.060840\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 101.10, NNZs: 1, Bias: -0.222890, T: 4266900, Avg. loss: 0.056635\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 99.97, NNZs: 1, Bias: 0.009766, T: 4323792, Avg. loss: 0.056007\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 98.88, NNZs: 1, Bias: 0.009782, T: 4380684, Avg. loss: 0.055065\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 97.81, NNZs: 1, Bias: 0.009794, T: 4437576, Avg. loss: 0.052422\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 96.76, NNZs: 1, Bias: 0.009820, T: 4494468, Avg. loss: 0.051659\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 95.74, NNZs: 1, Bias: 0.009843, T: 4551360, Avg. loss: 0.049413\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 94.74, NNZs: 1, Bias: 0.009854, T: 4608252, Avg. loss: 0.048184\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 93.77, NNZs: 1, Bias: 0.222786, T: 4665144, Avg. loss: 0.046624\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 92.81, NNZs: 1, Bias: 0.009884, T: 4722036, Avg. loss: 0.045821\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 91.88, NNZs: 1, Bias: 0.217778, T: 4778928, Avg. loss: 0.044778\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 90.96, NNZs: 1, Bias: 0.009915, T: 4835820, Avg. loss: 0.042518\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 90.07, NNZs: 1, Bias: 0.213008, T: 4892712, Avg. loss: 0.042490\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 89.19, NNZs: 1, Bias: 0.009955, T: 4949604, Avg. loss: 0.041893\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 88.34, NNZs: 1, Bias: 0.009970, T: 5006496, Avg. loss: 0.039730\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 87.50, NNZs: 1, Bias: 0.402523, T: 5063388, Avg. loss: 0.039655\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 86.67, NNZs: 1, Bias: 0.009998, T: 5120280, Avg. loss: 0.038840\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 85.87, NNZs: 1, Bias: 0.010017, T: 5177172, Avg. loss: 0.037425\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 85.08, NNZs: 1, Bias: 0.010018, T: 5234064, Avg. loss: 0.036750\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 84.31, NNZs: 1, Bias: 0.010041, T: 5290956, Avg. loss: 0.036162\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 83.55, NNZs: 1, Bias: 0.010056, T: 5347848, Avg. loss: 0.035062\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 82.81, NNZs: 1, Bias: 0.010072, T: 5404740, Avg. loss: 0.035124\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 82.08, NNZs: 1, Bias: 0.010072, T: 5461632, Avg. loss: 0.033360\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 81.36, NNZs: 1, Bias: 0.010091, T: 5518524, Avg. loss: 0.031762\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 80.66, NNZs: 1, Bias: 0.010091, T: 5575416, Avg. loss: 0.031318\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 79.97, NNZs: 1, Bias: 0.010099, T: 5632308, Avg. loss: 0.031767\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 79.29, NNZs: 1, Bias: 0.010109, T: 5689200, Avg. loss: 0.031043\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 78.63, NNZs: 1, Bias: 0.010110, T: 5746092, Avg. loss: 0.030062\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 77.98, NNZs: 1, Bias: 0.010121, T: 5802984, Avg. loss: 0.029921\n",
            "Total training time: 0.53 seconds.\n",
            "Convergence after 102 epochs took 0.53 seconds\n",
            "-- Epoch 1\n",
            "Norm: 216.17, NNZs: 1, Bias: 0.031052, T: 56892, Avg. loss: 17.721642\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 283.98, NNZs: 1, Bias: 0.006493, T: 113784, Avg. loss: 8.106469\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 319.74, NNZs: 1, Bias: -9.876984, T: 170676, Avg. loss: 5.208254\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 340.46, NNZs: 1, Bias: 0.007610, T: 227568, Avg. loss: 3.816535\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 352.99, NNZs: 1, Bias: 3.170731, T: 284460, Avg. loss: 2.926605\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 359.86, NNZs: 1, Bias: 2.690723, T: 341352, Avg. loss: 2.347782\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 363.32, NNZs: 1, Bias: 0.008301, T: 398244, Avg. loss: 1.941289\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 366.23, NNZs: 1, Bias: -2.045560, T: 455136, Avg. loss: 1.666921\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 366.85, NNZs: 1, Bias: 1.845990, T: 512028, Avg. loss: 1.457467\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 364.98, NNZs: 1, Bias: 0.005588, T: 568920, Avg. loss: 1.236981\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 361.26, NNZs: 1, Bias: 0.005683, T: 625812, Avg. loss: 1.092801\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 356.59, NNZs: 1, Bias: 0.006128, T: 682704, Avg. loss: 0.980238\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 350.68, NNZs: 1, Bias: 1.302945, T: 739596, Avg. loss: 0.887718\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 344.30, NNZs: 1, Bias: 0.006227, T: 796488, Avg. loss: 0.830682\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 336.90, NNZs: 0, Bias: 1.135795, T: 853380, Avg. loss: 0.750011\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 329.02, NNZs: 1, Bias: 0.005567, T: 910272, Avg. loss: 0.701968\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 320.52, NNZs: 1, Bias: 0.005735, T: 967164, Avg. loss: 0.634502\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 311.71, NNZs: 1, Bias: -0.941473, T: 1024056, Avg. loss: 0.590668\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 302.71, NNZs: 1, Bias: 0.005723, T: 1080948, Avg. loss: 0.560723\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 293.82, NNZs: 1, Bias: 0.005796, T: 1137840, Avg. loss: 0.535121\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 285.12, NNZs: 1, Bias: 0.005987, T: 1194732, Avg. loss: 0.492497\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 276.50, NNZs: 1, Bias: -0.773269, T: 1251624, Avg. loss: 0.460312\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 268.20, NNZs: 1, Bias: 0.006238, T: 1308516, Avg. loss: 0.439060\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 260.20, NNZs: 1, Bias: 0.722050, T: 1365408, Avg. loss: 0.415152\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 252.50, NNZs: 1, Bias: -1.369326, T: 1422300, Avg. loss: 0.379601\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 245.14, NNZs: 1, Bias: 0.006303, T: 1479192, Avg. loss: 0.371528\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 238.06, NNZs: 1, Bias: 0.644383, T: 1536084, Avg. loss: 0.345700\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 231.31, NNZs: 1, Bias: 0.006527, T: 1592976, Avg. loss: 0.332902\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 224.91, NNZs: 1, Bias: 0.006489, T: 1649868, Avg. loss: 0.303861\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 218.80, NNZs: 1, Bias: 0.006566, T: 1706760, Avg. loss: 0.296632\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 213.00, NNZs: 1, Bias: 0.006587, T: 1763652, Avg. loss: 0.286887\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 207.51, NNZs: 1, Bias: 0.006721, T: 1820544, Avg. loss: 0.275281\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 202.30, NNZs: 1, Bias: 1.054401, T: 1877436, Avg. loss: 0.259525\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 197.34, NNZs: 1, Bias: 0.006728, T: 1934328, Avg. loss: 0.245684\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 192.62, NNZs: 1, Bias: -0.487479, T: 1991220, Avg. loss: 0.233558\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 188.16, NNZs: 1, Bias: 0.006892, T: 2048112, Avg. loss: 0.231753\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 183.89, NNZs: 1, Bias: 0.006924, T: 2105004, Avg. loss: 0.220278\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 179.83, NNZs: 1, Bias: 0.007105, T: 2161896, Avg. loss: 0.211691\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 175.97, NNZs: 1, Bias: 0.007114, T: 2218788, Avg. loss: 0.201956\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 172.27, NNZs: 1, Bias: 0.007125, T: 2275680, Avg. loss: 0.193620\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 168.74, NNZs: 1, Bias: 0.430158, T: 2332572, Avg. loss: 0.183236\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 165.37, NNZs: 1, Bias: 0.007288, T: 2389464, Avg. loss: 0.175154\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 162.13, NNZs: 1, Bias: 0.007353, T: 2446356, Avg. loss: 0.166352\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 159.04, NNZs: 1, Bias: 0.007440, T: 2503248, Avg. loss: 0.162364\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 156.07, NNZs: 1, Bias: -0.378332, T: 2560140, Avg. loss: 0.155077\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 153.21, NNZs: 1, Bias: 0.385088, T: 2617032, Avg. loss: 0.150224\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 150.47, NNZs: 1, Bias: 0.007580, T: 2673924, Avg. loss: 0.144503\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 147.83, NNZs: 1, Bias: 0.007555, T: 2730816, Avg. loss: 0.138267\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 145.30, NNZs: 1, Bias: 0.007597, T: 2787708, Avg. loss: 0.136100\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 142.84, NNZs: 1, Bias: -0.340024, T: 2844600, Avg. loss: 0.128567\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 140.48, NNZs: 1, Bias: -0.333240, T: 2901492, Avg. loss: 0.129034\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 138.21, NNZs: 1, Bias: -0.326701, T: 2958384, Avg. loss: 0.120342\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 136.01, NNZs: 1, Bias: 0.007780, T: 3015276, Avg. loss: 0.114947\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 133.89, NNZs: 1, Bias: 0.007799, T: 3072168, Avg. loss: 0.109184\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 131.84, NNZs: 1, Bias: 0.007840, T: 3129060, Avg. loss: 0.109011\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 129.86, NNZs: 1, Bias: 0.007873, T: 3185952, Avg. loss: 0.105880\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 127.94, NNZs: 1, Bias: 0.007907, T: 3242844, Avg. loss: 0.102000\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 126.07, NNZs: 1, Bias: 0.007954, T: 3299736, Avg. loss: 0.098169\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 124.27, NNZs: 1, Bias: -0.287177, T: 3356628, Avg. loss: 0.091151\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 122.53, NNZs: 1, Bias: 0.588542, T: 3413520, Avg. loss: 0.092773\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 120.84, NNZs: 1, Bias: 0.008043, T: 3470412, Avg. loss: 0.090936\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 119.19, NNZs: 1, Bias: 0.008075, T: 3527304, Avg. loss: 0.084596\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 117.60, NNZs: 1, Bias: 0.008102, T: 3584196, Avg. loss: 0.084811\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 116.05, NNZs: 1, Bias: 0.008119, T: 3641088, Avg. loss: 0.079910\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 114.54, NNZs: 1, Bias: 0.008144, T: 3697980, Avg. loss: 0.077038\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 113.08, NNZs: 1, Bias: 0.008159, T: 3754872, Avg. loss: 0.077003\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 111.65, NNZs: 1, Bias: 0.008176, T: 3811764, Avg. loss: 0.072888\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 110.27, NNZs: 1, Bias: 0.008218, T: 3868656, Avg. loss: 0.071955\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 108.92, NNZs: 1, Bias: 0.008239, T: 3925548, Avg. loss: 0.069418\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 107.60, NNZs: 1, Bias: 0.008269, T: 3982440, Avg. loss: 0.071173\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 106.32, NNZs: 1, Bias: 0.008285, T: 4039332, Avg. loss: 0.067050\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 105.08, NNZs: 1, Bias: -0.233942, T: 4096224, Avg. loss: 0.062717\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 103.86, NNZs: 1, Bias: 0.008327, T: 4153116, Avg. loss: 0.065746\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 102.68, NNZs: 1, Bias: 0.008356, T: 4210008, Avg. loss: 0.061879\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 101.52, NNZs: 1, Bias: -0.224277, T: 4266900, Avg. loss: 0.061041\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 100.39, NNZs: 1, Bias: 0.008360, T: 4323792, Avg. loss: 0.060135\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 99.29, NNZs: 1, Bias: 0.008388, T: 4380684, Avg. loss: 0.056121\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 98.22, NNZs: 1, Bias: 0.008403, T: 4437576, Avg. loss: 0.055754\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 97.17, NNZs: 1, Bias: 0.008413, T: 4494468, Avg. loss: 0.052475\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 96.14, NNZs: 1, Bias: 0.008417, T: 4551360, Avg. loss: 0.052427\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 95.14, NNZs: 1, Bias: 0.008431, T: 4608252, Avg. loss: 0.050337\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 94.16, NNZs: 1, Bias: 0.008443, T: 4665144, Avg. loss: 0.050204\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 93.20, NNZs: 1, Bias: 0.008464, T: 4722036, Avg. loss: 0.047767\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 92.26, NNZs: 1, Bias: 0.008475, T: 4778928, Avg. loss: 0.048210\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 91.34, NNZs: 1, Bias: 0.008487, T: 4835820, Avg. loss: 0.046198\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 90.44, NNZs: 1, Bias: 0.414652, T: 4892712, Avg. loss: 0.044399\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 89.57, NNZs: 1, Bias: 0.008524, T: 4949604, Avg. loss: 0.044895\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 88.71, NNZs: 1, Bias: 0.008533, T: 5006496, Avg. loss: 0.041591\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 87.86, NNZs: 1, Bias: 0.008537, T: 5063388, Avg. loss: 0.041623\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 87.04, NNZs: 1, Bias: -0.185563, T: 5120280, Avg. loss: 0.040143\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 86.23, NNZs: 1, Bias: 0.008561, T: 5177172, Avg. loss: 0.039152\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 85.44, NNZs: 1, Bias: 0.198492, T: 5234064, Avg. loss: 0.039542\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 84.66, NNZs: 1, Bias: 0.196471, T: 5290956, Avg. loss: 0.037774\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 83.90, NNZs: 1, Bias: -0.177286, T: 5347848, Avg. loss: 0.036926\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 83.15, NNZs: 1, Bias: -0.175332, T: 5404740, Avg. loss: 0.034825\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 82.42, NNZs: 1, Bias: -0.173412, T: 5461632, Avg. loss: 0.034558\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 81.70, NNZs: 1, Bias: 0.008641, T: 5518524, Avg. loss: 0.034769\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 81.00, NNZs: 1, Bias: 0.008646, T: 5575416, Avg. loss: 0.033417\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 80.31, NNZs: 1, Bias: -0.167915, T: 5632308, Avg. loss: 0.033039\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 79.63, NNZs: 1, Bias: 0.008656, T: 5689200, Avg. loss: 0.031738\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 78.96, NNZs: 1, Bias: -0.164422, T: 5746092, Avg. loss: 0.031131\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 78.31, NNZs: 1, Bias: 0.008666, T: 5802984, Avg. loss: 0.029912\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 103\n",
            "Norm: 77.66, NNZs: 1, Bias: -0.161059, T: 5859876, Avg. loss: 0.031559\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 104\n",
            "Norm: 77.03, NNZs: 1, Bias: 0.008683, T: 5916768, Avg. loss: 0.029626\n",
            "Total training time: 0.54 seconds.\n",
            "-- Epoch 105\n",
            "Norm: 76.41, NNZs: 1, Bias: 0.008687, T: 5973660, Avg. loss: 0.028783\n",
            "Total training time: 0.54 seconds.\n",
            "-- Epoch 106\n",
            "Norm: 75.80, NNZs: 1, Bias: 0.008699, T: 6030552, Avg. loss: 0.028384\n",
            "Total training time: 0.54 seconds.\n",
            "-- Epoch 107\n",
            "Norm: 75.20, NNZs: 1, Bias: 0.008715, T: 6087444, Avg. loss: 0.027358\n",
            "Total training time: 0.55 seconds.\n",
            "-- Epoch 108\n",
            "Norm: 74.61, NNZs: 1, Bias: 0.008720, T: 6144336, Avg. loss: 0.026884\n",
            "Total training time: 0.55 seconds.\n",
            "-- Epoch 109\n",
            "Norm: 74.03, NNZs: 1, Bias: 0.008728, T: 6201228, Avg. loss: 0.026880\n",
            "Total training time: 0.56 seconds.\n",
            "-- Epoch 110\n",
            "Norm: 73.46, NNZs: 1, Bias: 0.167721, T: 6258120, Avg. loss: 0.026828\n",
            "Total training time: 0.56 seconds.\n",
            "-- Epoch 111\n",
            "Norm: 72.90, NNZs: 1, Bias: 0.008733, T: 6315012, Avg. loss: 0.025527\n",
            "Total training time: 0.56 seconds.\n",
            "-- Epoch 112\n",
            "Norm: 72.35, NNZs: 1, Bias: 0.008738, T: 6371904, Avg. loss: 0.025455\n",
            "Total training time: 0.57 seconds.\n",
            "-- Epoch 113\n",
            "Norm: 71.81, NNZs: 1, Bias: 0.008743, T: 6428796, Avg. loss: 0.025052\n",
            "Total training time: 0.57 seconds.\n",
            "-- Epoch 114\n",
            "Norm: 71.28, NNZs: 1, Bias: 0.008742, T: 6485688, Avg. loss: 0.024290\n",
            "Total training time: 0.58 seconds.\n",
            "-- Epoch 115\n",
            "Norm: 70.75, NNZs: 1, Bias: 0.008741, T: 6542580, Avg. loss: 0.023448\n",
            "Total training time: 0.58 seconds.\n",
            "-- Epoch 116\n",
            "Norm: 70.23, NNZs: 1, Bias: -0.142064, T: 6599472, Avg. loss: 0.023385\n",
            "Total training time: 0.59 seconds.\n",
            "Convergence after 116 epochs took 0.59 seconds\n",
            "-- Epoch 1\n",
            "Norm: 214.69, NNZs: 1, Bias: 11.309582, T: 56892, Avg. loss: 17.626829\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 284.15, NNZs: 1, Bias: 6.861673, T: 113784, Avg. loss: 8.219508\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 320.60, NNZs: 1, Bias: -0.011638, T: 170676, Avg. loss: 5.303498\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 341.86, NNZs: 1, Bias: -0.003479, T: 227568, Avg. loss: 3.836469\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 353.01, NNZs: 1, Bias: -3.163781, T: 284460, Avg. loss: 2.878114\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 360.49, NNZs: 1, Bias: 2.682238, T: 341352, Avg. loss: 2.338508\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 364.58, NNZs: 1, Bias: -2.320849, T: 398244, Avg. loss: 1.962541\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 366.62, NNZs: 1, Bias: 2.060548, T: 455136, Avg. loss: 1.646241\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 366.44, NNZs: 1, Bias: 0.006334, T: 512028, Avg. loss: 1.442656\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 364.07, NNZs: 1, Bias: 0.005985, T: 568920, Avg. loss: 1.222601\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 360.26, NNZs: 1, Bias: 0.006309, T: 625812, Avg. loss: 1.068596\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 355.34, NNZs: 1, Bias: 0.006005, T: 682704, Avg. loss: 0.979895\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 349.31, NNZs: 1, Bias: 0.006176, T: 739596, Avg. loss: 0.858885\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 342.79, NNZs: 1, Bias: 0.006410, T: 796488, Avg. loss: 0.803718\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 334.75, NNZs: 1, Bias: 2.266181, T: 853380, Avg. loss: 0.714905\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 326.35, NNZs: 1, Bias: 1.068160, T: 910272, Avg. loss: 0.676013\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 317.76, NNZs: 1, Bias: -0.994584, T: 967164, Avg. loss: 0.620106\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 309.22, NNZs: 0, Bias: 0.006923, T: 1024056, Avg. loss: 0.589445\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 300.28, NNZs: 0, Bias: 0.007055, T: 1080948, Avg. loss: 0.539895\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 291.54, NNZs: 1, Bias: 0.007042, T: 1137840, Avg. loss: 0.516740\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 282.78, NNZs: 1, Bias: 0.007155, T: 1194732, Avg. loss: 0.483129\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 274.23, NNZs: 1, Bias: -0.772041, T: 1251624, Avg. loss: 0.458859\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 266.02, NNZs: 1, Bias: 0.753529, T: 1308516, Avg. loss: 0.422898\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 258.01, NNZs: 1, Bias: 0.007519, T: 1365408, Avg. loss: 0.401946\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 250.36, NNZs: 1, Bias: 0.007467, T: 1422300, Avg. loss: 0.371316\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 243.02, NNZs: 0, Bias: 0.007666, T: 1479192, Avg. loss: 0.363084\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 236.03, NNZs: 0, Bias: 0.007792, T: 1536084, Avg. loss: 0.345863\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 229.35, NNZs: 1, Bias: -0.607697, T: 1592976, Avg. loss: 0.325258\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 222.99, NNZs: 1, Bias: 0.007845, T: 1649868, Avg. loss: 0.307367\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 216.94, NNZs: 1, Bias: 0.007858, T: 1706760, Avg. loss: 0.280702\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 211.21, NNZs: 1, Bias: -0.549142, T: 1763652, Avg. loss: 0.276856\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 205.77, NNZs: 1, Bias: 0.007879, T: 1820544, Avg. loss: 0.267986\n",
            "Total training time: 0.16 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 200.60, NNZs: 1, Bias: 0.007904, T: 1877436, Avg. loss: 0.251335\n",
            "Total training time: 0.17 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 195.68, NNZs: 1, Bias: -0.500713, T: 1934328, Avg. loss: 0.237894\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 191.01, NNZs: 1, Bias: 0.008013, T: 1991220, Avg. loss: 0.225901\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 186.57, NNZs: 1, Bias: 0.488832, T: 2048112, Avg. loss: 0.208878\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 182.34, NNZs: 1, Bias: 0.476082, T: 2105004, Avg. loss: 0.203038\n",
            "Total training time: 0.19 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 178.32, NNZs: 1, Bias: -0.447802, T: 2161896, Avg. loss: 0.200247\n",
            "Total training time: 0.20 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 174.49, NNZs: 1, Bias: 0.008077, T: 2218788, Avg. loss: 0.192455\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 170.82, NNZs: 1, Bias: 0.008105, T: 2275680, Avg. loss: 0.178205\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 167.32, NNZs: 1, Bias: 0.008177, T: 2332572, Avg. loss: 0.172198\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 163.98, NNZs: 1, Bias: 0.008189, T: 2389464, Avg. loss: 0.168039\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 160.77, NNZs: 1, Bias: 0.008218, T: 2446356, Avg. loss: 0.162206\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 157.70, NNZs: 1, Bias: 0.797180, T: 2503248, Avg. loss: 0.153069\n",
            "Total training time: 0.24 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 154.75, NNZs: 1, Bias: 0.008240, T: 2560140, Avg. loss: 0.150328\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 151.92, NNZs: 1, Bias: 0.008298, T: 2617032, Avg. loss: 0.142209\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 149.20, NNZs: 1, Bias: 0.008370, T: 2673924, Avg. loss: 0.139435\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 146.59, NNZs: 1, Bias: 0.008436, T: 2730816, Avg. loss: 0.131780\n",
            "Total training time: 0.26 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 144.07, NNZs: 1, Bias: -0.346253, T: 2787708, Avg. loss: 0.130469\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 141.64, NNZs: 1, Bias: 0.008426, T: 2844600, Avg. loss: 0.119436\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 139.31, NNZs: 1, Bias: 0.349381, T: 2901492, Avg. loss: 0.120856\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 137.05, NNZs: 1, Bias: -0.325981, T: 2958384, Avg. loss: 0.115198\n",
            "Total training time: 0.28 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 134.87, NNZs: 1, Bias: 0.008503, T: 3015276, Avg. loss: 0.109900\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 132.77, NNZs: 1, Bias: -0.313659, T: 3072168, Avg. loss: 0.103718\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 130.74, NNZs: 1, Bias: -0.307806, T: 3129060, Avg. loss: 0.103463\n",
            "Total training time: 0.29 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 128.77, NNZs: 1, Bias: 0.008629, T: 3185952, Avg. loss: 0.102273\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 126.86, NNZs: 1, Bias: 0.008628, T: 3242844, Avg. loss: 0.098067\n",
            "Total training time: 0.30 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 125.02, NNZs: 1, Bias: 0.008679, T: 3299736, Avg. loss: 0.093275\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 123.23, NNZs: 1, Bias: 0.008707, T: 3356628, Avg. loss: 0.090700\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 121.50, NNZs: 1, Bias: 0.008719, T: 3413520, Avg. loss: 0.084879\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 119.82, NNZs: 1, Bias: 0.008737, T: 3470412, Avg. loss: 0.084068\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 118.19, NNZs: 1, Bias: 0.008755, T: 3527304, Avg. loss: 0.080877\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 116.61, NNZs: 1, Bias: 0.285348, T: 3584196, Avg. loss: 0.079750\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 115.07, NNZs: 1, Bias: 0.008806, T: 3641088, Avg. loss: 0.077334\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 113.58, NNZs: 1, Bias: 0.008839, T: 3697980, Avg. loss: 0.073507\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 112.12, NNZs: 1, Bias: 0.008859, T: 3754872, Avg. loss: 0.073559\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 110.71, NNZs: 1, Bias: 0.008869, T: 3811764, Avg. loss: 0.070516\n",
            "Total training time: 0.36 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 109.34, NNZs: 1, Bias: 0.008887, T: 3868656, Avg. loss: 0.067326\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 108.00, NNZs: 1, Bias: 0.008907, T: 3925548, Avg. loss: 0.064224\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 106.70, NNZs: 1, Bias: 0.008929, T: 3982440, Avg. loss: 0.062796\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 105.43, NNZs: 1, Bias: 0.008965, T: 4039332, Avg. loss: 0.063259\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 104.20, NNZs: 1, Bias: 0.251232, T: 4096224, Avg. loss: 0.060051\n",
            "Total training time: 0.38 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 102.99, NNZs: 1, Bias: -0.229969, T: 4153116, Avg. loss: 0.057291\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 101.81, NNZs: 1, Bias: 0.009015, T: 4210008, Avg. loss: 0.058704\n",
            "Total training time: 0.39 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 100.67, NNZs: 1, Bias: 0.009037, T: 4266900, Avg. loss: 0.054861\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 99.55, NNZs: 1, Bias: 0.238654, T: 4323792, Avg. loss: 0.053231\n",
            "Total training time: 0.40 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 98.46, NNZs: 1, Bias: 0.009078, T: 4380684, Avg. loss: 0.052428\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 97.39, NNZs: 1, Bias: 0.009100, T: 4437576, Avg. loss: 0.051345\n",
            "Total training time: 0.41 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 96.35, NNZs: 1, Bias: 0.009131, T: 4494468, Avg. loss: 0.049066\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 95.33, NNZs: 1, Bias: 0.009145, T: 4551360, Avg. loss: 0.046834\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 94.34, NNZs: 1, Bias: 0.009150, T: 4608252, Avg. loss: 0.046110\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 93.37, NNZs: 1, Bias: 0.009166, T: 4665144, Avg. loss: 0.046767\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 92.41, NNZs: 1, Bias: -0.201180, T: 4722036, Avg. loss: 0.044711\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 91.48, NNZs: 1, Bias: 0.217083, T: 4778928, Avg. loss: 0.043068\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 90.57, NNZs: 1, Bias: 0.214671, T: 4835820, Avg. loss: 0.043014\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 89.69, NNZs: 1, Bias: 0.009234, T: 4892712, Avg. loss: 0.041384\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 88.81, NNZs: 1, Bias: 0.009257, T: 4949604, Avg. loss: 0.041016\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 87.96, NNZs: 1, Bias: 0.009274, T: 5006496, Avg. loss: 0.040460\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 87.12, NNZs: 1, Bias: -0.186975, T: 5063388, Avg. loss: 0.037011\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 86.31, NNZs: 1, Bias: -0.184790, T: 5120280, Avg. loss: 0.037354\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 85.51, NNZs: 1, Bias: 0.009323, T: 5177172, Avg. loss: 0.036525\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 84.72, NNZs: 1, Bias: 0.009337, T: 5234064, Avg. loss: 0.036407\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 83.95, NNZs: 1, Bias: 0.009348, T: 5290956, Avg. loss: 0.034052\n",
            "Total training time: 0.47 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 83.19, NNZs: 1, Bias: 0.009359, T: 5347848, Avg. loss: 0.035209\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 95\n",
            "Norm: 82.45, NNZs: 1, Bias: 0.009365, T: 5404740, Avg. loss: 0.033666\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 96\n",
            "Norm: 81.73, NNZs: 1, Bias: 0.009377, T: 5461632, Avg. loss: 0.031992\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 97\n",
            "Norm: 81.02, NNZs: 1, Bias: 0.009384, T: 5518524, Avg. loss: 0.030729\n",
            "Total training time: 0.49 seconds.\n",
            "-- Epoch 98\n",
            "Norm: 80.32, NNZs: 1, Bias: 0.009394, T: 5575416, Avg. loss: 0.030498\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 99\n",
            "Norm: 79.63, NNZs: 1, Bias: 0.009406, T: 5632308, Avg. loss: 0.030060\n",
            "Total training time: 0.50 seconds.\n",
            "-- Epoch 100\n",
            "Norm: 78.96, NNZs: 1, Bias: 0.009420, T: 5689200, Avg. loss: 0.028839\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 101\n",
            "Norm: 78.30, NNZs: 1, Bias: 0.009430, T: 5746092, Avg. loss: 0.029418\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 102\n",
            "Norm: 77.65, NNZs: 1, Bias: 0.009445, T: 5802984, Avg. loss: 0.028717\n",
            "Total training time: 0.51 seconds.\n",
            "-- Epoch 103\n",
            "Norm: 77.01, NNZs: 1, Bias: 0.179192, T: 5859876, Avg. loss: 0.027178\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 104\n",
            "Norm: 76.38, NNZs: 1, Bias: 0.009466, T: 5916768, Avg. loss: 0.026186\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 105\n",
            "Norm: 75.77, NNZs: 1, Bias: 0.009471, T: 5973660, Avg. loss: 0.026799\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 106\n",
            "Norm: 75.16, NNZs: 1, Bias: 0.009481, T: 6030552, Avg. loss: 0.025537\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 107\n",
            "Norm: 74.57, NNZs: 1, Bias: 0.009496, T: 6087444, Avg. loss: 0.024974\n",
            "Total training time: 0.54 seconds.\n",
            "-- Epoch 108\n",
            "Norm: 73.98, NNZs: 1, Bias: 0.009500, T: 6144336, Avg. loss: 0.024355\n",
            "Total training time: 0.54 seconds.\n",
            "Convergence after 108 epochs took 0.54 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000881, T: 56892, Avg. loss: 0.002557\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001329, T: 113784, Avg. loss: 0.001223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002144, T: 170676, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000634, T: 227568, Avg. loss: 0.001223\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000252, T: 284460, Avg. loss: 0.001223\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000416, T: 341352, Avg. loss: 0.001223\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000351, T: 398244, Avg. loss: 0.001223\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001039, T: 56892, Avg. loss: 0.002547\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001648, T: 113784, Avg. loss: 0.001252\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001527, T: 170676, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000587, T: 227568, Avg. loss: 0.001252\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000526, T: 284460, Avg. loss: 0.001252\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000364, T: 341352, Avg. loss: 0.001252\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000516, T: 398244, Avg. loss: 0.001252\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001116, T: 56892, Avg. loss: 0.002568\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000118, T: 113784, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000233, T: 170676, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000942, T: 227568, Avg. loss: 0.001247\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000266, T: 284460, Avg. loss: 0.001247\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000848, T: 341352, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000608, T: 398244, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000802, T: 56892, Avg. loss: 0.002562\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000268, T: 113784, Avg. loss: 0.001255\n",
            "Total training time: 0.02 seconds."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000422, T: 170676, Avg. loss: 0.001255\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000568, T: 227568, Avg. loss: 0.001255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000178, T: 284460, Avg. loss: 0.001255\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001165, T: 341352, Avg. loss: 0.001255\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001189, T: 398244, Avg. loss: 0.001255\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 7 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000345, T: 56892, Avg. loss: 0.002294\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000582, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000381, T: 170676, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001147, T: 227568, Avg. loss: 0.001045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000351, T: 284460, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000730, T: 341352, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000412, T: 398244, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000273, T: 56892, Avg. loss: 0.002570\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000264, T: 113784, Avg. loss: 0.001223\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000436, T: 170676, Avg. loss: 0.001223\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000032, T: 227568, Avg. loss: 0.001223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000235, T: 284460, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001908, T: 341352, Avg. loss: 0.001222\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000724, T: 398244, Avg. loss: 0.001222\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001787, T: 56892, Avg. loss: 0.002547\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.000468, T: 113784, Avg. loss: 0.001252\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000034, T: 170676, Avg. loss: 0.001252\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000389, T: 227568, Avg. loss: 0.001252\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000718, T: 284460, Avg. loss: 0.001252\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001355, T: 341352, Avg. loss: 0.001252\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001008, T: 398244, Avg. loss: 0.001252\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000959, T: 56892, Avg. loss: 0.002611\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000443, T: 113784, Avg. loss: 0.001247\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001548, T: 170676, Avg. loss: 0.001247\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001369, T: 227568, Avg. loss: 0.001247\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000169, T: 284460, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000186, T: 341352, Avg. loss: 0.001247\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001142, T: 398244, Avg. loss: 0.001247\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002005, T: 56892, Avg. loss: 0.002643\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000745, T: 113784, Avg. loss: 0.001255\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000200, T: 170676, Avg. loss: 0.001255\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000402, T: 227568, Avg. loss: 0.001255\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000853, T: 284460, Avg. loss: 0.001255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000260, T: 341352, Avg. loss: 0.001255\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001570, T: 398244, Avg. loss: 0.001255\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000173, T: 56892, Avg. loss: 0.002451\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: 0.000443, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000304, T: 170676, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001051, T: 227568, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000317, T: 284460, Avg. loss: 0.001045\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001101, T: 341352, Avg. loss: 0.001045\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000005, T: 398244, Avg. loss: 0.001045\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000045, T: 56892, Avg. loss: 0.002603\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000294, T: 113784, Avg. loss: 0.001223\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000062, T: 170676, Avg. loss: 0.001223\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000505, T: 227568, Avg. loss: 0.001223\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000556, T: 284460, Avg. loss: 0.001223\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000446, T: 341352, Avg. loss: 0.001222\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001575, T: 398244, Avg. loss: 0.001222\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000050, T: 56892, Avg. loss: 0.002599\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001368, T: 113784, Avg. loss: 0.001252\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000026, T: 170676, Avg. loss: 0.001252\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000350, T: 227568, Avg. loss: 0.001252\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000604, T: 284460, Avg. loss: 0.001252\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000660, T: 341352, Avg. loss: 0.001252\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000242, T: 398244, Avg. loss: 0.001252\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000293, T: 56892, Avg. loss: 0.002577\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: 0.001511, T: 113784, Avg. loss: 0.001247\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001405, T: 170676, Avg. loss: 0.001247\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000672, T: 227568, Avg. loss: 0.001247\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000292, T: 284460, Avg. loss: 0.001247\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000337, T: 341352, Avg. loss: 0.001247\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000851, T: 398244, Avg. loss: 0.001247\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000647, T: 56892, Avg. loss: 0.002661\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000420, T: 113784, Avg. loss: 0.001255\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000401, T: 170676, Avg. loss: 0.001255\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001372, T: 227568, Avg. loss: 0.001255\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000820, T: 284460, Avg. loss: 0.001255\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001548, T: 341352, Avg. loss: 0.001255\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000514, T: 398244, Avg. loss: 0.001255\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001462, T: 56892, Avg. loss: 0.002421\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000137, T: 113784, Avg. loss: 0.001045\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000110, T: 170676, Avg. loss: 0.001045\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000093, T: 227568, Avg. loss: 0.001045\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001181, T: 284460, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.001282, T: 341352, Avg. loss: 0.001045\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000021, T: 398244, Avg. loss: 0.001045\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.002216, T: 56892, Avg. loss: 0.005722\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001130, T: 113784, Avg. loss: 0.001002\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000685, T: 170676, Avg. loss: 0.001002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000915, T: 227568, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000493, T: 284460, Avg. loss: 0.001002\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001094, T: 341352, Avg. loss: 0.001002\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000948, T: 398244, Avg. loss: 0.001002\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002250, T: 56892, Avg. loss: 0.005737\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001527, T: 113784, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002455, T: 170676, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002312, T: 227568, Avg. loss: 0.001033\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002454, T: 284460, Avg. loss: 0.001033\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001426, T: 341352, Avg. loss: 0.001033\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001714, T: 398244, Avg. loss: 0.001033\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000491, T: 56892, Avg. loss: 0.005702\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001524, T: 113784, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001501, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001468, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001228, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000831, T: 341352, Avg. loss: 0.001010\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001313, T: 398244, Avg. loss: 0.001010\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002577, T: 56892, Avg. loss: 0.005769\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.002218, T: 113784, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001534, T: 170676, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001697, T: 227568, Avg. loss: 0.001031\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001735, T: 284460, Avg. loss: 0.001031\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002043, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.003114, T: 398244, Avg. loss: 0.001031\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001192, T: 56892, Avg. loss: 0.005614\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002913, T: 113784, Avg. loss: 0.000932\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001229, T: 170676, Avg. loss: 0.000933\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001505, T: 227568, Avg. loss: 0.000932\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001353, T: 284460, Avg. loss: 0.000933\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001368, T: 341352, Avg. loss: 0.000932\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001787, T: 398244, Avg. loss: 0.000932\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000631, T: 56892, Avg. loss: 0.005677\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001912, T: 113784, Avg. loss: 0.001002\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001969, T: 170676, Avg. loss: 0.001002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001889, T: 227568, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002200, T: 284460, Avg. loss: 0.001002\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001682, T: 341352, Avg. loss: 0.001002\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000683, T: 398244, Avg. loss: 0.001002\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002655, T: 56892, Avg. loss: 0.005722\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.001990, T: 113784, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002796, T: 170676, Avg. loss: 0.001034\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001343, T: 227568, Avg. loss: 0.001033\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002239, T: 284460, Avg. loss: 0.001033\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001952, T: 341352, Avg. loss: 0.001033\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002945, T: 398244, Avg. loss: 0.001033\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000218, T: 56892, Avg. loss: 0.005727\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001218, T: 113784, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001123, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001129, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001280, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000373, T: 341352, Avg. loss: 0.001010\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000722, T: 398244, Avg. loss: 0.001010\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002716, T: 56892, Avg. loss: 0.005720\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001497, T: 113784, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001952, T: 170676, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002444, T: 227568, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001288, T: 284460, Avg. loss: 0.001031\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002455, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002117, T: 398244, Avg. loss: 0.001031\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001565, T: 56892, Avg. loss: 0.005642\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.001455, T: 113784, Avg. loss: 0.000933\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001072, T: 170676, Avg. loss: 0.000933\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000668, T: 227568, Avg. loss: 0.000933\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001127, T: 284460, Avg. loss: 0.000933\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001950, T: 341352, Avg. loss: 0.000932\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001194, T: 398244, Avg. loss: 0.000932\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 7 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002411, T: 56892, Avg. loss: 0.005693\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002330, T: 113784, Avg. loss: 0.001002\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001870, T: 170676, Avg. loss: 0.001002\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002149, T: 227568, Avg. loss: 0.001002\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001431, T: 284460, Avg. loss: 0.001002\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000601, T: 341352, Avg. loss: 0.001002\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001529, T: 398244, Avg. loss: 0.001002\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002057, T: 56892, Avg. loss: 0.005699\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001582, T: 113784, Avg. loss: 0.001034\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002408, T: 170676, Avg. loss: 0.001033\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001038, T: 227568, Avg. loss: 0.001033\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002835, T: 284460, Avg. loss: 0.001033\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002642, T: 341352, Avg. loss: 0.001033\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002986, T: 398244, Avg. loss: 0.001033\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000683, T: 56892, Avg. loss: 0.005706\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.00, NNZs: 1, Bias: -0.001923, T: 113784, Avg. loss: 0.001011\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001584, T: 170676, Avg. loss: 0.001010\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000160, T: 227568, Avg. loss: 0.001010\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000550, T: 284460, Avg. loss: 0.001010\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001580, T: 341352, Avg. loss: 0.001010\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000638, T: 398244, Avg. loss: 0.001010\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 7 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001770, T: 56892, Avg. loss: 0.005671\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002005, T: 113784, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001734, T: 170676, Avg. loss: 0.001031\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002136, T: 227568, Avg. loss: 0.001031\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001581, T: 284460, Avg. loss: 0.001031\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002619, T: 341352, Avg. loss: 0.001031\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001658, T: 398244, Avg. loss: 0.001031\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001626, T: 56892, Avg. loss: 0.005691\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.002198, T: 113784, Avg. loss: 0.000933\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001005, T: 170676, Avg. loss: 0.000933\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000630, T: 227568, Avg. loss: 0.000932\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001183, T: 284460, Avg. loss: 0.000932\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000068, T: 341352, Avg. loss: 0.000932\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001524, T: 398244, Avg. loss: 0.000932\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: 0.006150, T: 56892, Avg. loss: 0.003643\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.011011, T: 113784, Avg. loss: 0.001639\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.004264, T: 170676, Avg. loss: 0.001638\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.004922, T: 227568, Avg. loss: 0.001639\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008474, T: 284460, Avg. loss: 0.001639\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006758, T: 341352, Avg. loss: 0.001637\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008334, T: 398244, Avg. loss: 0.001636\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005968, T: 56892, Avg. loss: 0.003728\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000737, T: 113784, Avg. loss: 0.001721\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001343, T: 170676, Avg. loss: 0.001719\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000517, T: 227568, Avg. loss: 0.001717\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.003431, T: 284460, Avg. loss: 0.001716\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000783, T: 341352, Avg. loss: 0.001716\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000076, T: 398244, Avg. loss: 0.001717\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010248, T: 56892, Avg. loss: 0.003710\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009467, T: 113784, Avg. loss: 0.001694\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.009322, T: 170676, Avg. loss: 0.001692\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.011114, T: 227568, Avg. loss: 0.001694\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007529, T: 284460, Avg. loss: 0.001692\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.011282, T: 341352, Avg. loss: 0.001695\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008389, T: 398244, Avg. loss: 0.001691\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002317, T: 56892, Avg. loss: 0.003843\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000925, T: 113784, Avg. loss: 0.001728\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000304, T: 170676, Avg. loss: 0.001728\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.004552, T: 227568, Avg. loss: 0.001727\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.004847, T: 284460, Avg. loss: 0.001728\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000576, T: 341352, Avg. loss: 0.001726\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000621, T: 398244, Avg. loss: 0.001724\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 7 epochs took 0.08 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000401, T: 56892, Avg. loss: 0.003119\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000815, T: 113784, Avg. loss: 0.001074\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.002137, T: 170676, Avg. loss: 0.001075\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000374, T: 227568, Avg. loss: 0.001075\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002981, T: 284460, Avg. loss: 0.001072\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.000407, T: 341352, Avg. loss: 0.001072\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.004017, T: 398244, Avg. loss: 0.001071\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009462, T: 56892, Avg. loss: 0.003681\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.013338, T: 113784, Avg. loss: 0.001638\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003035, T: 170676, Avg. loss: 0.001638\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.004116, T: 227568, Avg. loss: 0.001640\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002560, T: 284460, Avg. loss: 0.001636\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010128, T: 341352, Avg. loss: 0.001636\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002091, T: 398244, Avg. loss: 0.001635\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001273, T: 56892, Avg. loss: 0.003779\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001590, T: 113784, Avg. loss: 0.001719\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001590, T: 170676, Avg. loss: 0.001717\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002460, T: 227568, Avg. loss: 0.001717\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: -0.001916, T: 284460, Avg. loss: 0.001717\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000144, T: 341352, Avg. loss: 0.001718\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001678, T: 398244, Avg. loss: 0.001714\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.010488, T: 56892, Avg. loss: 0.003719\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005374, T: 113784, Avg. loss: 0.001697\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.011545, T: 170676, Avg. loss: 0.001697\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006794, T: 227568, Avg. loss: 0.001695\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008591, T: 284460, Avg. loss: 0.001691\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007341, T: 341352, Avg. loss: 0.001694\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006205, T: 398244, Avg. loss: 0.001694\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.004149, T: 56892, Avg. loss: 0.003793\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002728, T: 113784, Avg. loss: 0.001730\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000277, T: 170676, Avg. loss: 0.001726\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003542, T: 227568, Avg. loss: 0.001726\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003866, T: 284460, Avg. loss: 0.001723\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002937, T: 341352, Avg. loss: 0.001725\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000519, T: 398244, Avg. loss: 0.001725\n",
            "Total training time: 0.05 seconds.\n",
            "Convergence after 7 epochs took 0.05 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000869, T: 56892, Avg. loss: 0.003183\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.001310, T: 113784, Avg. loss: 0.001073\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001337, T: 170676, Avg. loss: 0.001074\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001333, T: 227568, Avg. loss: 0.001073\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.02, NNZs: 1, Bias: -0.001326, T: 284460, Avg. loss: 0.001074\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000478, T: 341352, Avg. loss: 0.001073\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.003682, T: 398244, Avg. loss: 0.001071\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006818, T: 56892, Avg. loss: 0.003736\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006803, T: 113784, Avg. loss: 0.001639\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.003870, T: 170676, Avg. loss: 0.001635\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.004002, T: 227568, Avg. loss: 0.001637\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002861, T: 284460, Avg. loss: 0.001638\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007991, T: 341352, Avg. loss: 0.001637\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005954, T: 398244, Avg. loss: 0.001633\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001526, T: 56892, Avg. loss: 0.003693\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.001739, T: 113784, Avg. loss: 0.001721\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.000062, T: 170676, Avg. loss: 0.001718\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: 0.002304, T: 227568, Avg. loss: 0.001717\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002213, T: 284460, Avg. loss: 0.001717\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001735, T: 341352, Avg. loss: 0.001715\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000119, T: 398244, Avg. loss: 0.001715\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.006804, T: 56892, Avg. loss: 0.003835\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005261, T: 113784, Avg. loss: 0.001696\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.007057, T: 170676, Avg. loss: 0.001696\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.011231, T: 227568, Avg. loss: 0.001694\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.009845, T: 284460, Avg. loss: 0.001694\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.008510, T: 341352, Avg. loss: 0.001694\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm: 1.01, NNZs: 1, Bias: 0.009321, T: 398244, Avg. loss: 0.001693\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000396, T: 56892, Avg. loss: 0.003753\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.000687, T: 113784, Avg. loss: 0.001727\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002723, T: 170676, Avg. loss: 0.001726\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001795, T: 227568, Avg. loss: 0.001726\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.005668, T: 284460, Avg. loss: 0.001724\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.002619, T: 341352, Avg. loss: 0.001727\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: 0.001824, T: 398244, Avg. loss: 0.001723\n",
            "Total training time: 0.07 seconds.\n",
            "Convergence after 7 epochs took 0.07 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.003458, T: 56892, Avg. loss: 0.003129\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.003596, T: 113784, Avg. loss: 0.001076\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.001851, T: 170676, Avg. loss: 0.001072\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000867, T: 227568, Avg. loss: 0.001074\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.000447, T: 284460, Avg. loss: 0.001073\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.02, NNZs: 1, Bias: -0.002102, T: 341352, Avg. loss: 0.001073\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.01, NNZs: 1, Bias: -0.002864, T: 398244, Avg. loss: 0.001070\n",
            "Total training time: 0.06 seconds.\n",
            "Convergence after 7 epochs took 0.06 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000866, T: 71115, Avg. loss: 0.002271\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.001190, T: 142230, Avg. loss: 0.001205\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000241, T: 213345, Avg. loss: 0.001205\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000171, T: 284460, Avg. loss: 0.001204\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000611, T: 355575, Avg. loss: 0.001205\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.00, NNZs: 1, Bias: 0.000560, T: 426690, Avg. loss: 0.001204\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.00, NNZs: 1, Bias: -0.000710, T: 497805, Avg. loss: 0.001204\n",
            "Total training time: 0.09 seconds.\n",
            "Convergence after 7 epochs took 0.09 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:169: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq42Q8FMo3XC",
        "outputId": "ad49bee6-693f-4bfb-dc64-8b8994793718"
      },
      "source": [
        "reg.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.0001,\n",
              " 'learning_rate': 'invscaling',\n",
              " 'loss': 'squared_loss',\n",
              " 'penalty': 'elasticnet'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J7v4StYpWY6"
      },
      "source": [
        "y_pred = reg.predict(X_test_1_scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV8JYP3kpi5n",
        "outputId": "a1233c5e-e350-4354-f30a-80b0a17bb09d"
      },
      "source": [
        "r2_score(y_test_1_scale, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.927009041089612"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "qeMUgR2t61rM",
        "outputId": "5c5adf89-9bb1-42c0-fc6b-495b91ccc44c"
      },
      "source": [
        "y_pred = reg.predict(X_train_scale)\n",
        "plt.scatter(X_train_scale, y_train_scale, c=\"crimson\")\n",
        "plt.scatter(X_train_scale, y_pred, c=\"yellow\")\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "plt.legend((\"True label\", \"Pred label\"))\n",
        "plt.title(\"Regression result on Training\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "5RfCjTvO66k4",
        "outputId": "b8daac05-aa08-47b9-fc17-bb1faae4d2fd"
      },
      "source": [
        "y_pred = reg.predict(X_test_1_scale)\n",
        "plt.scatter(X_test_1_scale, y_test_1_scale, c=\"crimson\")\n",
        "plt.scatter(X_test_1_scale, y_pred, c=\"yellow\")\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "plt.legend((\"True label\", \"Pred label\"))\n",
        "plt.title(\"Regression result on Test set 1\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzSH4daO89Nu"
      },
      "source": [
        "# __Áp dụng một số phương pháp để cải thiện kết quả R2__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKaRLYtH9jJD"
      },
      "source": [
        "## Phương pháp 1: Loại các sample có kích thước nhỏ hơn 0.4 * 1e7 trong tập training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Bs-f1Yf_90fR",
        "outputId": "b4f4f4da-dfab-44e0-dff7-daaca8ee5fa3"
      },
      "source": [
        "df_train = pd.read_csv(\"./train.csv\")\n",
        "df_train = df_train.loc[df_train[\"size\"] > 0.4 * 1e7]\n",
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>size</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.264600e+04</td>\n",
              "      <td>42646.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.998698e+06</td>\n",
              "      <td>0.575391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.724112e+06</td>\n",
              "      <td>0.150183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.000211e+06</td>\n",
              "      <td>0.303903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.502625e+06</td>\n",
              "      <td>0.445050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.993454e+06</td>\n",
              "      <td>0.573137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.499236e+06</td>\n",
              "      <td>0.705020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.999882e+06</td>\n",
              "      <td>0.983776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               size          time\n",
              "count  4.264600e+04  42646.000000\n",
              "mean   6.998698e+06      0.575391\n",
              "std    1.724112e+06      0.150183\n",
              "min    4.000211e+06      0.303903\n",
              "25%    5.502625e+06      0.445050\n",
              "50%    6.993454e+06      0.573137\n",
              "75%    8.499236e+06      0.705020\n",
              "max    9.999882e+06      0.983776"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "unRpLMbN-48j",
        "outputId": "1c2f2484-d1c3-4254-83a2-21e36ca463ce"
      },
      "source": [
        "sns.scatterplot(x='size', y='time', data=df_train, color='crimson')\n",
        "\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "\n",
        "plt.legend([\"Training samples\"])\n",
        "plt.title(\"Training set Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai7r2FOw_BM8"
      },
      "source": [
        "# Training set\n",
        "X_train, y_train = df_train.to_numpy(dtype=np.float32)[:, :-1], df_train.to_numpy(dtype=np.float32)[:, -1].reshape(-1, 1)\n",
        "\n",
        "# Test set\n",
        "X_test, y_test = df_test_1.to_numpy(dtype=np.float32)[:, :-1], df_test_1.to_numpy(dtype=np.float32)[:, -1].reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X7TmF-n_IyT"
      },
      "source": [
        "lin_reg = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPVqYIIq_mHl",
        "outputId": "4c3cf0f4-8004-4108-edf0-e25f408d32b1"
      },
      "source": [
        "lin_reg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo6q5dik_pt7",
        "outputId": "34108b1a-c0aa-4422-fb75-ef6c9b07fbbc"
      },
      "source": [
        "lin_reg.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9656180444113118"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "5K-3d3itIqjH",
        "outputId": "765aa18d-b252-42d8-d213-cf7c2c45ff4c"
      },
      "source": [
        "fig = plt.figure(figsize=(16, 6))\n",
        "\n",
        "# Training set\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(X_train, y_train, 'b.', linewidth=1, label='Training set')\n",
        "plt.plot(X_train, lin_reg.predict(X_train), 'r-', linewidth=2, label='Prediction')\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.title(\"Result on training set Visualization\")\n",
        "\n",
        "# Test set 1\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(X_test, y_test, 'b.', linewidth=1, label='Test set 1')\n",
        "plt.plot(X_test, lin_reg.predict(X_test), 'r-', linewidth=2, label='Prediction')\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.title(\"Result on test set 1 Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bou5E4P7tDwi"
      },
      "source": [
        "## Phương pháp 2: Sử dụng polynomial với phương trình có dạng $y = 𝞱_1 * x^\\frac{1}{10} + 𝞱_2 * x^\\frac{1}{10} * log(x) + 𝞱_3 * x + 𝞱_0$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI87IwlO49Ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc4968b-574f-49dc-f2bf-748066cb6625"
      },
      "source": [
        "def polynomial_custom(X):\n",
        "  return np.concatenate((X ** (1/10), X ** (1/10) * np.log(X), X), axis=1)\n",
        "\n",
        "# Training set\n",
        "X_train, y_train = df_train.to_numpy(dtype=np.float32)[:, :-1], df_train.to_numpy(dtype=np.float32)[:, -1].reshape(-1, 1)\n",
        "\n",
        "# Test set\n",
        "X_test, y_test = df_test_1.to_numpy(dtype=np.float32)[:, :-1], df_test_1.to_numpy(dtype=np.float32)[:, -1].reshape(-1, 1)\n",
        "\n",
        "X_train_custom = polynomial_custom(X_train)\n",
        "X_test_custom = polynomial_custom(X_test)\n",
        "\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train_custom, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-mTVOEpzjpN",
        "outputId": "f4db1a36-69b7-4303-f4d8-7a7fccb8d4e6"
      },
      "source": [
        "print(\"R2 score on test set 1: \", reg.score(X_test_custom, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score on test set 1:  0.9878710068205038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "Jsf9y00IHIXZ",
        "outputId": "5b07eff3-2977-474c-bcd5-23d9fd875390"
      },
      "source": [
        "fig = plt.figure(figsize=(16, 6))\n",
        "\n",
        "# Training set\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(X_train, y_train, 'b.', linewidth=1, label='Training set')\n",
        "plt.plot(X_train, reg.predict(X_train_custom), 'r-', linewidth=2, label='Prediction')\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.title(\"Result on training set Visualization\")\n",
        "\n",
        "# Test set 1\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(X_test, y_test, 'b.', linewidth=1, label='Test set 1')\n",
        "plt.plot(X_test, reg.predict(X_test_custom), 'r-', linewidth=2, label='Prediction')\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.title(\"Result on test set 1 Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo4af48wEXC5"
      },
      "source": [
        "# __Thực hiện training trên tập test set 1 (data3) và test trên tập test set 2 (data4)__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Z1VfRVIQJYBv",
        "outputId": "c2e03e7b-9f06-4b99-e656-35173e587d6b"
      },
      "source": [
        "df_train = pd.read_csv(\"./test_1.csv\")\n",
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>size</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.059000e+04</td>\n",
              "      <td>10590.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.999277e+07</td>\n",
              "      <td>2.642812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.759381e+06</td>\n",
              "      <td>0.537305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000026e+07</td>\n",
              "      <td>1.669640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.503806e+07</td>\n",
              "      <td>2.180550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.994436e+07</td>\n",
              "      <td>2.639820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.500845e+07</td>\n",
              "      <td>3.100155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.999734e+07</td>\n",
              "      <td>4.287660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               size          time\n",
              "count  1.059000e+04  10590.000000\n",
              "mean   2.999277e+07      2.642812\n",
              "std    5.759381e+06      0.537305\n",
              "min    2.000026e+07      1.669640\n",
              "25%    2.503806e+07      2.180550\n",
              "50%    2.994436e+07      2.639820\n",
              "75%    3.500845e+07      3.100155\n",
              "max    3.999734e+07      4.287660"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "15KegZcWJygg",
        "outputId": "1584facf-f383-48c6-e5ef-7ad24a0ef0e2"
      },
      "source": [
        "sns.scatterplot(x='size', y='time', data=df_train, color='crimson')\n",
        "\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "\n",
        "plt.legend([\"Training samples\"])\n",
        "plt.title(\"Training set Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l6smCkiINDA",
        "outputId": "5d9a1bd9-a339-4adc-dbec-faf5d14ede46"
      },
      "source": [
        "def polynomial_custom(X):\n",
        "  return np.concatenate((X ** (1/10), X ** (1/10) * np.log(X), X), axis=1)\n",
        "\n",
        "# Training set\n",
        "X_train, y_train = df_train.to_numpy(dtype=np.float32)[:, :-1], df_train.to_numpy(dtype=np.float32)[:, -1].reshape(-1, 1)\n",
        "\n",
        "# Test set\n",
        "X_test, y_test = df_test_2.to_numpy(dtype=np.float32)[:, :-1], df_test_2.to_numpy(dtype=np.float32)[:, -1].reshape(-1, 1)\n",
        "\n",
        "X_train_custom = polynomial_custom(X_train)\n",
        "X_test_custom = polynomial_custom(X_test)\n",
        "\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train_custom, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmlq6MKHIVch",
        "outputId": "392b56b2-ed5b-4a21-98fc-7f937262374a"
      },
      "source": [
        "print(\"R2 score on test set 2: \", reg.score(X_test_custom, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score on test set 2:  0.9330611345348044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "GE3TJaGMF-T7",
        "outputId": "8f5ad95a-1177-448b-cd4b-597d586d7b48"
      },
      "source": [
        "fig = plt.figure(figsize=(16, 6))\n",
        "\n",
        "# Training set\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(X_train, y_train, 'b.', linewidth=1, label='Training set')\n",
        "plt.plot(X_train, reg.predict(X_train_custom), 'r-', linewidth=2, label='Prediction')\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.title(\"Result on training set Visualization\")\n",
        "\n",
        "# Test set 1\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(X_test, y_test, 'b.', linewidth=1, label='Test set 2')\n",
        "plt.plot(X_test, reg.predict(X_test_custom), 'r-', linewidth=2, label='Prediction')\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Time\")\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.title(\"Result on test set 2 Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iNzV5txCooW"
      },
      "source": [
        "# __Nhận xét__\n",
        "| STT | Phương pháp                                                               | Training Set | Test Set | R2 Score |\n",
        "|-----|---------------------------------------------------------------------------|--------------|----------|----------|\n",
        "| 1   | Linear Regression                                                         | data2        | data3    | 0.926    |\n",
        "| 2   | SGD Linear Regression + Grid Search                                       | data2        | data3    | 0.927    |\n",
        "| 3   | Linear Regression + loại bỏ training sample có size nhỏ hơn 0.4 * 1e7     | data2        | data3    | 0.965    |\n",
        "| 4   | Polynomial Regression + loại bỏ training sample có size nhỏ hơn 0.4 * 1e7 | data2        | data3    | 0.987    |\n",
        "| 5   | Polynomial Regression                                                     | data3        | data4    | 0.933    |\n",
        "\n",
        "- Có thể thấy khi loại bỏ các mẫu dữ liệu có size nhỏ hơn 0.4 * 1e7 ở data2, điểm R2 tăng -> các điểm dữ liệu có size nhỏ hơn 0.4 * 1e7 không mang lại quá nhiều thông tin và có thể coi là nhiễu.\n",
        "- Khi áp dụng Polynomial Regression, có thể thấy rằng việc tạo thêm các đặc trưng từ các hàm toán học cơ bản có thể giúp mô hình fit với dữ liệu test hơn."
      ]
    }
  ]
}